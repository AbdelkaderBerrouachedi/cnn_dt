{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "try: from sklearn.model_selection import train_test_split\n",
    "except: from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,m):\n",
    "    #evaluate results\n",
    "    mse=sklearn.metrics.mean_squared_error(y_test,m)\n",
    "    mabs=sklearn.metrics.mean_absolute_error(y_test,m)\n",
    "    exvar=sklearn.metrics.explained_variance_score(y_test,m)   \n",
    "    print('Mean Squa Error :',mse)\n",
    "    print('Mean Abso Error :',mabs)\n",
    "    print('Expl. Variance  :',exvar,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the train & test and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1       2     3         4        5\n",
       "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
       "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
       "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
       "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
       "4  2000  0.0  0.3048  71.3  0.002663  127.461"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "# load data\n",
    "df=pd.read_csv('airfoil_self_noise.dat', sep=\"\\t\", header=None)\n",
    "# del df['Date']\n",
    "# del df['Next_Tmax'] #Next_Tmin\n",
    "# drop nan \n",
    "df = df.dropna()\n",
    "# the head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values\n",
    "Y = df[:,5]\n",
    "X = df[:,0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "   \n",
    "minmaxscale = MinMaxScaler().fit(X)\n",
    "X = minmaxscale.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X, Y, test_size=0.2, random_state=1) \n",
    "x_train_, x_test_, y_train_, y_test_ = x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train, test):\n",
    "\n",
    "    mean = np.mean(train, axis=0)\n",
    "    std = np.std(train, axis=0)+0.000001\n",
    "\n",
    "    X_train = (train - mean) / std\n",
    "    X_test = (test - mean) /std\n",
    "    return X_train, X_test\n",
    "\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 5, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.any(np.isnan(X_test)))\n",
    "# print(np.any(np.isnan(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation structure of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CNN\n",
    "def CNN_net():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation=\"relu\", input_shape=(X.shape[1],1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1202 samples, validate on 301 samples\n",
      "Epoch 1/250\n",
      "1202/1202 [==============================] - 1s 530us/step - loss: 14530.6863 - val_loss: 12959.7035\n",
      "Epoch 2/250\n",
      "1202/1202 [==============================] - 1s 420us/step - loss: 10432.9047 - val_loss: 7723.7247\n",
      "Epoch 3/250\n",
      "1202/1202 [==============================] - 1s 597us/step - loss: 5354.5393 - val_loss: 3397.6051\n",
      "Epoch 4/250\n",
      "1202/1202 [==============================] - 0s 342us/step - loss: 2542.4856 - val_loss: 1760.5966\n",
      "Epoch 5/250\n",
      "1202/1202 [==============================] - 0s 379us/step - loss: 1731.2499 - val_loss: 1244.8048\n",
      "Epoch 6/250\n",
      "1202/1202 [==============================] - 0s 400us/step - loss: 1434.3963 - val_loss: 983.3095\n",
      "Epoch 7/250\n",
      "1202/1202 [==============================] - 0s 328us/step - loss: 1161.1874 - val_loss: 800.3178\n",
      "Epoch 8/250\n",
      "1202/1202 [==============================] - 0s 319us/step - loss: 1046.8369 - val_loss: 661.6691\n",
      "Epoch 9/250\n",
      "1202/1202 [==============================] - 0s 301us/step - loss: 955.2547 - val_loss: 547.8395\n",
      "Epoch 10/250\n",
      "1202/1202 [==============================] - 0s 335us/step - loss: 782.7595 - val_loss: 458.2292\n",
      "Epoch 11/250\n",
      "1202/1202 [==============================] - 0s 346us/step - loss: 789.8976 - val_loss: 380.4612\n",
      "Epoch 12/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 654.9747 - val_loss: 330.0751\n",
      "Epoch 13/250\n",
      "1202/1202 [==============================] - 0s 293us/step - loss: 647.3815 - val_loss: 282.5446\n",
      "Epoch 14/250\n",
      "1202/1202 [==============================] - 0s 316us/step - loss: 555.5932 - val_loss: 252.9741\n",
      "Epoch 15/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 588.2354 - val_loss: 218.5773\n",
      "Epoch 16/250\n",
      "1202/1202 [==============================] - 0s 293us/step - loss: 550.8288 - val_loss: 185.7607\n",
      "Epoch 17/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 491.3145 - val_loss: 165.4569\n",
      "Epoch 18/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 509.1761 - val_loss: 144.3860\n",
      "Epoch 19/250\n",
      "1202/1202 [==============================] - 0s 328us/step - loss: 479.9077 - val_loss: 124.0533\n",
      "Epoch 20/250\n",
      "1202/1202 [==============================] - 0s 361us/step - loss: 450.7387 - val_loss: 114.7768\n",
      "Epoch 21/250\n",
      "1202/1202 [==============================] - 0s 336us/step - loss: 441.7708 - val_loss: 102.9815\n",
      "Epoch 22/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 458.9075 - val_loss: 92.5254\n",
      "Epoch 23/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 414.7524 - val_loss: 80.9828\n",
      "Epoch 24/250\n",
      "1202/1202 [==============================] - 0s 283us/step - loss: 411.8540 - val_loss: 81.1920\n",
      "Epoch 25/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 397.9910 - val_loss: 74.8608\n",
      "Epoch 26/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 396.5534 - val_loss: 66.8480\n",
      "Epoch 27/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 418.2642 - val_loss: 66.4410\n",
      "Epoch 28/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 409.4583 - val_loss: 61.8696\n",
      "Epoch 29/250\n",
      "1202/1202 [==============================] - 0s 312us/step - loss: 413.4238 - val_loss: 57.6326\n",
      "Epoch 30/250\n",
      "1202/1202 [==============================] - 0s 325us/step - loss: 420.2186 - val_loss: 54.7061\n",
      "Epoch 31/250\n",
      "1202/1202 [==============================] - 0s 338us/step - loss: 380.9552 - val_loss: 49.4795\n",
      "Epoch 32/250\n",
      "1202/1202 [==============================] - 0s 334us/step - loss: 385.2206 - val_loss: 56.8048\n",
      "Epoch 33/250\n",
      "1202/1202 [==============================] - 0s 312us/step - loss: 397.7778 - val_loss: 48.7751\n",
      "Epoch 34/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 396.4938 - val_loss: 45.3459\n",
      "Epoch 35/250\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 393.0839 - val_loss: 50.9883\n",
      "Epoch 36/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 376.0511 - val_loss: 45.2376\n",
      "Epoch 37/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 387.1044 - val_loss: 44.4657\n",
      "Epoch 38/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 379.7308 - val_loss: 44.0649\n",
      "Epoch 39/250\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 366.6016 - val_loss: 41.8088\n",
      "Epoch 40/250\n",
      "1202/1202 [==============================] - 0s 280us/step - loss: 396.2615 - val_loss: 39.5807\n",
      "Epoch 41/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 380.8601 - val_loss: 45.2256\n",
      "Epoch 42/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 386.6583 - val_loss: 37.5190\n",
      "Epoch 43/250\n",
      "1202/1202 [==============================] - 0s 332us/step - loss: 399.4132 - val_loss: 41.8628\n",
      "Epoch 44/250\n",
      "1202/1202 [==============================] - 0s 312us/step - loss: 379.6353 - val_loss: 42.5392\n",
      "Epoch 45/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 365.5363 - val_loss: 41.7192\n",
      "Epoch 46/250\n",
      "1202/1202 [==============================] - 0s 322us/step - loss: 363.9143 - val_loss: 35.5852\n",
      "Epoch 47/250\n",
      "1202/1202 [==============================] - 0s 410us/step - loss: 366.3682 - val_loss: 40.8935\n",
      "Epoch 48/250\n",
      "1202/1202 [==============================] - 0s 312us/step - loss: 350.9323 - val_loss: 42.4451\n",
      "Epoch 49/250\n",
      "1202/1202 [==============================] - 0s 297us/step - loss: 338.9697 - val_loss: 40.6236\n",
      "Epoch 50/250\n",
      "1202/1202 [==============================] - 0s 286us/step - loss: 347.6076 - val_loss: 38.2184\n",
      "Epoch 51/250\n",
      "1202/1202 [==============================] - 0s 306us/step - loss: 357.0876 - val_loss: 45.0177\n",
      "Epoch 52/250\n",
      "1202/1202 [==============================] - 1s 565us/step - loss: 353.9082 - val_loss: 48.2001\n",
      "Epoch 53/250\n",
      "1202/1202 [==============================] - 1s 448us/step - loss: 391.7569 - val_loss: 39.8922\n",
      "Epoch 54/250\n",
      "1202/1202 [==============================] - 1s 438us/step - loss: 363.3505 - val_loss: 39.0392\n",
      "Epoch 55/250\n",
      "1202/1202 [==============================] - 1s 430us/step - loss: 368.4492 - val_loss: 37.4314\n",
      "Epoch 56/250\n",
      "1202/1202 [==============================] - ETA: 0s - loss: 334.848 - 0s 403us/step - loss: 340.2475 - val_loss: 39.2385\n",
      "Epoch 57/250\n",
      "1202/1202 [==============================] - 1s 440us/step - loss: 370.1309 - val_loss: 36.4934\n",
      "Epoch 58/250\n",
      "1202/1202 [==============================] - 1s 438us/step - loss: 354.9937 - val_loss: 39.8713\n",
      "Epoch 59/250\n",
      "1202/1202 [==============================] - 1s 467us/step - loss: 366.2823 - val_loss: 37.7845\n",
      "Epoch 60/250\n",
      "1202/1202 [==============================] - 1s 439us/step - loss: 353.9829 - val_loss: 38.3683\n",
      "Epoch 61/250\n",
      "1202/1202 [==============================] - 1s 462us/step - loss: 333.4647 - val_loss: 42.3875\n",
      "Epoch 62/250\n",
      "1202/1202 [==============================] - 1s 436us/step - loss: 360.3317 - val_loss: 39.8994\n",
      "Epoch 63/250\n",
      "1202/1202 [==============================] - 1s 509us/step - loss: 359.8660 - val_loss: 35.3696\n",
      "Epoch 64/250\n",
      "1202/1202 [==============================] - 1s 481us/step - loss: 357.4681 - val_loss: 42.6577\n",
      "Epoch 65/250\n",
      "1202/1202 [==============================] - 1s 506us/step - loss: 389.9106 - val_loss: 43.7725\n",
      "Epoch 66/250\n",
      "1202/1202 [==============================] - 1s 439us/step - loss: 353.4701 - val_loss: 38.7511\n",
      "Epoch 67/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 1s 435us/step - loss: 366.7637 - val_loss: 35.2375\n",
      "Epoch 68/250\n",
      "1202/1202 [==============================] - 0s 406us/step - loss: 376.1114 - val_loss: 39.2990\n",
      "Epoch 69/250\n",
      "1202/1202 [==============================] - 0s 388us/step - loss: 343.2308 - val_loss: 37.9596\n",
      "Epoch 70/250\n",
      "1202/1202 [==============================] - 0s 364us/step - loss: 347.1729 - val_loss: 37.9735\n",
      "Epoch 71/250\n",
      "1202/1202 [==============================] - 0s 400us/step - loss: 354.1286 - val_loss: 33.6125\n",
      "Epoch 72/250\n",
      "1202/1202 [==============================] - 0s 371us/step - loss: 344.3728 - val_loss: 36.5202\n",
      "Epoch 73/250\n",
      "1202/1202 [==============================] - 0s 347us/step - loss: 364.0416 - val_loss: 37.8687\n",
      "Epoch 74/250\n",
      "1202/1202 [==============================] - 0s 338us/step - loss: 382.1583 - val_loss: 45.1129\n",
      "Epoch 75/250\n",
      "1202/1202 [==============================] - 0s 334us/step - loss: 340.9646 - val_loss: 39.1620\n",
      "Epoch 76/250\n",
      "1202/1202 [==============================] - 0s 384us/step - loss: 370.8127 - val_loss: 38.2146\n",
      "Epoch 77/250\n",
      "1202/1202 [==============================] - 0s 406us/step - loss: 365.5594 - val_loss: 44.8204\n",
      "Epoch 78/250\n",
      "1202/1202 [==============================] - 1s 422us/step - loss: 348.7273 - val_loss: 40.3924\n",
      "Epoch 79/250\n",
      "1202/1202 [==============================] - 1s 485us/step - loss: 348.2698 - val_loss: 39.5867\n",
      "Epoch 80/250\n",
      "1202/1202 [==============================] - 1s 489us/step - loss: 358.8440 - val_loss: 36.0196\n",
      "Epoch 81/250\n",
      "1202/1202 [==============================] - 0s 361us/step - loss: 341.1496 - val_loss: 35.8084\n",
      "Epoch 82/250\n",
      "1202/1202 [==============================] - 1s 430us/step - loss: 335.8289 - val_loss: 42.7567\n",
      "Epoch 83/250\n",
      "1202/1202 [==============================] - 1s 498us/step - loss: 364.7281 - val_loss: 42.2587\n",
      "Epoch 84/250\n",
      "1202/1202 [==============================] - 1s 423us/step - loss: 361.2887 - val_loss: 44.7105\n",
      "Epoch 85/250\n",
      "1202/1202 [==============================] - 0s 407us/step - loss: 353.9197 - val_loss: 39.0866\n",
      "Epoch 86/250\n",
      "1202/1202 [==============================] - 0s 382us/step - loss: 342.6220 - val_loss: 43.4976\n",
      "Epoch 87/250\n",
      "1202/1202 [==============================] - 1s 417us/step - loss: 369.5959 - val_loss: 48.5401\n",
      "Epoch 88/250\n",
      "1202/1202 [==============================] - 1s 427us/step - loss: 356.8175 - val_loss: 34.5578\n",
      "Epoch 89/250\n",
      "1202/1202 [==============================] - 1s 460us/step - loss: 319.5872 - val_loss: 38.5250\n",
      "Epoch 90/250\n",
      "1202/1202 [==============================] - 1s 421us/step - loss: 341.9045 - val_loss: 48.7684\n",
      "Epoch 91/250\n",
      "1202/1202 [==============================] - 0s 335us/step - loss: 337.1740 - val_loss: 37.8207\n",
      "Epoch 92/250\n",
      "1202/1202 [==============================] - 0s 342us/step - loss: 344.9724 - val_loss: 44.7448\n",
      "Epoch 93/250\n",
      "1202/1202 [==============================] - 0s 345us/step - loss: 347.4832 - val_loss: 36.5140\n",
      "Epoch 94/250\n",
      "1202/1202 [==============================] - 0s 338us/step - loss: 351.0293 - val_loss: 38.4494\n",
      "Epoch 95/250\n",
      "1202/1202 [==============================] - 0s 347us/step - loss: 358.3292 - val_loss: 37.3988\n",
      "Epoch 96/250\n",
      "1202/1202 [==============================] - 0s 341us/step - loss: 354.3907 - val_loss: 41.3325\n",
      "Epoch 97/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 336.6799 - val_loss: 41.6505\n",
      "Epoch 98/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 361.1013 - val_loss: 41.6923\n",
      "Epoch 99/250\n",
      "1202/1202 [==============================] - 0s 311us/step - loss: 328.1606 - val_loss: 44.2177\n",
      "Epoch 100/250\n",
      "1202/1202 [==============================] - 0s 340us/step - loss: 352.4805 - val_loss: 41.4197\n",
      "Epoch 101/250\n",
      "1202/1202 [==============================] - 0s 337us/step - loss: 329.7532 - val_loss: 37.2219\n",
      "Epoch 102/250\n",
      "1202/1202 [==============================] - 0s 373us/step - loss: 343.9454 - val_loss: 38.7734\n",
      "Epoch 103/250\n",
      "1202/1202 [==============================] - 0s 348us/step - loss: 344.9685 - val_loss: 37.0803\n",
      "Epoch 104/250\n",
      "1202/1202 [==============================] - 0s 290us/step - loss: 338.6949 - val_loss: 42.5258\n",
      "Epoch 105/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 337.5984 - val_loss: 42.4934\n",
      "Epoch 106/250\n",
      "1202/1202 [==============================] - 0s 298us/step - loss: 341.9535 - val_loss: 33.4161\n",
      "Epoch 107/250\n",
      "1202/1202 [==============================] - 0s 301us/step - loss: 337.8295 - val_loss: 44.6455\n",
      "Epoch 108/250\n",
      "1202/1202 [==============================] - 0s 298us/step - loss: 337.4165 - val_loss: 38.9413\n",
      "Epoch 109/250\n",
      "1202/1202 [==============================] - 0s 305us/step - loss: 336.6089 - val_loss: 40.5792\n",
      "Epoch 110/250\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 361.3815 - val_loss: 40.6813\n",
      "Epoch 111/250\n",
      "1202/1202 [==============================] - 0s 303us/step - loss: 332.8234 - val_loss: 35.5944\n",
      "Epoch 112/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 342.3688 - val_loss: 33.1063\n",
      "Epoch 113/250\n",
      "1202/1202 [==============================] - 0s 320us/step - loss: 310.9023 - val_loss: 42.5993\n",
      "Epoch 114/250\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 317.8605 - val_loss: 39.2951\n",
      "Epoch 115/250\n",
      "1202/1202 [==============================] - 0s 303us/step - loss: 340.9559 - val_loss: 38.1060\n",
      "Epoch 116/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 313.1921 - val_loss: 35.3460\n",
      "Epoch 117/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 334.7628 - val_loss: 45.7931\n",
      "Epoch 118/250\n",
      "1202/1202 [==============================] - 0s 305us/step - loss: 332.0449 - val_loss: 35.5275\n",
      "Epoch 119/250\n",
      "1202/1202 [==============================] - 0s 301us/step - loss: 347.8538 - val_loss: 40.0966\n",
      "Epoch 120/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 363.1665 - val_loss: 35.1633\n",
      "Epoch 121/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 325.7407 - val_loss: 35.9053\n",
      "Epoch 122/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 332.8951 - val_loss: 39.1783\n",
      "Epoch 123/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 336.8367 - val_loss: 33.5048\n",
      "Epoch 124/250\n",
      "1202/1202 [==============================] - 0s 302us/step - loss: 340.1334 - val_loss: 33.1986\n",
      "Epoch 125/250\n",
      "1202/1202 [==============================] - 0s 305us/step - loss: 317.5396 - val_loss: 38.0239\n",
      "Epoch 126/250\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 316.9558 - val_loss: 38.4528\n",
      "Epoch 127/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 325.5891 - val_loss: 41.8844\n",
      "Epoch 128/250\n",
      "1202/1202 [==============================] - 0s 342us/step - loss: 350.7834 - val_loss: 40.3064\n",
      "Epoch 129/250\n",
      "1202/1202 [==============================] - 0s 337us/step - loss: 313.9981 - val_loss: 42.9693\n",
      "Epoch 130/250\n",
      "1202/1202 [==============================] - 0s 350us/step - loss: 341.9668 - val_loss: 46.8276\n",
      "Epoch 131/250\n",
      "1202/1202 [==============================] - 0s 319us/step - loss: 338.5105 - val_loss: 35.3883\n",
      "Epoch 132/250\n",
      "1202/1202 [==============================] - 0s 326us/step - loss: 339.2952 - val_loss: 32.2957\n",
      "Epoch 133/250\n",
      "1202/1202 [==============================] - 0s 324us/step - loss: 321.8647 - val_loss: 39.5812\n",
      "Epoch 134/250\n",
      "1202/1202 [==============================] - 0s 307us/step - loss: 313.8981 - val_loss: 33.9463\n",
      "Epoch 135/250\n",
      "1202/1202 [==============================] - 0s 308us/step - loss: 331.7631 - val_loss: 37.7075\n",
      "Epoch 136/250\n",
      "1202/1202 [==============================] - 0s 307us/step - loss: 354.3381 - val_loss: 34.9949\n",
      "Epoch 137/250\n",
      "1202/1202 [==============================] - 0s 306us/step - loss: 327.7759 - val_loss: 42.7161\n",
      "Epoch 138/250\n",
      "1202/1202 [==============================] - 0s 313us/step - loss: 319.2724 - val_loss: 35.2928\n",
      "Epoch 139/250\n",
      "1202/1202 [==============================] - 0s 329us/step - loss: 350.3057 - val_loss: 38.1631\n",
      "Epoch 140/250\n",
      "1202/1202 [==============================] - 0s 308us/step - loss: 339.2841 - val_loss: 35.4372\n",
      "Epoch 141/250\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 318.1394 - val_loss: 39.7630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/250\n",
      "1202/1202 [==============================] - 0s 343us/step - loss: 338.6674 - val_loss: 36.3590\n",
      "Epoch 143/250\n",
      "1202/1202 [==============================] - 0s 336us/step - loss: 314.6984 - val_loss: 35.2758\n",
      "Epoch 144/250\n",
      "1202/1202 [==============================] - 0s 353us/step - loss: 339.5994 - val_loss: 37.3860\n",
      "Epoch 145/250\n",
      "1202/1202 [==============================] - 0s 397us/step - loss: 335.3253 - val_loss: 40.3482\n",
      "Epoch 146/250\n",
      "1202/1202 [==============================] - 0s 415us/step - loss: 298.4391 - val_loss: 48.3715\n",
      "Epoch 147/250\n",
      "1202/1202 [==============================] - 0s 389us/step - loss: 319.6947 - val_loss: 33.4070\n",
      "Epoch 148/250\n",
      "1202/1202 [==============================] - 0s 384us/step - loss: 326.7222 - val_loss: 33.8028\n",
      "Epoch 149/250\n",
      "1202/1202 [==============================] - 1s 501us/step - loss: 331.9539 - val_loss: 36.6278\n",
      "Epoch 150/250\n",
      "1202/1202 [==============================] - 1s 481us/step - loss: 314.2574 - val_loss: 36.9191\n",
      "Epoch 151/250\n",
      "1202/1202 [==============================] - 1s 508us/step - loss: 324.3168 - val_loss: 36.9403\n",
      "Epoch 152/250\n",
      "1202/1202 [==============================] - 0s 416us/step - loss: 316.2943 - val_loss: 36.0671\n",
      "Epoch 153/250\n",
      "1202/1202 [==============================] - 0s 342us/step - loss: 301.6500 - val_loss: 34.6957\n",
      "Epoch 154/250\n",
      "1202/1202 [==============================] - 0s 335us/step - loss: 322.8691 - val_loss: 39.2019\n",
      "Epoch 155/250\n",
      "1202/1202 [==============================] - 0s 324us/step - loss: 326.7766 - val_loss: 43.9664\n",
      "Epoch 156/250\n",
      "1202/1202 [==============================] - 0s 332us/step - loss: 332.6963 - val_loss: 40.3562\n",
      "Epoch 157/250\n",
      "1202/1202 [==============================] - 0s 363us/step - loss: 317.6330 - val_loss: 33.0145\n",
      "Epoch 158/250\n",
      "1202/1202 [==============================] - 1s 449us/step - loss: 311.1530 - val_loss: 41.5387\n",
      "Epoch 159/250\n",
      "1202/1202 [==============================] - 0s 356us/step - loss: 324.8912 - val_loss: 37.4604\n",
      "Epoch 160/250\n",
      "1202/1202 [==============================] - 1s 603us/step - loss: 317.7717 - val_loss: 36.5217\n",
      "Epoch 161/250\n",
      "1202/1202 [==============================] - 1s 561us/step - loss: 325.9271 - val_loss: 47.1150\n",
      "Epoch 162/250\n",
      "1202/1202 [==============================] - 1s 646us/step - loss: 323.7645 - val_loss: 36.8681\n",
      "Epoch 163/250\n",
      "1202/1202 [==============================] - 1s 567us/step - loss: 302.2155 - val_loss: 37.1078\n",
      "Epoch 164/250\n",
      "1202/1202 [==============================] - 1s 582us/step - loss: 294.6751 - val_loss: 41.0582\n",
      "Epoch 165/250\n",
      "1202/1202 [==============================] - 1s 596us/step - loss: 331.2645 - val_loss: 36.1215\n",
      "Epoch 166/250\n",
      "1202/1202 [==============================] - 1s 622us/step - loss: 319.9386 - val_loss: 33.2400\n",
      "Epoch 167/250\n",
      "1202/1202 [==============================] - 1s 609us/step - loss: 314.5395 - val_loss: 31.8380\n",
      "Epoch 168/250\n",
      "1202/1202 [==============================] - 1s 626us/step - loss: 322.3794 - val_loss: 38.2772\n",
      "Epoch 169/250\n",
      "1202/1202 [==============================] - 1s 545us/step - loss: 318.1558 - val_loss: 40.0031\n",
      "Epoch 170/250\n",
      "1202/1202 [==============================] - 1s 703us/step - loss: 299.2253 - val_loss: 35.4548\n",
      "Epoch 171/250\n",
      "1202/1202 [==============================] - 1s 590us/step - loss: 323.0609 - val_loss: 39.2684\n",
      "Epoch 172/250\n",
      "1202/1202 [==============================] - 1s 558us/step - loss: 317.3786 - val_loss: 36.6635\n",
      "Epoch 173/250\n",
      "1202/1202 [==============================] - 1s 438us/step - loss: 314.5202 - val_loss: 33.9640\n",
      "Epoch 174/250\n",
      "1202/1202 [==============================] - 1s 452us/step - loss: 297.1939 - val_loss: 33.5941\n",
      "Epoch 175/250\n",
      "1202/1202 [==============================] - 0s 388us/step - loss: 311.6560 - val_loss: 36.5386\n",
      "Epoch 176/250\n",
      "1202/1202 [==============================] - 0s 361us/step - loss: 266.2879 - val_loss: 36.3885\n",
      "Epoch 177/250\n",
      "1202/1202 [==============================] - 0s 378us/step - loss: 309.8459 - val_loss: 34.4026\n",
      "Epoch 178/250\n",
      "1202/1202 [==============================] - 0s 380us/step - loss: 320.2979 - val_loss: 34.7609\n",
      "Epoch 179/250\n",
      "1202/1202 [==============================] - 0s 370us/step - loss: 275.5282 - val_loss: 33.2508\n",
      "Epoch 180/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 313.4084 - val_loss: 38.7702\n",
      "Epoch 181/250\n",
      "1202/1202 [==============================] - 0s 390us/step - loss: 314.7136 - val_loss: 37.6081\n",
      "Epoch 182/250\n",
      "1202/1202 [==============================] - 0s 379us/step - loss: 300.4866 - val_loss: 36.1891\n",
      "Epoch 183/250\n",
      "1202/1202 [==============================] - 0s 381us/step - loss: 290.3713 - val_loss: 31.9167\n",
      "Epoch 184/250\n",
      "1202/1202 [==============================] - 0s 378us/step - loss: 307.1199 - val_loss: 35.4398\n",
      "Epoch 185/250\n",
      "1202/1202 [==============================] - 0s 379us/step - loss: 300.3734 - val_loss: 40.9885\n",
      "Epoch 186/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 309.8397 - val_loss: 43.9350\n",
      "Epoch 187/250\n",
      "1202/1202 [==============================] - 0s 373us/step - loss: 317.6419 - val_loss: 33.9064\n",
      "Epoch 188/250\n",
      "1202/1202 [==============================] - 1s 462us/step - loss: 313.5993 - val_loss: 37.3946\n",
      "Epoch 189/250\n",
      "1202/1202 [==============================] - 0s 377us/step - loss: 305.5617 - val_loss: 39.4677\n",
      "Epoch 190/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 307.6701 - val_loss: 49.0437\n",
      "Epoch 191/250\n",
      "1202/1202 [==============================] - 1s 477us/step - loss: 308.5406 - val_loss: 36.0800\n",
      "Epoch 192/250\n",
      "1202/1202 [==============================] - 0s 414us/step - loss: 309.4089 - val_loss: 34.6703\n",
      "Epoch 193/250\n",
      "1202/1202 [==============================] - 0s 347us/step - loss: 311.6030 - val_loss: 36.3183\n",
      "Epoch 194/250\n",
      "1202/1202 [==============================] - 0s 376us/step - loss: 281.9272 - val_loss: 39.8914\n",
      "Epoch 195/250\n",
      "1202/1202 [==============================] - 0s 372us/step - loss: 292.1308 - val_loss: 34.8145\n",
      "Epoch 196/250\n",
      "1202/1202 [==============================] - 0s 366us/step - loss: 298.0203 - val_loss: 37.6014\n",
      "Epoch 197/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 298.7972 - val_loss: 34.1442\n",
      "Epoch 198/250\n",
      "1202/1202 [==============================] - 0s 371us/step - loss: 300.0184 - val_loss: 31.3114\n",
      "Epoch 199/250\n",
      "1202/1202 [==============================] - 0s 413us/step - loss: 304.3328 - val_loss: 39.6448\n",
      "Epoch 200/250\n",
      "1202/1202 [==============================] - 0s 378us/step - loss: 297.9141 - val_loss: 32.7674\n",
      "Epoch 201/250\n",
      "1202/1202 [==============================] - 0s 380us/step - loss: 296.7277 - val_loss: 39.3628\n",
      "Epoch 202/250\n",
      "1202/1202 [==============================] - 0s 384us/step - loss: 308.7784 - val_loss: 35.0750\n",
      "Epoch 203/250\n",
      "1202/1202 [==============================] - 1s 456us/step - loss: 291.2344 - val_loss: 39.4067\n",
      "Epoch 204/250\n",
      "1202/1202 [==============================] - 1s 427us/step - loss: 305.8449 - val_loss: 42.8085\n",
      "Epoch 205/250\n",
      "1202/1202 [==============================] - 1s 437us/step - loss: 329.5442 - val_loss: 36.5938\n",
      "Epoch 206/250\n",
      "1202/1202 [==============================] - 1s 422us/step - loss: 297.5158 - val_loss: 39.9050\n",
      "Epoch 207/250\n",
      "1202/1202 [==============================] - 0s 402us/step - loss: 317.0502 - val_loss: 41.6295\n",
      "Epoch 208/250\n",
      "1202/1202 [==============================] - 1s 448us/step - loss: 312.2218 - val_loss: 33.5894\n",
      "Epoch 209/250\n",
      "1202/1202 [==============================] - 0s 355us/step - loss: 288.4743 - val_loss: 37.5542\n",
      "Epoch 210/250\n",
      "1202/1202 [==============================] - 0s 378us/step - loss: 286.7918 - val_loss: 37.2736\n",
      "Epoch 211/250\n",
      "1202/1202 [==============================] - 0s 374us/step - loss: 287.9814 - val_loss: 35.7564\n",
      "Epoch 212/250\n",
      "1202/1202 [==============================] - 0s 376us/step - loss: 292.5552 - val_loss: 42.6297\n",
      "Epoch 213/250\n",
      "1202/1202 [==============================] - 0s 366us/step - loss: 300.1278 - val_loss: 32.8945\n",
      "Epoch 214/250\n",
      "1202/1202 [==============================] - 0s 382us/step - loss: 294.1746 - val_loss: 39.6115\n",
      "Epoch 215/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 291.8546 - val_loss: 36.2383\n",
      "Epoch 216/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 0s 374us/step - loss: 309.3351 - val_loss: 35.1577\n",
      "Epoch 217/250\n",
      "1202/1202 [==============================] - 0s 369us/step - loss: 300.4085 - val_loss: 35.9414\n",
      "Epoch 218/250\n",
      "1202/1202 [==============================] - 0s 387us/step - loss: 297.6098 - val_loss: 34.9157\n",
      "Epoch 219/250\n",
      "1202/1202 [==============================] - 0s 373us/step - loss: 287.7887 - val_loss: 35.6162\n",
      "Epoch 220/250\n",
      "1202/1202 [==============================] - 0s 368us/step - loss: 299.0950 - val_loss: 35.6732\n",
      "Epoch 221/250\n",
      "1202/1202 [==============================] - 0s 374us/step - loss: 283.3061 - val_loss: 35.1055\n",
      "Epoch 222/250\n",
      "1202/1202 [==============================] - 0s 377us/step - loss: 295.1107 - val_loss: 41.5673\n",
      "Epoch 223/250\n",
      "1202/1202 [==============================] - 0s 373us/step - loss: 302.9222 - val_loss: 30.6112\n",
      "Epoch 224/250\n",
      "1202/1202 [==============================] - 0s 405us/step - loss: 308.1000 - val_loss: 33.9804\n",
      "Epoch 225/250\n",
      "1202/1202 [==============================] - 0s 381us/step - loss: 292.1616 - val_loss: 34.7656\n",
      "Epoch 226/250\n",
      "1202/1202 [==============================] - 0s 377us/step - loss: 297.0378 - val_loss: 31.9998\n",
      "Epoch 227/250\n",
      "1202/1202 [==============================] - 0s 373us/step - loss: 281.8592 - val_loss: 43.4944\n",
      "Epoch 228/250\n",
      "1202/1202 [==============================] - 0s 388us/step - loss: 294.5232 - val_loss: 34.8180\n",
      "Epoch 229/250\n",
      "1202/1202 [==============================] - 0s 375us/step - loss: 260.1081 - val_loss: 36.1253\n",
      "Epoch 230/250\n",
      "1202/1202 [==============================] - 0s 361us/step - loss: 297.1703 - val_loss: 42.2653\n",
      "Epoch 231/250\n",
      "1202/1202 [==============================] - 0s 384us/step - loss: 282.3539 - val_loss: 32.9262\n",
      "Epoch 232/250\n",
      "1202/1202 [==============================] - 0s 379us/step - loss: 295.2410 - val_loss: 37.0834\n",
      "Epoch 233/250\n",
      "1202/1202 [==============================] - 0s 386us/step - loss: 295.5839 - val_loss: 37.9198\n",
      "Epoch 234/250\n",
      "1202/1202 [==============================] - 0s 381us/step - loss: 291.7335 - val_loss: 35.0293\n",
      "Epoch 235/250\n",
      "1202/1202 [==============================] - 0s 387us/step - loss: 298.0117 - val_loss: 36.1900\n",
      "Epoch 236/250\n",
      "1202/1202 [==============================] - 0s 372us/step - loss: 283.4880 - val_loss: 38.7218\n",
      "Epoch 237/250\n",
      "1202/1202 [==============================] - 0s 398us/step - loss: 303.3194 - val_loss: 37.7391\n",
      "Epoch 238/250\n",
      "1202/1202 [==============================] - 1s 423us/step - loss: 301.3100 - val_loss: 33.3967\n",
      "Epoch 239/250\n",
      "1202/1202 [==============================] - 1s 422us/step - loss: 283.6509 - val_loss: 32.7662\n",
      "Epoch 240/250\n",
      "1202/1202 [==============================] - 1s 426us/step - loss: 298.1677 - val_loss: 40.9078\n",
      "Epoch 241/250\n",
      "1202/1202 [==============================] - 1s 460us/step - loss: 296.6728 - val_loss: 38.1188\n",
      "Epoch 242/250\n",
      "1202/1202 [==============================] - 0s 349us/step - loss: 274.4803 - val_loss: 33.4947\n",
      "Epoch 243/250\n",
      "1202/1202 [==============================] - 0s 370us/step - loss: 288.2430 - val_loss: 30.6413\n",
      "Epoch 244/250\n",
      "1202/1202 [==============================] - 0s 370us/step - loss: 277.8546 - val_loss: 37.9908\n",
      "Epoch 245/250\n",
      "1202/1202 [==============================] - 0s 386us/step - loss: 296.2127 - val_loss: 36.0149\n",
      "Epoch 246/250\n",
      "1202/1202 [==============================] - 0s 410us/step - loss: 289.9404 - val_loss: 34.7117\n",
      "Epoch 247/250\n",
      "1202/1202 [==============================] - 0s 387us/step - loss: 293.6555 - val_loss: 36.6263\n",
      "Epoch 248/250\n",
      "1202/1202 [==============================] - 0s 376us/step - loss: 291.6495 - val_loss: 34.4958\n",
      "Epoch 249/250\n",
      "1202/1202 [==============================] - 0s 365us/step - loss: 270.9790 - val_loss: 37.1366\n",
      "Epoch 250/250\n",
      "1202/1202 [==============================] - 0s 372us/step - loss: 306.5424 - val_loss: 33.6555\n"
     ]
    }
   ],
   "source": [
    "# Parametres\n",
    "verbose, epochs, batch_size = 1, 250, 5\n",
    "# initialize the model object\n",
    "clf_cnn = CNN_net()\n",
    "# fit network #Train the model using tensorboard instance in the callbacks\n",
    "history = clf_cnn.fit(x_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs, verbose=verbose, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - 0s 30us/step\n",
      " Model.evaluate :  36.329156631241226 \n",
      "\n",
      "Mean Squa Error : 33.65552434291699\n",
      "Mean Abso Error : 4.764523396945078\n",
      "Expl. Variance  : 0.2984487739666838\n"
     ]
    }
   ],
   "source": [
    "ypred = clf_cnn.predict(x_test)\n",
    "\n",
    "print(\" Model.evaluate : \",clf_cnn.evaluate(x_train, y_train),'\\n')\n",
    "\n",
    "#evaluate results\n",
    "mse=sklearn.metrics.mean_squared_error(y_test,ypred)\n",
    "mabs=sklearn.metrics.mean_absolute_error(y_test,ypred)\n",
    "exvar=sklearn.metrics.explained_variance_score(y_test,ypred)   \n",
    "print('Mean Squa Error :',mse)\n",
    "print('Mean Abso Error :',mabs)\n",
    "print('Expl. Variance  :',exvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 64)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.datatechnotes.com/2019/12/how-to-fit-regression-data-with-cnn.html\n",
    "x_ax = range(len(ypred))\n",
    "plt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training loss','Validation loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Novel Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# from the first Fully-Connected layer \n",
    "layer_name = 'dense_1'\n",
    "intermediate_layer_model = Model(inputs=clf_cnn.input,\n",
    "                                 outputs=clf_cnn.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features of the train dataset to use it in future.\n",
    "out_cnn_train = intermediate_layer_model.predict(x_train)\n",
    "# Save the features of the test dataset to use it in future.\n",
    "out_cnn_test = intermediate_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (from CNN) Shape: (1202, 1)\n",
      "Training Labels (from CNN) Shape: (1202,) \n",
      "\n",
      "Test Features (from CNN) Shape: (301, 1)\n",
      "Test Labels (from CNN) Shape: (301,) \n",
      "\n",
      "Test Features original Shape: (1202, 5, 1)\n",
      "Test Features original Shape: (301, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features (from CNN) Shape:', out_cnn_train.shape)\n",
    "print('Training Labels (from CNN) Shape:', y_train.shape,'\\n')\n",
    "\n",
    "print('Test Features (from CNN) Shape:', out_cnn_test.shape)\n",
    "print('Test Labels (from CNN) Shape:', y_test.shape,'\\n')\n",
    "\n",
    "print('Test Features original Shape:', x_train_.shape)\n",
    "print('Test Features original Shape:', x_test_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + Random Forest + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "djinn example\n",
      "Finding optimal hyper-parameters...\n",
      "Determining learning rate...\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:444: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:477: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:461: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Determining number of epochs needed...\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:528: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:531: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:532: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Optimal learning rate:  0.0007399558105791465\n",
      "Optimal # epochs:  210\n",
      "Optimal batch size:  61\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:263: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:334: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Epoch: 0001 cost= 0.060166229\n",
      "Epoch: 0002 cost= 0.035428790\n",
      "Epoch: 0003 cost= 0.031972939\n",
      "Epoch: 0004 cost= 0.029127313\n",
      "Epoch: 0005 cost= 0.026193128\n",
      "Epoch: 0006 cost= 0.028186298\n",
      "Epoch: 0007 cost= 0.027958144\n",
      "Epoch: 0008 cost= 0.026032179\n",
      "Epoch: 0009 cost= 0.024997249\n",
      "Epoch: 0010 cost= 0.027814652\n",
      "Epoch: 0011 cost= 0.025370607\n",
      "Epoch: 0012 cost= 0.025123873\n",
      "Epoch: 0013 cost= 0.024751814\n",
      "Epoch: 0014 cost= 0.024428385\n",
      "Epoch: 0015 cost= 0.025145995\n",
      "Epoch: 0016 cost= 0.024316720\n",
      "Epoch: 0017 cost= 0.022761102\n",
      "Epoch: 0018 cost= 0.023353376\n",
      "Epoch: 0019 cost= 0.022294224\n",
      "Epoch: 0020 cost= 0.024190062\n",
      "Epoch: 0021 cost= 0.023583936\n",
      "Epoch: 0022 cost= 0.023067206\n",
      "Epoch: 0023 cost= 0.022390983\n",
      "Epoch: 0024 cost= 0.023693763\n",
      "Epoch: 0025 cost= 0.023929566\n",
      "Epoch: 0026 cost= 0.022211790\n",
      "Epoch: 0027 cost= 0.023842941\n",
      "Epoch: 0028 cost= 0.021597252\n",
      "Epoch: 0029 cost= 0.024581512\n",
      "Epoch: 0030 cost= 0.023911630\n",
      "Epoch: 0031 cost= 0.021964718\n",
      "Epoch: 0032 cost= 0.023243604\n",
      "Epoch: 0033 cost= 0.021961513\n",
      "Epoch: 0034 cost= 0.021885934\n",
      "Epoch: 0035 cost= 0.023351718\n",
      "Epoch: 0036 cost= 0.021373792\n",
      "Epoch: 0037 cost= 0.023606797\n",
      "Epoch: 0038 cost= 0.020310967\n",
      "Epoch: 0039 cost= 0.022657921\n",
      "Epoch: 0040 cost= 0.023445875\n",
      "Epoch: 0041 cost= 0.024817897\n",
      "Epoch: 0042 cost= 0.021726055\n",
      "Epoch: 0043 cost= 0.021654043\n",
      "Epoch: 0044 cost= 0.023786825\n",
      "Epoch: 0045 cost= 0.022726147\n",
      "Epoch: 0046 cost= 0.020908041\n",
      "Epoch: 0047 cost= 0.023906745\n",
      "Epoch: 0048 cost= 0.022014500\n",
      "Epoch: 0049 cost= 0.022899987\n",
      "Epoch: 0050 cost= 0.022606564\n",
      "Epoch: 0051 cost= 0.022720596\n",
      "Epoch: 0052 cost= 0.023137851\n",
      "Epoch: 0053 cost= 0.023104840\n",
      "Epoch: 0054 cost= 0.021112589\n",
      "Epoch: 0055 cost= 0.023056561\n",
      "Epoch: 0056 cost= 0.023682410\n",
      "Epoch: 0057 cost= 0.020050874\n",
      "Epoch: 0058 cost= 0.021997732\n",
      "Epoch: 0059 cost= 0.023254788\n",
      "Epoch: 0060 cost= 0.023161476\n",
      "Epoch: 0061 cost= 0.022358524\n",
      "Epoch: 0062 cost= 0.022213976\n",
      "Epoch: 0063 cost= 0.022216807\n",
      "Epoch: 0064 cost= 0.022425874\n",
      "Epoch: 0065 cost= 0.021333238\n",
      "Epoch: 0066 cost= 0.022190821\n",
      "Epoch: 0067 cost= 0.022814315\n",
      "Epoch: 0068 cost= 0.023350358\n",
      "Epoch: 0069 cost= 0.023207431\n",
      "Epoch: 0070 cost= 0.021603355\n",
      "Epoch: 0071 cost= 0.021063184\n",
      "Epoch: 0072 cost= 0.022396479\n",
      "Epoch: 0073 cost= 0.021833361\n",
      "Epoch: 0074 cost= 0.022606571\n",
      "Epoch: 0075 cost= 0.023997153\n",
      "Epoch: 0076 cost= 0.022546815\n",
      "Epoch: 0077 cost= 0.023465270\n",
      "Epoch: 0078 cost= 0.022257551\n",
      "Epoch: 0079 cost= 0.020871361\n",
      "Epoch: 0080 cost= 0.021745197\n",
      "Epoch: 0081 cost= 0.021625821\n",
      "Epoch: 0082 cost= 0.020699583\n",
      "Epoch: 0083 cost= 0.023683753\n",
      "Epoch: 0084 cost= 0.022942388\n",
      "Epoch: 0085 cost= 0.021878966\n",
      "Epoch: 0086 cost= 0.021021205\n",
      "Epoch: 0087 cost= 0.023579970\n",
      "Epoch: 0088 cost= 0.022312180\n",
      "Epoch: 0089 cost= 0.022690529\n",
      "Epoch: 0090 cost= 0.021570893\n",
      "Epoch: 0091 cost= 0.021752015\n",
      "Epoch: 0092 cost= 0.022430591\n",
      "Epoch: 0093 cost= 0.023778069\n",
      "Epoch: 0094 cost= 0.022711663\n",
      "Epoch: 0095 cost= 0.021954000\n",
      "Epoch: 0096 cost= 0.023778298\n",
      "Epoch: 0097 cost= 0.023067461\n",
      "Epoch: 0098 cost= 0.021327905\n",
      "Epoch: 0099 cost= 0.021430078\n",
      "Epoch: 0100 cost= 0.023380093\n",
      "Epoch: 0101 cost= 0.021393161\n",
      "Epoch: 0102 cost= 0.022934254\n",
      "Epoch: 0103 cost= 0.022268103\n",
      "Epoch: 0104 cost= 0.023988591\n",
      "Epoch: 0105 cost= 0.021667216\n",
      "Epoch: 0106 cost= 0.023210450\n",
      "Epoch: 0107 cost= 0.022046365\n",
      "Epoch: 0108 cost= 0.020874752\n",
      "Epoch: 0109 cost= 0.023393919\n",
      "Epoch: 0110 cost= 0.022389382\n",
      "Epoch: 0111 cost= 0.021293450\n",
      "Epoch: 0112 cost= 0.025835867\n",
      "Epoch: 0113 cost= 0.023281076\n",
      "Epoch: 0114 cost= 0.020264502\n",
      "Epoch: 0115 cost= 0.020752846\n",
      "Epoch: 0116 cost= 0.022878656\n",
      "Epoch: 0117 cost= 0.022639662\n",
      "Epoch: 0118 cost= 0.020434888\n",
      "Epoch: 0119 cost= 0.021232021\n",
      "Epoch: 0120 cost= 0.022067543\n",
      "Epoch: 0121 cost= 0.021065009\n",
      "Epoch: 0122 cost= 0.024404872\n",
      "Epoch: 0123 cost= 0.022390490\n",
      "Epoch: 0124 cost= 0.022899522\n",
      "Epoch: 0125 cost= 0.020765206\n",
      "Epoch: 0126 cost= 0.021800072\n",
      "Epoch: 0127 cost= 0.024212145\n",
      "Epoch: 0128 cost= 0.022964078\n",
      "Epoch: 0129 cost= 0.021181155\n",
      "Epoch: 0130 cost= 0.023167860\n",
      "Epoch: 0131 cost= 0.021544885\n",
      "Epoch: 0132 cost= 0.022884576\n",
      "Epoch: 0133 cost= 0.022734848\n",
      "Epoch: 0134 cost= 0.022795499\n",
      "Epoch: 0135 cost= 0.023914434\n",
      "Epoch: 0136 cost= 0.024457331\n",
      "Epoch: 0137 cost= 0.021820158\n",
      "Epoch: 0138 cost= 0.023085299\n",
      "Epoch: 0139 cost= 0.023490631\n",
      "Epoch: 0140 cost= 0.021389445\n",
      "Epoch: 0141 cost= 0.023120212\n",
      "Epoch: 0142 cost= 0.023366144\n",
      "Epoch: 0143 cost= 0.022550553\n",
      "Epoch: 0144 cost= 0.023237365\n",
      "Epoch: 0145 cost= 0.022374180\n",
      "Epoch: 0146 cost= 0.024237074\n",
      "Epoch: 0147 cost= 0.023086369\n",
      "Epoch: 0148 cost= 0.019780370\n",
      "Epoch: 0149 cost= 0.023312258\n",
      "Epoch: 0150 cost= 0.021402578\n",
      "Epoch: 0151 cost= 0.022810515\n",
      "Epoch: 0152 cost= 0.023561777\n",
      "Epoch: 0153 cost= 0.023352411\n",
      "Epoch: 0154 cost= 0.023028855\n",
      "Epoch: 0155 cost= 0.023407415\n",
      "Epoch: 0156 cost= 0.021706889\n",
      "Epoch: 0157 cost= 0.024249487\n",
      "Epoch: 0158 cost= 0.021380268\n",
      "Epoch: 0159 cost= 0.022225419\n",
      "Epoch: 0160 cost= 0.022875588\n",
      "Epoch: 0161 cost= 0.024256372\n",
      "Epoch: 0162 cost= 0.021708444\n",
      "Epoch: 0163 cost= 0.022174586\n",
      "Epoch: 0164 cost= 0.023017115\n",
      "Epoch: 0165 cost= 0.022585070\n",
      "Epoch: 0166 cost= 0.021919122\n",
      "Epoch: 0167 cost= 0.023598142\n",
      "Epoch: 0168 cost= 0.022493004\n",
      "Epoch: 0169 cost= 0.021740212\n",
      "Epoch: 0170 cost= 0.022066544\n",
      "Epoch: 0171 cost= 0.021801169\n",
      "Epoch: 0172 cost= 0.023778817\n",
      "Epoch: 0173 cost= 0.023270034\n",
      "Epoch: 0174 cost= 0.023498674\n",
      "Epoch: 0175 cost= 0.023398507\n",
      "Epoch: 0176 cost= 0.023086342\n",
      "Epoch: 0177 cost= 0.021627866\n",
      "Epoch: 0178 cost= 0.023187998\n",
      "Epoch: 0179 cost= 0.021919390\n",
      "Epoch: 0180 cost= 0.021524647\n",
      "Epoch: 0181 cost= 0.023545908\n",
      "Epoch: 0182 cost= 0.022897062\n",
      "Epoch: 0183 cost= 0.021086431\n",
      "Epoch: 0184 cost= 0.021650410\n",
      "Epoch: 0185 cost= 0.022264794\n",
      "Epoch: 0186 cost= 0.022180803\n",
      "Epoch: 0187 cost= 0.022957242\n",
      "Epoch: 0188 cost= 0.022123138\n",
      "Epoch: 0189 cost= 0.023563309\n",
      "Epoch: 0190 cost= 0.021562819\n",
      "Epoch: 0191 cost= 0.021791420\n",
      "Epoch: 0192 cost= 0.022128869\n",
      "Epoch: 0193 cost= 0.022682154\n",
      "Epoch: 0194 cost= 0.022016860\n",
      "Epoch: 0195 cost= 0.022959974\n",
      "Epoch: 0196 cost= 0.022021491\n",
      "Epoch: 0197 cost= 0.022072218\n",
      "Epoch: 0198 cost= 0.023319280\n",
      "Epoch: 0199 cost= 0.022821323\n",
      "Epoch: 0200 cost= 0.023140438\n",
      "Epoch: 0201 cost= 0.023356131\n",
      "Epoch: 0202 cost= 0.023419657\n",
      "Epoch: 0203 cost= 0.024112183\n",
      "Epoch: 0204 cost= 0.023623812\n",
      "Epoch: 0205 cost= 0.023787438\n",
      "Epoch: 0206 cost= 0.023139752\n",
      "Epoch: 0207 cost= 0.022917829\n",
      "Epoch: 0208 cost= 0.022979696\n",
      "Epoch: 0209 cost= 0.023276341\n",
      "Epoch: 0210 cost= 0.022624100\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in: ./reg_djinn_test_tree0.ckpt\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn.py:276: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./reg_djinn_test_tree0.ckpt\n",
      "Model 0 restored\n",
      "Mean Squa Error : 29.995753247390187\n",
      "Mean Abso Error : 4.485469323649358\n",
      "Expl. Variance  : 0.29433416349650365 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from djinn import djinn\n",
    "print(\"djinn example\")    \n",
    "modelname=\"reg_djinn_test\"   # name the model\n",
    "ntrees=1                 # number of trees = number of neural nets in ensemble\n",
    "maxdepth=5               # max depth of tree -- optimize this for each data set\n",
    "dropout_keep=1.0         # dropout typically set to 1 for non-Bayesian models\n",
    "\n",
    "#initialize the model\n",
    "model=djinn.DJINN_Regressor(ntrees,maxdepth,dropout_keep)\n",
    "x_train, y_train, x_test, y_test = out_cnn_train, y_train, out_cnn_test, y_test\n",
    "\n",
    "# find optimal settings: this function returns dict with hyper-parameters\n",
    "# each djinn function accepts random seeds for reproducible behavior\n",
    "optimal=model.get_hyperparameters(x_train, y_train, random_state=42)\n",
    "batchsize=optimal['batch_size']\n",
    "learnrate=optimal['learn_rate']\n",
    "epochs=optimal['epochs']\n",
    "\n",
    "# batchsize=304\n",
    "# learnrate=0.002474296684203603\n",
    "# epochs=210\n",
    " \n",
    "# train the model with hyperparameters determined above\n",
    "model.train(x_train,y_train,epochs=epochs,learn_rate=learnrate, batch_size=batchsize, \n",
    "              display_step=1, save_files=True, file_name=modelname, \n",
    "              save_model=True,model_name=modelname, random_state=1)\n",
    "\n",
    "# *note there is a function model.fit(x_train,y_train, ... ) that wraps \n",
    "# get_hyperparameters() and train(), so that you do not have to manually\n",
    "# pass hyperparameters to train(). However, get_hyperparameters() can\n",
    "# be expensive, so I recommend running it once per dataset and using those\n",
    "# hyperparameter values in train() to save computational time\n",
    "\n",
    "# make predictions\n",
    "m=model.predict(x_test) #returns the median prediction if more than one tree\n",
    "\n",
    "#evaluate results\n",
    "evaluate(y_test,m)\n",
    "\n",
    "#close model \n",
    "model.close_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + ( SVM, XGB, DTree, ExtraTrees, RandomFores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 27.43459009249709\n",
      "Mean Abso Error : 4.218852631388756\n",
      "Expl. Variance  : 0.3605612271406058 \n",
      "\n",
      "================================================================================\n",
      "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False) \n",
      "\n",
      "Mean Squa Error : 3.8242203598467585e+25\n",
      "Mean Abso Error : 6181778822599.152\n",
      "Expl. Variance  : -6.548551082175998e+20 \n",
      "\n",
      "================================================================================\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 29.84611480604282\n",
      "Mean Abso Error : 4.476864287053399\n",
      "Expl. Variance  : 0.29731361722187044 \n",
      "\n",
      "================================================================================\n",
      "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
      "          fit_path=True, max_iter=500, normalize=True, positive=False,\n",
      "          precompute='auto', verbose=False) \n",
      "\n",
      "Mean Squa Error : 42.48062037744516\n",
      "Mean Abso Error : 5.2586509768463845\n",
      "Expl. Variance  : 0.0 \n",
      "\n",
      "================================================================================\n",
      "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, threshold_lambda=10000.0, tol=0.001,\n",
      "              verbose=False) \n",
      "\n",
      "Mean Squa Error : 29.84611480603784\n",
      "Mean Abso Error : 4.476864287053077\n",
      "Expl. Variance  : 0.2973136172219877 \n",
      "\n",
      "================================================================================\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=1000,\n",
      "                           n_iter_no_change=5, random_state=None, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "Mean Squa Error : 30.535120396989477\n",
      "Mean Abso Error : 4.548252484049514\n",
      "Expl. Variance  : 0.2988043627817041 \n",
      "\n",
      "================================================================================\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "                  max_subpopulation=10000, n_jobs=None, n_subsamples=None,\n",
      "                  random_state=None, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 30.835334507293616\n",
      "Mean Abso Error : 4.5558170883125415\n",
      "Expl. Variance  : 0.29739326188594584 \n",
      "\n",
      "================================================================================\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
      "\n",
      "Mean Squa Error : 29.850439801333845\n",
      "Mean Abso Error : 4.477142048883279\n",
      "Expl. Variance  : 0.2972116929523759 \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/41925157/logisticregression-unknown-label-type-continuous-using-sklearn-in-python\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(gamma='scale'),\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()\n",
    "              ]\n",
    "\n",
    "for item in classifiers:\n",
    "    print(item,'\\n')\n",
    "    clf = item\n",
    "    clf.fit(out_cnn_train, y_train)\n",
    "    #print(clf.predict(predictionData),'\\n')\n",
    "    #Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "    m = clf.predict(out_cnn_test)\n",
    "    #evaluate results\n",
    "    mse=sklearn.metrics.mean_squared_error(y_test,m)\n",
    "    mabs=sklearn.metrics.mean_absolute_error(y_test,m)\n",
    "    exvar=sklearn.metrics.explained_variance_score(y_test,m)   \n",
    "    print('Mean Squa Error :',mse)\n",
    "    print('Mean Abso Error :',mabs)\n",
    "    print('Expl. Variance  :',exvar,'\\n')\n",
    "    print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN XGBRegressor      \n",
      "Mean Squa Error : 32.363865494011144\n",
      "Mean Abso Error : 4.556666892016844\n",
      "Expl. Variance  : 0.2380583429793891 \n",
      "\n",
      "CNN ExtraTreesRegressor      \n",
      "Mean Squa Error : 48.471269272790686\n",
      "Mean Abso Error : 5.5103504983388705\n",
      "Expl. Variance  : -0.14111401799449075 \n",
      "\n",
      "CNN DecisionTreeRegressor      \n",
      "Mean Squa Error : 56.08787118604649\n",
      "Mean Abso Error : 5.934581395348836\n",
      "Expl. Variance  : -0.31945441598538404 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "from xgboost import XGBRegressor\n",
    "XGBModel = XGBRegressor()\n",
    "XGBModel.fit(out_cnn_train, y_train , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(out_cnn_test)\n",
    "print('CNN XGBRegressor      ')\n",
    "evaluate(y_test,XGBpredictions)\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "Ext = ExtraTreesRegressor(n_estimators=10)\n",
    "Ext.fit(out_cnn_train, y_train)\n",
    "#Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "predictionsCNN_Ext = Ext.predict(out_cnn_test)\n",
    "print('CNN ExtraTreesRegressor      ')\n",
    "evaluate(y_test,predictionsCNN_Ext)\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "clf_dt = tree.DecisionTreeRegressor()\n",
    "clf_dt.fit(out_cnn_train, y_train)\n",
    "# Get the mean absolute error on the validation data :\n",
    "clf_dtpredictions = clf_dt.predict(out_cnn_test)\n",
    "print('CNN DecisionTreeRegressor      ')\n",
    "evaluate(y_test,clf_dtpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1202, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cnn_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "1202/1202 [==============================] - 1s 469us/step - loss: 196838.5209\n",
      "Epoch 2/50\n",
      "1202/1202 [==============================] - 0s 332us/step - loss: 107652.8947\n",
      "Epoch 3/50\n",
      "1202/1202 [==============================] - 0s 299us/step - loss: 107955.5370\n",
      "Epoch 4/50\n",
      "1202/1202 [==============================] - 0s 311us/step - loss: 107928.3003\n",
      "Epoch 5/50\n",
      "1202/1202 [==============================] - 0s 282us/step - loss: 108202.1374\n",
      "Epoch 6/50\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 108313.3902\n",
      "Epoch 7/50\n",
      "1202/1202 [==============================] - 0s 333us/step - loss: 108553.0353\n",
      "Epoch 8/50\n",
      "1202/1202 [==============================] - 0s 288us/step - loss: 109278.6692\n",
      "Epoch 9/50\n",
      "1202/1202 [==============================] - 0s 325us/step - loss: 108378.8933\n",
      "Epoch 10/50\n",
      "1202/1202 [==============================] - 0s 295us/step - loss: 107722.4198\n",
      "Epoch 11/50\n",
      "1202/1202 [==============================] - 0s 314us/step - loss: 108065.0430\n",
      "Epoch 12/50\n",
      "1202/1202 [==============================] - 0s 304us/step - loss: 108639.3857\n",
      "Epoch 13/50\n",
      "1202/1202 [==============================] - 0s 332us/step - loss: 108093.9225\n",
      "Epoch 14/50\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 108088.5146\n",
      "Epoch 15/50\n",
      "1202/1202 [==============================] - 0s 290us/step - loss: 107991.3650\n",
      "Epoch 16/50\n",
      "1202/1202 [==============================] - 0s 294us/step - loss: 107898.1621\n",
      "Epoch 17/50\n",
      "1202/1202 [==============================] - 0s 335us/step - loss: 108222.9178\n",
      "Epoch 18/50\n",
      "1202/1202 [==============================] - 0s 300us/step - loss: 108065.5905\n",
      "Epoch 19/50\n",
      "1202/1202 [==============================] - 1s 439us/step - loss: 108052.0655\n",
      "Epoch 20/50\n",
      "1202/1202 [==============================] - 0s 361us/step - loss: 108089.6406\n",
      "Epoch 21/50\n",
      "1202/1202 [==============================] - 0s 380us/step - loss: 107630.8982\n",
      "Epoch 22/50\n",
      "1202/1202 [==============================] - 0s 371us/step - loss: 107934.9302\n",
      "Epoch 23/50\n",
      "1202/1202 [==============================] - 1s 434us/step - loss: 107948.5743\n",
      "Epoch 24/50\n",
      "1202/1202 [==============================] - 0s 328us/step - loss: 107898.1867\n",
      "Epoch 25/50\n",
      "1202/1202 [==============================] - 0s 303us/step - loss: 108180.1292\n",
      "Epoch 26/50\n",
      "1202/1202 [==============================] - 0s 329us/step - loss: 107660.1713\n",
      "Epoch 27/50\n",
      "1202/1202 [==============================] - 0s 342us/step - loss: 107900.2734\n",
      "Epoch 28/50\n",
      "1202/1202 [==============================] - 0s 297us/step - loss: 107890.3566\n",
      "Epoch 29/50\n",
      "1202/1202 [==============================] - 0s 334us/step - loss: 107966.5363\n",
      "Epoch 30/50\n",
      "1202/1202 [==============================] - 0s 293us/step - loss: 108262.2210\n",
      "Epoch 31/50\n",
      "1202/1202 [==============================] - 0s 319us/step - loss: 108143.1014\n",
      "Epoch 32/50\n",
      "1202/1202 [==============================] - 0s 296us/step - loss: 108210.4423\n",
      "Epoch 33/50\n",
      "1202/1202 [==============================] - 0s 310us/step - loss: 107656.7585\n",
      "Epoch 34/50\n",
      "1202/1202 [==============================] - 0s 295us/step - loss: 108180.8652\n",
      "Epoch 35/50\n",
      "1202/1202 [==============================] - 0s 351us/step - loss: 107812.8990\n",
      "Epoch 36/50\n",
      "1202/1202 [==============================] - 0s 303us/step - loss: 107621.4963\n",
      "Epoch 37/50\n",
      "1202/1202 [==============================] - 0s 327us/step - loss: 108247.5046\n",
      "Epoch 38/50\n",
      "1202/1202 [==============================] - 0s 323us/step - loss: 108444.0539\n",
      "Epoch 39/50\n",
      "1202/1202 [==============================] - 0s 288us/step - loss: 108069.9990\n",
      "Epoch 40/50\n",
      "1202/1202 [==============================] - 0s 323us/step - loss: 108009.6527\n",
      "Epoch 41/50\n",
      "1202/1202 [==============================] - 0s 294us/step - loss: 107862.3085\n",
      "Epoch 42/50\n",
      "1202/1202 [==============================] - 0s 332us/step - loss: 108409.3642\n",
      "Epoch 43/50\n",
      "1202/1202 [==============================] - 0s 322us/step - loss: 107839.6299\n",
      "Epoch 44/50\n",
      "1202/1202 [==============================] - 0s 293us/step - loss: 108466.5477\n",
      "Epoch 45/50\n",
      "1202/1202 [==============================] - 0s 320us/step - loss: 107715.1429\n",
      "Epoch 46/50\n",
      "1202/1202 [==============================] - 0s 295us/step - loss: 107879.5288\n",
      "Epoch 47/50\n",
      "1202/1202 [==============================] - 0s 345us/step - loss: 107801.9402\n",
      "Epoch 48/50\n",
      "1202/1202 [==============================] - 0s 317us/step - loss: 107717.1842\n",
      "Epoch 49/50\n",
      "1202/1202 [==============================] - 0s 285us/step - loss: 108038.1049\n",
      "Epoch 50/50\n",
      "1202/1202 [==============================] - 0s 312us/step - loss: 108121.7763\n",
      "301/301 [==============================] - 0s 278us/step\n",
      "CNN MLP Mean Squa Error : 468.47942597674444\n",
      "CNN MLP Mean Abso Error : 20.639903654485057\n",
      "CNN MLP Expl. Variance  : 0.0\n"
     ]
    }
   ],
   "source": [
    "# Regression Example With Boston Dataset: Baseline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=out_cnn_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "clf_MLP = KerasClassifier(build_fn = baseline_model, epochs = 50, batch_size=5, verbose=1)\n",
    "clf_MLP.fit(out_cnn_train, y_train)\n",
    "y_predmlp = clf_MLP.predict(out_cnn_test)\n",
    "\n",
    "#print(\"CNN MLP Model.evaluate : \",clf_MLP.evaluate(out_cnn_test, y_train),'\\n')\n",
    "#evaluate results\n",
    "mse=sklearn.metrics.mean_squared_error(y_test,y_predmlp)\n",
    "mabs=sklearn.metrics.mean_absolute_error(y_test,y_predmlp)\n",
    "exvar=sklearn.metrics.explained_variance_score(y_test,y_predmlp)   \n",
    "print('CNN MLP Mean Squa Error :',mse)\n",
    "print('CNN MLP Mean Abso Error :',mabs)\n",
    "print('CNN MLP Expl. Variance  :',exvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by RandomForest, ExtraTrees, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train_.reshape(x_train_.shape[0], x_train_.shape[1])\n",
    "x_test_  = x_test_.reshape(x_test_.shape[0], x_test_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RandomForestRegressor      \n",
      "Mean Squa Error : 2.431353182168442\n",
      "Mean Abso Error : 1.1421651495016674\n",
      "Expl. Variance  : 0.9442639588694615 \n",
      "\n",
      " XGBRegressor      \n",
      "Mean Squa Error : 2.149974348789351\n",
      "Mean Abso Error : 1.0521050820588274\n",
      "Expl. Variance  : 0.9493874100580102 \n",
      "\n",
      " ExtraTreesRegressor      \n",
      "Mean Squa Error : 2.3082564065780766\n",
      "Mean Abso Error : 1.0908684385382053\n",
      "Expl. Variance  : 0.9469680086085129 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier : from dataset originl\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(x_train_, y_train_)\n",
    "predictions = rf.predict(x_test_)\n",
    "print(' RandomForestRegressor      ')\n",
    "evaluate(y_test_,predictions)\n",
    "\n",
    "\n",
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "from xgboost import XGBRegressor\n",
    "XGBModel = XGBRegressor()\n",
    "XGBModel.fit(x_train_, y_train_ , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(x_test_)\n",
    "print(' XGBRegressor      ')\n",
    "evaluate(y_test_,XGBpredictions)\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "Ext = ExtraTreesRegressor(n_estimators=10)\n",
    "Ext.fit(x_train_, y_train_)\n",
    "#Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "predictionsCNN_Ext = Ext.predict(x_test_)\n",
    "print(' ExtraTreesRegressor      ')\n",
    "evaluate(y_test_,predictionsCNN_Ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
