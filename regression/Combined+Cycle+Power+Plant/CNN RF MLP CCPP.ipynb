{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "try: from sklearn.model_selection import train_test_split\n",
    "except: from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test,m):\n",
    "    #evaluate results\n",
    "    mse=sklearn.metrics.mean_squared_error(y_test,m)\n",
    "    mabs=sklearn.metrics.mean_absolute_error(y_test,m)\n",
    "    exvar=sklearn.metrics.explained_variance_score(y_test,m)   \n",
    "    print('Mean Squa Error :',mse)\n",
    "    print('Mean Abso Error :',mabs)\n",
    "    print('Expl. Variance  :',exvar,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the train & test and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "# load data\n",
    "df=pd.read_excel('CCPP/Folds5x2_pp.xlsx')\n",
    "# del df['Date']\n",
    "# del df['Next_Tmax'] #Next_Tmin\n",
    "# drop nan \n",
    "df = df.dropna()\n",
    "# the head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "# df to values\n",
    "df = df.values\n",
    "Y = df[:,4]\n",
    "X = df[:,0:4]\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print(X.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X, Y, test_size=0.2, random_state=1) \n",
    "x_train_, x_test_, y_train_, y_test_ = x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train, test):\n",
    "\n",
    "    mean = np.mean(train, axis=0)\n",
    "    std = np.std(train, axis=0)+0.000001\n",
    "\n",
    "    X_train = (train - mean) / std\n",
    "    X_test = (test - mean) /std\n",
    "    return X_train, X_test\n",
    "\n",
    "x_train, x_test = standardize(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1914, 4, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.any(np.isnan(X_test)))\n",
    "# print(np.any(np.isnan(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation structure of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CNN\n",
    "def CNN_net():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation=\"relu\", input_shape=(X.shape[1],1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Conv1D(128, 3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7654 samples, validate on 1914 samples\n",
      "Epoch 1/250\n",
      "7654/7654 [==============================] - 3s 329us/step - loss: 141148.6720 - val_loss: 51951.4185\n",
      "Epoch 2/250\n",
      "7654/7654 [==============================] - 2s 300us/step - loss: 25022.0800 - val_loss: 10151.5188\n",
      "Epoch 3/250\n",
      "7654/7654 [==============================] - 2s 305us/step - loss: 13015.1606 - val_loss: 5094.3776\n",
      "Epoch 4/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 9272.0667 - val_loss: 2331.5553\n",
      "Epoch 5/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 7256.6957 - val_loss: 1248.7007\n",
      "Epoch 6/250\n",
      "7654/7654 [==============================] - 2s 306us/step - loss: 6361.3713 - val_loss: 752.2241\n",
      "Epoch 7/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 5924.4837 - val_loss: 585.1581\n",
      "Epoch 8/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 5792.8962 - val_loss: 414.4209\n",
      "Epoch 9/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 5596.0909 - val_loss: 359.0375\n",
      "Epoch 10/250\n",
      "7654/7654 [==============================] - 2s 312us/step - loss: 5525.9458 - val_loss: 300.4405\n",
      "Epoch 11/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 5528.6884 - val_loss: 234.7154\n",
      "Epoch 12/250\n",
      "7654/7654 [==============================] - 3s 339us/step - loss: 5472.4858 - val_loss: 199.6961\n",
      "Epoch 13/250\n",
      "7654/7654 [==============================] - 2s 321us/step - loss: 5209.2643 - val_loss: 221.6393\n",
      "Epoch 14/250\n",
      "7654/7654 [==============================] - 2s 313us/step - loss: 5271.1889 - val_loss: 176.3523\n",
      "Epoch 15/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 5129.9840 - val_loss: 181.6765\n",
      "Epoch 16/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 5243.3719 - val_loss: 189.5587\n",
      "Epoch 17/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 5164.2616 - val_loss: 301.8622\n",
      "Epoch 18/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 5221.7960 - val_loss: 170.8998\n",
      "Epoch 19/250\n",
      "7654/7654 [==============================] - 3s 333us/step - loss: 5117.8520 - val_loss: 170.1277\n",
      "Epoch 20/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 5148.4671 - val_loss: 173.6903\n",
      "Epoch 21/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4982.5220 - val_loss: 136.5036\n",
      "Epoch 22/250\n",
      "7654/7654 [==============================] - 2s 299us/step - loss: 5118.6842 - val_loss: 172.7814\n",
      "Epoch 23/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 5118.9901 - val_loss: 145.9091\n",
      "Epoch 24/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 5037.4400 - val_loss: 172.1350\n",
      "Epoch 25/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 5004.9685 - val_loss: 170.7224\n",
      "Epoch 26/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 5177.6912 - val_loss: 89.8802\n",
      "Epoch 27/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 5058.8903 - val_loss: 193.1449\n",
      "Epoch 28/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 5082.9342 - val_loss: 178.9178\n",
      "Epoch 29/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4999.3270 - val_loss: 105.8107\n",
      "Epoch 30/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4987.8315 - val_loss: 141.0234\n",
      "Epoch 31/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 5123.1144 - val_loss: 174.6711\n",
      "Epoch 32/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 5093.2270 - val_loss: 216.9829\n",
      "Epoch 33/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 4811.8485 - val_loss: 109.7825\n",
      "Epoch 34/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 4857.5110 - val_loss: 145.1222\n",
      "Epoch 35/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4927.7819 - val_loss: 127.8367\n",
      "Epoch 36/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4958.3859 - val_loss: 143.1379\n",
      "Epoch 37/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4928.2738 - val_loss: 225.0447\n",
      "Epoch 38/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4997.5356 - val_loss: 146.5454\n",
      "Epoch 39/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4856.6791 - val_loss: 209.4403\n",
      "Epoch 40/250\n",
      "7654/7654 [==============================] - 3s 331us/step - loss: 4903.4187 - val_loss: 230.2728\n",
      "Epoch 41/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 4934.7607 - val_loss: 155.4895\n",
      "Epoch 42/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 4805.1917 - val_loss: 105.6054\n",
      "Epoch 43/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4776.5434 - val_loss: 169.0441\n",
      "Epoch 44/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4887.4811 - val_loss: 88.5173\n",
      "Epoch 45/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4668.8239 - val_loss: 223.7417\n",
      "Epoch 46/250\n",
      "7654/7654 [==============================] - 2s 302us/step - loss: 4829.0906 - val_loss: 200.8281\n",
      "Epoch 47/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 4875.1790 - val_loss: 265.6330\n",
      "Epoch 48/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4946.3708 - val_loss: 147.0652\n",
      "Epoch 49/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4725.0114 - val_loss: 182.5510\n",
      "Epoch 50/250\n",
      "7654/7654 [==============================] - 2s 300us/step - loss: 4711.2188 - val_loss: 213.5472\n",
      "Epoch 51/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4609.8669 - val_loss: 142.9631\n",
      "Epoch 52/250\n",
      "7654/7654 [==============================] - 2s 290us/step - loss: 4656.2903 - val_loss: 206.7519\n",
      "Epoch 53/250\n",
      "7654/7654 [==============================] - 2s 300us/step - loss: 4783.0453 - val_loss: 111.0035\n",
      "Epoch 54/250\n",
      "7654/7654 [==============================] - 2s 314us/step - loss: 4637.8445 - val_loss: 243.7575\n",
      "Epoch 55/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4696.7452 - val_loss: 115.1175\n",
      "Epoch 56/250\n",
      "7654/7654 [==============================] - 2s 310us/step - loss: 4664.0206 - val_loss: 128.1139\n",
      "Epoch 57/250\n",
      "7654/7654 [==============================] - 2s 310us/step - loss: 4550.0090 - val_loss: 123.1708\n",
      "Epoch 58/250\n",
      "7654/7654 [==============================] - 2s 313us/step - loss: 4569.6355 - val_loss: 169.0144\n",
      "Epoch 59/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 4616.9743 - val_loss: 221.0433\n",
      "Epoch 60/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 4505.3864 - val_loss: 174.2725\n",
      "Epoch 61/250\n",
      "7654/7654 [==============================] - 2s 303us/step - loss: 4657.4397 - val_loss: 190.9521\n",
      "Epoch 62/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4501.0592 - val_loss: 146.9143\n",
      "Epoch 63/250\n",
      "7654/7654 [==============================] - 2s 290us/step - loss: 4586.9773 - val_loss: 193.1481\n",
      "Epoch 64/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4575.8107 - val_loss: 155.9485\n",
      "Epoch 65/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 4564.5605 - val_loss: 137.7089\n",
      "Epoch 66/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7654/7654 [==============================] - 2s 297us/step - loss: 4568.2364 - val_loss: 97.0350\n",
      "Epoch 67/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 4417.5660 - val_loss: 132.7101\n",
      "Epoch 68/250\n",
      "7654/7654 [==============================] - 2s 308us/step - loss: 4584.2602 - val_loss: 151.8824\n",
      "Epoch 69/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4636.4926 - val_loss: 158.9053\n",
      "Epoch 70/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4540.9157 - val_loss: 130.6196\n",
      "Epoch 71/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4553.8184 - val_loss: 160.9813\n",
      "Epoch 72/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4521.7274 - val_loss: 141.8307\n",
      "Epoch 73/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 4441.5782 - val_loss: 157.3794\n",
      "Epoch 74/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 4376.8363 - val_loss: 154.9684\n",
      "Epoch 75/250\n",
      "7654/7654 [==============================] - 2s 302us/step - loss: 4521.1591 - val_loss: 104.3367\n",
      "Epoch 76/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 4464.3615 - val_loss: 164.1774\n",
      "Epoch 77/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4413.2944 - val_loss: 112.3950\n",
      "Epoch 78/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4427.3750 - val_loss: 117.2937\n",
      "Epoch 79/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4438.9557 - val_loss: 143.4710\n",
      "Epoch 80/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4367.5086 - val_loss: 128.9932\n",
      "Epoch 81/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 4491.6672 - val_loss: 87.0041\n",
      "Epoch 82/250\n",
      "7654/7654 [==============================] - 2s 299us/step - loss: 4355.6377 - val_loss: 139.2772\n",
      "Epoch 83/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4394.5740 - val_loss: 170.4040\n",
      "Epoch 84/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4378.1484 - val_loss: 161.3388\n",
      "Epoch 85/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4349.2061 - val_loss: 164.0273\n",
      "Epoch 86/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4391.1743 - val_loss: 133.8082\n",
      "Epoch 87/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4350.9646 - val_loss: 198.9118\n",
      "Epoch 88/250\n",
      "7654/7654 [==============================] - 2s 316us/step - loss: 4366.7678 - val_loss: 111.9101\n",
      "Epoch 89/250\n",
      "7654/7654 [==============================] - 2s 305us/step - loss: 4228.8122 - val_loss: 156.1552\n",
      "Epoch 90/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4331.3136 - val_loss: 223.6661\n",
      "Epoch 91/250\n",
      "7654/7654 [==============================] - 2s 299us/step - loss: 4295.5162 - val_loss: 86.2321\n",
      "Epoch 92/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4337.6419 - val_loss: 167.5917\n",
      "Epoch 93/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4320.6882 - val_loss: 88.1958\n",
      "Epoch 94/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4139.0936 - val_loss: 209.4086\n",
      "Epoch 95/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 4227.2034 - val_loss: 148.6857\n",
      "Epoch 96/250\n",
      "7654/7654 [==============================] - 2s 304us/step - loss: 4226.4325 - val_loss: 82.5381\n",
      "Epoch 97/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 4127.2541 - val_loss: 194.7606\n",
      "Epoch 98/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4300.7251 - val_loss: 132.2639\n",
      "Epoch 99/250\n",
      "7654/7654 [==============================] - 2s 299us/step - loss: 4226.7459 - val_loss: 115.3422\n",
      "Epoch 100/250\n",
      "7654/7654 [==============================] - 2s 304us/step - loss: 4243.4615 - val_loss: 156.4740\n",
      "Epoch 101/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4167.7293 - val_loss: 236.9251\n",
      "Epoch 102/250\n",
      "7654/7654 [==============================] - 3s 338us/step - loss: 4092.0330 - val_loss: 130.6474\n",
      "Epoch 103/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 4182.0321 - val_loss: 125.0983\n",
      "Epoch 104/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4071.4127 - val_loss: 166.8737\n",
      "Epoch 105/250\n",
      "7654/7654 [==============================] - 2s 300us/step - loss: 4146.5444 - val_loss: 120.4042\n",
      "Epoch 106/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 4070.8755 - val_loss: 106.3474\n",
      "Epoch 107/250\n",
      "7654/7654 [==============================] - 2s 303us/step - loss: 4114.2545 - val_loss: 125.5966\n",
      "Epoch 108/250\n",
      "7654/7654 [==============================] - 2s 319us/step - loss: 4006.2793 - val_loss: 129.5147\n",
      "Epoch 109/250\n",
      "7654/7654 [==============================] - 3s 327us/step - loss: 4135.0173 - val_loss: 228.1235\n",
      "Epoch 110/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4091.7639 - val_loss: 115.4215\n",
      "Epoch 111/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 4008.4684 - val_loss: 117.9936\n",
      "Epoch 112/250\n",
      "7654/7654 [==============================] - 2s 291us/step - loss: 4045.5146 - val_loss: 136.0417\n",
      "Epoch 113/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 4072.5028 - val_loss: 164.1576\n",
      "Epoch 114/250\n",
      "7654/7654 [==============================] - 2s 303us/step - loss: 4012.3448 - val_loss: 110.3591\n",
      "Epoch 115/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3983.7427 - val_loss: 95.0246\n",
      "Epoch 116/250\n",
      "7654/7654 [==============================] - 2s 326us/step - loss: 4065.0558 - val_loss: 114.7725\n",
      "Epoch 117/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 4038.3367 - val_loss: 95.1713\n",
      "Epoch 118/250\n",
      "7654/7654 [==============================] - 2s 291us/step - loss: 3997.2428 - val_loss: 104.5890\n",
      "Epoch 119/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3921.2287 - val_loss: 143.7151\n",
      "Epoch 120/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3922.2623 - val_loss: 158.4615\n",
      "Epoch 121/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3954.9595 - val_loss: 107.5759\n",
      "Epoch 122/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3939.6200 - val_loss: 109.0303\n",
      "Epoch 123/250\n",
      "7654/7654 [==============================] - 3s 327us/step - loss: 3902.6892 - val_loss: 167.8915\n",
      "Epoch 124/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3811.5007 - val_loss: 105.8728\n",
      "Epoch 125/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3921.5852 - val_loss: 158.4801\n",
      "Epoch 126/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3941.6911 - val_loss: 129.8437\n",
      "Epoch 127/250\n",
      "7654/7654 [==============================] - 2s 291us/step - loss: 3968.9975 - val_loss: 158.9855\n",
      "Epoch 128/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3757.7170 - val_loss: 91.6207\n",
      "Epoch 129/250\n",
      "7654/7654 [==============================] - 2s 309us/step - loss: 3944.8859 - val_loss: 105.4862\n",
      "Epoch 130/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 3855.3240 - val_loss: 88.8475\n",
      "Epoch 131/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3841.8183 - val_loss: 89.0356\n",
      "Epoch 132/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3682.6767 - val_loss: 106.4285\n",
      "Epoch 133/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3773.7213 - val_loss: 187.4131\n",
      "Epoch 134/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3914.5671 - val_loss: 154.9372\n",
      "Epoch 135/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3787.7200 - val_loss: 87.3531\n",
      "Epoch 136/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3792.1922 - val_loss: 76.5319\n",
      "Epoch 137/250\n",
      "7654/7654 [==============================] - 3s 328us/step - loss: 3793.6091 - val_loss: 131.4313\n",
      "Epoch 138/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3740.9774 - val_loss: 114.5371\n",
      "Epoch 139/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7654/7654 [==============================] - 2s 296us/step - loss: 3748.5576 - val_loss: 134.6143\n",
      "Epoch 140/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3677.8480 - val_loss: 140.7604\n",
      "Epoch 141/250\n",
      "7654/7654 [==============================] - 2s 305us/step - loss: 3711.7522 - val_loss: 137.8581\n",
      "Epoch 142/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3681.5148 - val_loss: 143.5897\n",
      "Epoch 143/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3661.8885 - val_loss: 92.8462\n",
      "Epoch 144/250\n",
      "7654/7654 [==============================] - 2s 323us/step - loss: 3784.1708 - val_loss: 104.4726\n",
      "Epoch 145/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3688.7291 - val_loss: 117.6290\n",
      "Epoch 146/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3758.4381 - val_loss: 120.3471\n",
      "Epoch 147/250\n",
      "7654/7654 [==============================] - 2s 300us/step - loss: 3663.9366 - val_loss: 138.7843\n",
      "Epoch 148/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3680.2269 - val_loss: 138.4433\n",
      "Epoch 149/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3700.2814 - val_loss: 76.0913\n",
      "Epoch 150/250\n",
      "7654/7654 [==============================] - 2s 316us/step - loss: 3634.9185 - val_loss: 134.8598\n",
      "Epoch 151/250\n",
      "7654/7654 [==============================] - 3s 335us/step - loss: 3602.2846 - val_loss: 148.7191\n",
      "Epoch 152/250\n",
      "7654/7654 [==============================] - 2s 309us/step - loss: 3575.8241 - val_loss: 172.5250\n",
      "Epoch 153/250\n",
      "7654/7654 [==============================] - 2s 307us/step - loss: 3603.1813 - val_loss: 92.2889\n",
      "Epoch 154/250\n",
      "7654/7654 [==============================] - 2s 308us/step - loss: 3575.8274 - val_loss: 152.5780\n",
      "Epoch 155/250\n",
      "7654/7654 [==============================] - 2s 307us/step - loss: 3579.1377 - val_loss: 94.6787\n",
      "Epoch 156/250\n",
      "7654/7654 [==============================] - 2s 308us/step - loss: 3624.7414 - val_loss: 130.5954\n",
      "Epoch 157/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 3575.9413 - val_loss: 144.2896\n",
      "Epoch 158/250\n",
      "7654/7654 [==============================] - 2s 322us/step - loss: 3638.9379 - val_loss: 100.3247\n",
      "Epoch 159/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3630.4265 - val_loss: 147.0757\n",
      "Epoch 160/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3539.1405 - val_loss: 118.3774\n",
      "Epoch 161/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 3569.3736 - val_loss: 122.4628\n",
      "Epoch 162/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3512.6765 - val_loss: 96.7152\n",
      "Epoch 163/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3588.8830 - val_loss: 152.2384\n",
      "Epoch 164/250\n",
      "7654/7654 [==============================] - 2s 313us/step - loss: 3494.6825 - val_loss: 133.8423\n",
      "Epoch 165/250\n",
      "7654/7654 [==============================] - 2s 312us/step - loss: 3497.4080 - val_loss: 150.0943\n",
      "Epoch 166/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3545.6908 - val_loss: 86.7259\n",
      "Epoch 167/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3507.9394 - val_loss: 142.9125\n",
      "Epoch 168/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3546.2754 - val_loss: 101.7932\n",
      "Epoch 169/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 3439.6787 - val_loss: 116.1454\n",
      "Epoch 170/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3421.2894 - val_loss: 111.3988\n",
      "Epoch 171/250\n",
      "7654/7654 [==============================] - 2s 315us/step - loss: 3503.4546 - val_loss: 145.8899\n",
      "Epoch 172/250\n",
      "7654/7654 [==============================] - 2s 301us/step - loss: 3393.6304 - val_loss: 184.7154\n",
      "Epoch 173/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3443.3636 - val_loss: 118.9634\n",
      "Epoch 174/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3379.5645 - val_loss: 158.4506\n",
      "Epoch 175/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3413.6659 - val_loss: 151.2362\n",
      "Epoch 176/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3414.4482 - val_loss: 112.5015\n",
      "Epoch 177/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3372.5247 - val_loss: 96.4121\n",
      "Epoch 178/250\n",
      "7654/7654 [==============================] - 2s 321us/step - loss: 3441.6706 - val_loss: 97.0352\n",
      "Epoch 179/250\n",
      "7654/7654 [==============================] - 2s 303us/step - loss: 3441.2097 - val_loss: 122.6057\n",
      "Epoch 180/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 3356.0586 - val_loss: 134.8554\n",
      "Epoch 181/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3324.4019 - val_loss: 125.6476\n",
      "Epoch 182/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3324.7653 - val_loss: 97.2777\n",
      "Epoch 183/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 3352.0787 - val_loss: 99.2360\n",
      "Epoch 184/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3377.6545 - val_loss: 166.1703\n",
      "Epoch 185/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 3498.2823 - val_loss: 170.9156\n",
      "Epoch 186/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 3334.8149 - val_loss: 162.1917\n",
      "Epoch 187/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 3192.9676 - val_loss: 92.2062\n",
      "Epoch 188/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 3359.0429 - val_loss: 164.9603\n",
      "Epoch 189/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3299.3532 - val_loss: 92.7588\n",
      "Epoch 190/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3359.8609 - val_loss: 109.2500\n",
      "Epoch 191/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3268.1987 - val_loss: 128.7609\n",
      "Epoch 192/250\n",
      "7654/7654 [==============================] - 2s 320us/step - loss: 3297.3772 - val_loss: 100.4898\n",
      "Epoch 193/250\n",
      "7654/7654 [==============================] - 2s 299us/step - loss: 3215.8934 - val_loss: 88.9913\n",
      "Epoch 194/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3270.5144 - val_loss: 93.0102\n",
      "Epoch 195/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3229.9240 - val_loss: 106.7757\n",
      "Epoch 196/250\n",
      "7654/7654 [==============================] - 2s 301us/step - loss: 3178.2039 - val_loss: 108.7662\n",
      "Epoch 197/250\n",
      "7654/7654 [==============================] - 2s 308us/step - loss: 3227.7673 - val_loss: 120.6528\n",
      "Epoch 198/250\n",
      "7654/7654 [==============================] - 2s 307us/step - loss: 3216.4148 - val_loss: 137.9667\n",
      "Epoch 199/250\n",
      "7654/7654 [==============================] - 3s 342us/step - loss: 3190.5794 - val_loss: 114.4717\n",
      "Epoch 200/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3152.5329 - val_loss: 100.5656\n",
      "Epoch 201/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3227.0494 - val_loss: 121.2604\n",
      "Epoch 202/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 3157.3867 - val_loss: 122.8288\n",
      "Epoch 203/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3138.9971 - val_loss: 99.2029\n",
      "Epoch 204/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 3220.2274 - val_loss: 55.2252\n",
      "Epoch 205/250\n",
      "7654/7654 [==============================] - 2s 289us/step - loss: 3111.5972 - val_loss: 121.8024\n",
      "Epoch 206/250\n",
      "7654/7654 [==============================] - 3s 329us/step - loss: 3089.5046 - val_loss: 99.3929\n",
      "Epoch 207/250\n",
      "7654/7654 [==============================] - 2s 291us/step - loss: 3103.5619 - val_loss: 118.0315\n",
      "Epoch 208/250\n",
      "7654/7654 [==============================] - 2s 291us/step - loss: 3177.0970 - val_loss: 136.2522\n",
      "Epoch 209/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3120.9496 - val_loss: 77.4652\n",
      "Epoch 210/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3109.8840 - val_loss: 80.3598\n",
      "Epoch 211/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3053.8832 - val_loss: 118.3912\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7654/7654 [==============================] - 2s 294us/step - loss: 3121.6010 - val_loss: 97.2600\n",
      "Epoch 213/250\n",
      "7654/7654 [==============================] - 2s 324us/step - loss: 3059.4319 - val_loss: 119.3813\n",
      "Epoch 214/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 3060.5919 - val_loss: 76.1735\n",
      "Epoch 215/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3082.3005 - val_loss: 151.1299\n",
      "Epoch 216/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2993.4486 - val_loss: 174.9949\n",
      "Epoch 217/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 2984.9598 - val_loss: 101.1841\n",
      "Epoch 218/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3118.6982 - val_loss: 156.0389\n",
      "Epoch 219/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3051.0407 - val_loss: 135.9813\n",
      "Epoch 220/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 3008.7227 - val_loss: 86.7188\n",
      "Epoch 221/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2997.6229 - val_loss: 129.3723\n",
      "Epoch 222/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 2995.7200 - val_loss: 101.8215\n",
      "Epoch 223/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 3018.4096 - val_loss: 105.1907\n",
      "Epoch 224/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2990.2637 - val_loss: 105.4307\n",
      "Epoch 225/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 2886.8235 - val_loss: 114.3453\n",
      "Epoch 226/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 3004.6885 - val_loss: 116.9160\n",
      "Epoch 227/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 2960.2971 - val_loss: 131.9691\n",
      "Epoch 228/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2974.1760 - val_loss: 130.9487\n",
      "Epoch 229/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 2871.7859 - val_loss: 64.3253\n",
      "Epoch 230/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2870.0241 - val_loss: 90.0709\n",
      "Epoch 231/250\n",
      "7654/7654 [==============================] - 2s 292us/step - loss: 2888.6348 - val_loss: 108.2496\n",
      "Epoch 232/250\n",
      "7654/7654 [==============================] - 2s 294us/step - loss: 2944.1213 - val_loss: 83.3902\n",
      "Epoch 233/250\n",
      "7654/7654 [==============================] - 2s 297us/step - loss: 2924.7072 - val_loss: 87.4022\n",
      "Epoch 234/250\n",
      "7654/7654 [==============================] - 2s 325us/step - loss: 2843.3867 - val_loss: 119.2648\n",
      "Epoch 235/250\n",
      "7654/7654 [==============================] - 2s 304us/step - loss: 2882.8299 - val_loss: 159.6474\n",
      "Epoch 236/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 2874.0576 - val_loss: 101.5438\n",
      "Epoch 237/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 2879.2980 - val_loss: 83.2331\n",
      "Epoch 238/250\n",
      "7654/7654 [==============================] - 2s 293us/step - loss: 2840.8496 - val_loss: 151.9781\n",
      "Epoch 239/250\n",
      "7654/7654 [==============================] - 2s 296us/step - loss: 2897.9236 - val_loss: 111.1451\n",
      "Epoch 240/250\n",
      "7654/7654 [==============================] - 2s 308us/step - loss: 2850.4629 - val_loss: 99.2798\n",
      "Epoch 241/250\n",
      "7654/7654 [==============================] - 3s 345us/step - loss: 2826.5264 - val_loss: 155.4520\n",
      "Epoch 242/250\n",
      "7654/7654 [==============================] - 2s 311us/step - loss: 2877.8815 - val_loss: 120.5076\n",
      "Epoch 243/250\n",
      "7654/7654 [==============================] - 2s 309us/step - loss: 2744.2950 - val_loss: 105.5529\n",
      "Epoch 244/250\n",
      "7654/7654 [==============================] - 2s 311us/step - loss: 2774.7807 - val_loss: 99.7001\n",
      "Epoch 245/250\n",
      "7654/7654 [==============================] - 2s 310us/step - loss: 2810.0415 - val_loss: 123.6289\n",
      "Epoch 246/250\n",
      "7654/7654 [==============================] - 2s 307us/step - loss: 2750.3855 - val_loss: 94.5810\n",
      "Epoch 247/250\n",
      "7654/7654 [==============================] - 2s 302us/step - loss: 2746.2439 - val_loss: 105.8818\n",
      "Epoch 248/250\n",
      "7654/7654 [==============================] - 2s 318us/step - loss: 2776.4667 - val_loss: 98.5886\n",
      "Epoch 249/250\n",
      "7654/7654 [==============================] - 2s 295us/step - loss: 2748.8191 - val_loss: 77.9107\n",
      "Epoch 250/250\n",
      "7654/7654 [==============================] - 2s 298us/step - loss: 2745.2325 - val_loss: 103.9736\n"
     ]
    }
   ],
   "source": [
    "# Parametres\n",
    "verbose, epochs, batch_size = 1, 250, 5\n",
    "# initialize the model object\n",
    "clf_cnn = CNN_net()\n",
    "# fit network #Train the model using tensorboard instance in the callbacks\n",
    "history = clf_cnn.fit(x_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs, verbose=verbose, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7654/7654 [==============================] - 0s 21us/step\n",
      " Model.evaluate :  104.22526198826479 \n",
      "\n",
      "Mean Squa Error : 103.97355503014487\n",
      "Mean Abso Error : 8.931542982781071\n",
      "Expl. Variance  : 0.8943818722069423\n"
     ]
    }
   ],
   "source": [
    "ypred = clf_cnn.predict(x_test)\n",
    "\n",
    "print(\" Model.evaluate : \",clf_cnn.evaluate(x_train, y_train),'\\n')\n",
    "\n",
    "#evaluate results\n",
    "mse=sklearn.metrics.mean_squared_error(y_test,ypred)\n",
    "mabs=sklearn.metrics.mean_absolute_error(y_test,ypred)\n",
    "exvar=sklearn.metrics.explained_variance_score(y_test,ypred)   \n",
    "print('Mean Squa Error :',mse)\n",
    "print('Mean Abso Error :',mabs)\n",
    "print('Expl. Variance  :',exvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 2, 64)             256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOx9eZgUxd3/p2Z2YbmvZUFYDo8IHhxyKMuhojFqvCJqwKgxHjHRJK9vEpO8/vIajTmNb+JtjBrjrcT7Nl6AnAooCHKJgrAsC8siy7HA7kx/f39U13R1dfU5PTuzy3yeZ5+d6amuqq6u+t71LUZEKKKIIooo4sBFIt8dKKKIIoooIr8oMoIiiiiiiAMcRUZQRBFFFHGAo8gIiiiiiCIOcBQZQRFFFFHEAY6SfHcAAMrLy2nw4MH57kYRRRRRRKvC4sWLtxFR72zrKQhGMHjwYCxatCjf3SiiiCKKaFVgjH0ZRz1F01ARRRRRxAGOIiMooogiijjAUWQERRRRRBEHOArCR1BEEUW0PTQ3N6O6uhr79u3Ld1daPcrKylBZWYnS0tKc1F9kBEUUUUROUF1djS5dumDw4MFgjOW7O60WRIT6+npUV1fj4IMPzkkbRdNQEUUUkRPs27cPvXr1KjKBLMEYQ69evXKqWRUZQRGBYBjAli1AMVlt60U+3mGRCcSDXI9jkREU4QvDACZPBiorgRNP5N+LaF0ovsPCAxHQ3FwYwlWRERThi7o6YN48IJXi/+vq8t2jIsKi+A7jQefOnQEANTU1OP/88z3L3n777WhsbNT+RgSsXg188gn/L5jBzJkzceaZZ8ba5yAoMoIifFFRAYwfD5SU8P8VFfnuURFhEfc7bEumwnQ6Hfqefv364dlnn/Us48UIUilgzx4+fnv28O/5RJERFOELxoAZM4DqamDmTP69iNaFON9hazIzrV+/HkOHDsWll16K4cOH4/zzz0djYyMGDx6Mm2++GRMnTsQzzzyDzz//HKeddhpGjx6NSZMmYdWqVQCAdevWoaqqCmPHjsUNN9xgq/foo48GwBnJddddh2HDhmH48OG46667cOedd6KmpgaTJ0/G5MmTAQBvvfUWqqqqMGrUKHznOxcA2A3GgI8+ehPDhg3FxIkT8fzzz7f4GAHgoUn5/hs9ejQVUUQRROk0UW0tkWHkuyfuqK0lKikhAvj/2lp9uRUrVrRsxzRYt24dAaA5c+YQEdFll11Gt956Kw0aNIhuueWWTLmTTjqJ1qxZQ0RECxYsoMmTJxMR0VlnnUWPPPIIERHdfffd1KlTp0y9Rx11FBER3XvvvTRlyhRqbm4mIqL6+noiIho0aBDV1dUREVFdXR1NmjSJdu/eTUREf/7zn+mmm35LO3fupcrKSlqzZg0ZhkEXXHABnXHGGdpn0Y0ngEUUAw0u7iMooogCgZC0583j5psZM4BEAerswswk+hnYzHTaacC2bfF1pLwcePNN32IDBgzAhAkTAAAXX3wx7rzzTgDA1KlTAQC7d+/GvHnzcMEFF2Tu2b9/PwBg7ty5eO655wAAl1xyCX71q1856n/nnXfwwx/+ECUlnJz27NnTUWbBggVYsWJFph9NTU2oqqrC55+vwsEHH4yvfe1rmf7df//9wZ4/RhQZQZ5hGNxxV1FRNLkc6NA5dPv0yXevnBBmptDzNgDRzgXU0EvxvVOnTgAAwzDQvXt3LFmyJND9KogoUJlTTjkFTz31lO36kiVLCiLEtgDljQMHrcnWWkTu0Zqc8okEZ1IFQMN8sWHDBsyfPx8A8NRTT2HixIm237t27YqDDz4YzzzzDABOtJcuXQoAmDBhAp5++mkAwBNPPKGt/xvf+Abuu+8+pEyP7/bt2wEAXbp0wa5duwAA48aNw9y5c7F27VoAQGNjI9asWYOhQ4di3bp1+PzzzzP9yweKjCCPKIb0FSGj6JTPDY444gg88sgjGD58OLZv346rr77aUeaJJ57AP//5T4wYMQJHHXUUXnrpJQDAHXfcgXvuuQdjx45FQ0ODtv4rr7wSAwcOxPDhwzFixAg8+eSTAICrrroKp59+OiZPnozevXvj4YcfxoUXXojhw4dj3LhxWLVqFcrKynD//ffjjDPOwMSJEzFo0KDcDYQHGBVA/NeYMWPoQDyYhohrAsLWeiAv/qKJjKMtjcPKlStxxBFH5LUP69evx5lnnonly5fntR9xQDeejLHFRDQm27qLGkEeUZQAOYomMo7iOBSRLwRmBIyxJGPsY8bYq+b3kxhjHzHGljPGHmGMlZjXGWPsTsbYWsbYJ4yxUbnqfFtAa7K15gp+JrK2tHnJC0VTYfwYPHhwm9AGco0wGsG1AFYCAGMsAeARANOI6GgAXwK41Cx3OoCvmX9XAfh7bL0tIIQhTgcKIYsKLydpW5OSveaCOg7l5cV5U0TLIBAjYIxVAjgDwIPmpV4A9hPRGvP72wDOMz+fA+BRc7/DAgDdGWMHxdjnvCMMcQpSNiqjaCsMxstE1pakZL+5II/De+8BJ53Udhhga0MhJYRrCQTVCG4H8EsAYjpuA1DKGBNOivMBDDA/9wewUbq32rzW6uBGaMMQJ7ns3LnA1q3ONqJIvG1NUnYzkbWmkEoZurkTZN6Icdi2re0wwNYGt4RwbRm+jIAxdiaArUS0WFwztzZPA3AbY+xDALsAiLRJOmu3YygZY1cxxhYxxhbV5WiWZyMxexHaMMSpogKoqrLq/Pa3gc2brT5FlXjbkqTsBS9tQbzfdLqwNCO3ueM2b3TzNMgc85rfbUVbzAcKLSFci8AvBwWAP4FL9esB1AJoBPC4UuYbAP5tfv4HgAul31YDOMirjWxyDam5WcT3VIro+ON5LpTjj+fXw8Avn0o6TVRTQ7R5s39emJoaqy5Rn+iTYdj7GTTHTNT7CgXZ5tRJp/lzJ5NE3bpFf8+5gG7uyPNSna9u89RrjPzuU3/LRw6jQsg1JMMwiJqa9GNw+umn01dffZUpt3Il0aJF/L8of8MNN9Dbb78dqe0ZM2a45hAKilzmGgpXGDgRwKvm5wrzf3sA7wI4yfx+BoA3wDWDcQA+9Ks3KiNQJ3xzs/V93LhgibHc4Edo3RaibsGJupJJIsacfZLvCbNgoy7ufCc28yJiQSETW5nBhn3PuYA6d7yEkqAJ3FR43af+VlOT/XhHmTOFxAjciLthGJTWDIgX04iCtswIbgWPIloN4L+lMgzAPQA+B7AMwBi/eqMyAnXCL1tmfU8miaqqspOYvSa/m9TnJaVt3hyNucSJuNuIQiCiEj8ZMnOVNYKWZG5+Erv4zet5c6ERqr9t3pzdeIedM+LZC4UR/PWvf6UjjzyKDjnkKPrpT2+jl19eR0OGDKWrr76aRo4cSevXr7dlCr355ptpyJAh9PWvf52mTZtGt956KxERXXrppfTMM88QEc8s+pvf/IaOOeYYOvroo2nlypVERPTBBx9QVVUVjRw5kqqqqmjVqlVE1MYYQa7+ojICdcKrE1ZVw+OEbiEGIXBhmUvciLMNPwLh9qxxmbXczC0tgTDEMYh2GbdmJ/+W7XiHmTPyuLz33oq8a6uLFi2io48+mnbt2k2LFu2iQw45kp577iNijNH8+fMz5QQjWLhwIY0YMYIaGxtp586ddNhhh7kygttuu5MMg+iee+6hK664goiIGhoaMumo3377bZoyZQoRFT4jaNXZR3VZENXvucreqGsrSHpeERWiQ+T0viEQZxte2TK9UipHzl6pQB7Lls7SqYsG69tXX9bveXVzIkiqCa+5pP6WzXiHmTPyuOzfz/+XlgZrJxdpuOfMmYNzzz0XnTt3wqhRwNSpU7Bx42wMGjQI48aN05Y/55xz0KFDBwDAWWed5ShDZmjpkCFTsHo1MGrU6MyBMg0NDbj00kvx2WefgTGG5ubm7B6ghdDqU0yoYYctuVNXbSvblBEtkXIizja8Ilv8oppay45qt+gbORosnQamTvUO4VWf1y/iJ+7Q4GzGO8yckedE+/b8f1DkIhKOpAFmDEgm+X+RgtqrvBtSKf7eSkvbm9FFSTQ3p0AE3HDDDZg8eTKWL1+OV155Bfv27cv+IVoArZ4RFBrCLjiVIHjdbxg89LS2NruwwGyIgtxfLwKhYxLqsxb6RjovgswYIGcMnj2b9ynbeoHCDA0OOmfkOdG3b7g5ps6ZHj2iv2MhtU+adDxefPFFNDY2Ys+ePXjhhRcwadIk1/smTpyYIeC7d+/Ga6+95ihTUsKfizMUYNMmYPduvuegoaEB/fvzbVP/+tfDmb4UOoqMIATiJkBhdyifeCLQrx//y8cmMl1/3QiEyiSI+L39+/NF3tyc3UY6UU+Ec8cDw48gJ5PWZ8EY46i3NaWa0K0JL5MV4L5rV8yZjRuB++4Dli2LtqGLpA1hnTqNwqWXfg/HHnssjjvuOFx55ZXo0aOH671jx47F2WefjREjRmDKlCkYM2YMunXr5uhnaSlw5JHAoYcCe/fy63v2AD/72S9x/fXXY8KECdi6NY2mplayKS0OR0O2f63hzOJcRPSEccLV1vIImXyGSmbjaFb7P3p09LBJuZ6qqtztHfBzshoG0aRJvD+TJsW7BySu/TBhETZ82atvOuemWxinjKYm/vvChfx/U1O4Z8j2/l27dhER0Z49e2j06NG0ePFi17Juz5NtH3TIpbO4qBG4QJV0cqGuh92hPH48/8xYy6ZbEGPRu3f0dA/l5cDIkdb3JUuAsWPD11VRwe8TWLjQ+11ko8URAU8/zSVUnW2cMX590yZg1qzgGkEYm3tLmonC+ib80qfoEGTXbkkJN7kI00sYP0OU+1UN5aqrrsLIkSMxatQonHfeeRg1yj2BMmPAkCHA8OH8v3iX2T5DiyMObpLtX6FpBDpJJ1c7ecNKYEF3M0dtQ3evumkvbF2ijkSCqEuX7MN7U6lge0Sy0eJaYk9HkLYnTWq5HeRhNT6hEQF8o6Q6TlE1AlHOb0OXV5mgG8KC9idMnV7ls9moVtxH4IFc7JLV7cysreUvcOlS/j2O9lpih2+2BC3bvRFqHckk3/iX7TMHGTu3vmdzb0vAbf7lep9EUGFHHj85fYo6TitWrCBDU0lcBDUoAfdCUBOO2t7+/eHbzKbPhmEUTUNuyFUGTtlkU1UFTJvGnZPl5cCIEfxz2PZ0ETMtkT00W9OCn/kqyHPIdUyYABx1VPZho35RLIbBx1oXuRRk3OPIehrVLKW23bdvsIidbJPwBTFZqePnNU5lZWWor6/nEqfSTmlpsDlApM8EGjUxnGoGEiYcAOjY0UpYokJub/fuaI7s6H0m1NfXo6ysLHhjIdGqzyzesoVPyFSKv9ANGziBiOO8V7GhhwgYMMD50kpK+IIJspFJt1Gmrs7ed1FX3GfWEmV/LrJXn9R3oI6JuLe8nKdWdnuuoM8dpJw83lVVwPTpViijX3/lOrZssTYlRhmzbDZHhZ0Hor25c4HOnTmhiWtTlgzd+PXure9rc3Mzqqurs4qlT6d5GwKVlVa0Vm0t37TWvr37Zj4ZRLz/4h7xXuXrgP03GaI9GXJ/vNoVEXZy+0H6LFBWVobKykqUKrvz4jqzOO9mIcrCNCSrsqotNS6brpzTpmtXstlDg6p2OjODTg3PlV06iClEVybIfV6RM0Gfp7nZbvN3Kxe0vmxz+8SdFC9O05Jbtt1Nm5xJ+JJJ7k+Ks72ovrKoZlCv9sLW6fZOgkbk1dQ4I9bU96D2RZ3bUXxsXkDRR8AhHKiffJJ9Yi23DKByKF8UZ608mS8c+xkZacPRJlFw4hG3b8EtbXGQ9Mhe5YL6F8aN81+EQesjyj63T9xJ8caNi4epu2XblYUUwCmwRG07TIbdKPX43RMlI68X3OaFzumta1d9p4Kou4X4hpnbUVFkBCbEJMsmC6VXlEbcUjkBRGZGQhUtJa2q0BE+L0er3L6XszDI89TW8mginZQVdnyiEA9dubgixIJoOmGInFe2XVkLWLIkHm3EiyFG7XcQLSWXEVtu/VYj8tzenW5/h1vKe92el7gd/kVGYCKOiBS1jpxGiwBEHul5W0JaVaEjfG7EUG1fpNZWJd+gmUFTKc7AAR5aaiZudIXXQpaZeZDIrqBaT1T4vauwBE81hYpzBlQhqLnZGtNu3fgYR4HbHIjSb68wUxX5jNgiCibJqzRDF87sphXGqdEXGYGJOKQ3L19D0Pj+wC8WoPTyFZEnQlCtIaxPoLmZM1F5ssq2f3Fd177ODhqUUMS16OV6RF0tSXC8NAs381CU9oXkqjIEmeHKkmgyGf9zBdUUZGFg6dLgzxqXRhYVQSR51TfmJvDozMxxajtFRiDBS0oMSnCj2iSDvFhbfQBdPHqFg8CGgZ8/I0h/dLZm+Z4wi102Uagmi5Za9DLR1Z0Cl23bfiYFtzH3Mg+FfXbRB7+DZqKMaZg5H0RTEAKV0FbCmm7DBi/EKWUH8e9EJehxaztFRiDBbdLILzOqeuyHIOr/Bceuz0wYAmgIVmakjZqa6G3rJmOQieZlaxb3hPFX6M4NjkLgsl3E6bT/KXBR2vZymroyn5dfJqJg88OrfZ1N2k1rle3cYXZtuwULBOmX3LZ6QqDOfxF1M6GfGS+qlB1ViAzr9xCIW9tpcUYAIAngY1hHVZ4M4CMASwDMAXCYeb09gOkA1gL4AMBgv7rjcBark0Cn3sXpdBLwe7HCQSwIAQE01GQEjGUX3qcjMrr+uEU/+BHusItBXuRxSmhhEXfbbsTczRwlND+i7Ba+/F5Uh6S621iY8qJEC6nPF/aMY5khdu2q1wiyJXxeDFXXf3Vs/PxKYRlIWL+H2m6r9REA+BmAJyVGsAbAEebnawA8LH2+z/w8DcB0v7rjchbLE8QwnA6fXG3V93qxgijIGsHFY1ZGVtvlz14qulzeTZoNsli8kCtbbhQfRy7h9pyqb8kWVmwygmz6GsQhKZeNmp1Wfb6wZxyrDFGYPeXwymzflddc8/LxySG2qmUgWzONV8RcS6FFGQGASgDvAjhJYgSrARxnfr4ewB/Nz/8BUGV+LgGwDeYOZre/WJ3F48YR/fGPRGRPThYkLDRO4iLU9E2biAiwiARA6U9XRlLbdc/g59vwktqDPkcYE0G2CMK4wkhycTA8r/tc65MYQdS61bktCKqOsMoSKhB+70IQAcMNUfwzYSCbx/x8BCoTW7bM3TKQrSATh48pW7Q0I3gWwGgAJ0qMYBKAegDVAFYA6GpeXw6gUrr3cwDlmjqvArAIwKKBAwdmNRi2QU4kyLjscgdx3LzZHkmhUx/j8inIajrMYT5p4n5Kpwx+wWUfgQ4qIfdy4OqIo7xIhdMu6PPFHeEQBDopTe1HUEksiFM8Z1AZwerVRDt3+vbRj7n72cqrqy0zUjbPGJZwBfHPBHUAq76OMO9MZ/b0CgUN85x+/c+FCcoPLcYIAJwJ4F7zs8wInpc0gl8AeND8/KmGEfTyaiOuNNTpNJGRSNCrfS53DLocr961KyfUqpM1qE/BT0JR6xIftj/9n0CMwE068wptdXNeiUX1ySfhfSbZqs5xmZvUfgR1CPs5xXOa1VNlBADRTTf59tHPPu/3Tvzs5blGGGLodk22vbtt1vJqV+2DW9rysEzA6714/R53pJCMlmQEfzKl/vUAagE0AngNwOdSmYEAVpifW9Q0JCBeRAoJ+icu93Ts6SRrnU9B98JkzUGNlBFQ1XTxwXjqaV9GEFZC1LUpnFeyBDxxItGoUf7Pp9YZxYns9hxBoVvI6gapIH3wcor7mdkyeOUVosrK8P0OyAjC2uf9zBFegoOXYBMldYpbXW7CkfpcbtdkgUVosF6nwAWZa2E0Kx3CMGDVBJsrXxpRCzICW2FTI5AI/OHm9SsAPGd+/pHiLP63X71xMALxIlJI0IO43DHoQSTrIAeeqI4xN9u76iOw/amMwDAyIrzXhPMjfqrJRE1BoB4ME0UdFhKb3z6IOKUgmTiE3SDl5iNQCa6rJH7HHURAaMYXlBGofQwyB4P6bbyYiqzVRo1+cRsDnflRRwzdrsn9mTTJqb2riDLXwt4j+ppIcIFKfjbZLKYTEONktCryygjMz+cCWAZgKYCZAA4xr5cBeAY8fPRDcd3rLw5GIF5UCtw0pBv0oPY8r0Wms7nrXrytDj9G8NZbGcLhFokSRIJRF5bYzCQ78bI9GKamxv4obvsg4pSCciFReUni8hilb+eMwMskoCO6Okaw67qbAjETQWz80m2EfUadNCyk7SCaot/a8DOvRvERBIlgijI/gp5yJ2P/fi5ICc20udmpZao7qOU0III5xuk4zgsjyNVf3D4C47LLcxodIktTOruzg2CrjGD1anvlL79sIxxiIRx/PNFr7Jv00MAbQzlIRd/EBDzuOLtUFdUxRsQXpmAqfvsg4pzwfn6ZbOqUpVOVse+4mTMCPwe9qmWq75MAupH91tNRH8ZPFfS5dO9ANWMIk6hXevWggkjc2TaDEvko9v6wgSHLltmX8bJl/v4rOUgF4O3F6TguMgI3mIwgymC7TXavRaBKFloJJiQjILIm2FfgxvHdV14bSurJxmno9bz5DJkL4rDLpr102snYG35n1whkqVotW10t5WuS3qeYAzfgt54EPg5CGkVzDJJePagpJYqkHeSZ4pxHXvZ8v37Ivqp0Wr8e0s1pqt1sZAQM+Z3GndSyyAjckEhQ47TLIg2222R3u66TLLSE0o8RvPSSgxGIegQjMPr1yxCYIJNWt9iDLia/Re+1MFWNJC7Jx69fURyGOjjen2ka2rJ8KxkrVtrakrUHL41AzAHBCOIkpOozBSXYYYlrPgWAMAjzjr0CPtygJmfUtvmd7xB997uZ3732M2U7RkVG4IZEgozvXRZpsN0mu9t1Lwbh6SMIwAhEPemunBGkDuqvj0bxQFSiHNrmWl+faU+2Pctjs3XxhtD91kXEfHvsF9p+BWFeQcfA1v7ttxMBtOeiKzNjr5Mog/gI/jHg5lgJqe6Z4vanBPGr0RNPZNdIFn1Sr4d5x2pupGxPc8tg5EiiY4917XOcZs4iI3BDIkF0eW59BAKBF11ERkBEZJjHTW1Ef300SgBEiaoINX4AUW2tg0DKkq3a76CL2XG0n0sEj9+7CDMGtkV7G2cEDzLOCNyIrXpNxwjSv73Z2XfD0G4084JfVFBcEnlgwmo+a+B2XYzyrvc3N2fO8ND1KUiUlA5qhFJcmqsxciQ1jRwbKDAgW425yAjckEgQXXaZ7VKUhRFGKvMtpzCCunlr7OU9GEG6Mw9T2IBKvaQZ4Dk2b/Y+V9hX4vN7ToBo2zZvc5TiPHVbBDpHpi1U1eP5vfoYxukol9txM2cE/8D3M0zIrS3bNdHPhx7iFwHa9cubne2+8IIrc/PrX9xmBrr3XtvXwMzTZJCBCZuL9ut6/4svZu7R+b68xsNvfYbJFxRkrafTRKs7H0MfYqzjOeT7owhnOhQZgRsURqAunKAnV+1n7WhY8tNI3NrPNDQ0ucaqN5WyTXQVhhmv9iUGhNYIZFu2yArp5gT32nzku8gBou3b9c8ulzHhZVKToy6OO84+dDU1+udPp4PFaQdZyGrfGn57GxFADzDOCAITW9FPgNIPP0oE0A2J3znH9qGHSXZGyxKuri0dIYwtRt3FT6VzlOu0NPWdBpkLbs9lI4zPPZe5R+2Tbj+ILNiEdZwHFRAIMDcJOZ/jIxxDH2CsY4e/KiTFwcSLjEBBZtKZpiEBeYKJyeJH3EWUx2S8G5pb60wbKiM4DGusegGi++8nIVU5Fo7JCFL9B2QkzaDSoyztyM+vc4J7RTP4Si8AbVm13V8rMqGNtNAw7JoaTaiqQkSam53hj9mo946+/Y0zgj0Xfz/TdmAt0Py/4+7HiAD6NX7nGL8ddz5CBNgImRfx0mldnqY0Cb79dmGy8j1a4moySHH9tPENRICz3IIFRE8+qW3HkyA/+6xt7NWTwcR9Z1TVh/Ib6Z7RbYxUzYGAzH4g+R7DIFrd6Rj6EGNs8zEUowyBIiOQIE/OFLizWECOEAi6qUoQ3K8n3g3NrXV2cjeNQLSTuu1O/cIhIurcmd83cGBm0QV1hslpLrp2dR6rF9TM4LVIRZ/Kk9sD2ZHl+2Qzim6haNtVTExyaJ7bgtcRs8z399/37tttnBHQ97+fYdZh7OYEkPEoZwRCI7CN7SOP2t7ppk125qfbsOdmYhDzTRcfH6jfErF10zK0xFVlkJtqMs9kK3fRRURlZVpG4Bh36dpXDz6bmSOyBvB3djXt+vmNlE4T1c1d7ag3rOPcbYzktSSIOwGUXrFKy7ibho2ihRjjP5djQJERSJAnZwo8fFRGOs0X2ITjmmkOJgQLGQOo/tn3/F/YrbcSXXhh5qv8wkXkjMoIbD4CgK4ru4uEVOggZhIjEItOpwbrxuTMxGsEcGuZ6IsuX3tUH4GIvCCAeqDe147sCkWi9DNDyM8oNuvsRkcC9IxKfV7bwn363959UxhBGLu5+C80gtqf/N453x59NFOvYXBCJ08Xv0gWdb65bUir3WzQ4OQG736bjM7LgSq3J3a+O7TU6mqHYGMYxMMqO3b0Hm8J4t1dkHgmw1jk+duY6JiZO/TJJw4hIWxkjtu7lbWBjLkHoIvGrNKm3jZGjaKVncf4z+UYUGQEJlS7cgp8Q5la5vjjiTolGjMTyrEgjj7a6ey78Ub/Dpx/PlH37o72hGkjY0+U/z77zCoM0DW4O0Pgk0mFmHXqxCf7oEGZCehn0yeynkFmSH4moDCQ/Q8EUO9kvbek48MIRJ2yhOlXj3HjTfSzYW9l+rBv/IlkVNvtturiVjeBfXV/OEYQJlJMaEsXs8eJAPrfxO+d7+qxx2ztp1J2B3kgQmYSYlVDkt+v8cmyzHxw7bdZj1/KCTG/5fdv00I2bMg8v63v06Zl5rNan5s5hjGi88Hf0Xl4hqYkns+sLdHJ448nSn+81DaPHGujpoboo488BtHdZKkyRrG2jkyuso2T+I0zgtFZnUseFEVGQC6OYE3UkCAGZeCMQLthR5FgMm/YDy6M4Jvj6imRMMOJfRjBz8ruIQKoa1eNM9tcODXtB2e0C6G2+xJ0iUAEMQF5QV2sYkzvw1VEAK2YU+9LrJJ1z9wAACAASURBVDIQuZauu44vTnWcAzICAsi4+hqLeQBEc+faiquLWyUSxnRvRpD+6994O9+/ysGwghBnAuhCPEEE0P/D753vSmIEMnMdN46oqYl/f4xdQo8P+FUgs5vrhjRznP18BLqQSj+ntazNVlURpb9Yrx/TqVMtDdeEl8lKaEeCESzBcFqYPDbDHEWjJSVE296zGIFWsv/hDwOt58y7/eWviLZtc5jeMhoaQFNHrsqsqcZvX5oZp6bho2kRRmctbAVBkRGQywtXGcFvf5shBkIj0DrUFE3BjRHYiEA6TXTeeQ5GULuQS0TdsT2zULwYQequeykjQaowGcEXGJypK7DNUaMqBwmp0z2zulhFamjxTKkt27wrUQh45v+tt/L/69YRffGFZ79tv+3axT//6EfWdYDqX5ptO8lLZICV7d22Ov/tZASyWeGuQzgjeKnvVdr5QO3bE9XVaZ9XSI4XMc4Ifp34g/NdSYygtpaoLNlEpdhv016+wGB6h53saYZy9YEI6Biuph5xv18kkux7kxlBSQnR1g/X6dv69re5s0r6zcvUJrSjqWx6hhF8gGPtWrspwBlLLdOQ3LfMSW0BGYFtLN5/37nOVq2m9O//QATQEYlVlhYk1W2MHk2rOo+K3R+g72Y8jCCBVoyKCmD8eKCkhP+vqDB/YMwqdOONIAKefBIYM4ZfOvlkoHdvezHAXlcGUiHDACZPBiorgRNPBKh9e+D11/l0lNBn7EAAQBLpQM+RTPL/CeltGAawZYtJ+gEQWKYrFRW8WzNmANXVwMyZVjet++xtJBJAnz68nPw5g6YmfrMGdXXAvHlAKsX/19UB27YBu3dbZerr3dv2RNocowsuAKZMsf1kGMBF4z7PjHeme5ddBnTpwj8rL3HKuYRevYD+/YGePYF+/fj7mjrV6pf2+aU2xTueOBFYv55f37LFpf/79wMNDdqfRP333Ms//OTH/J3Z2pW+VFQAz5dfhTfYNzF+PHDkkXwuEhi6dyNrfsv9TfOHOqHfZ/jmhAYYhsvz6R7WBYkEcNBBQN++/DbdexXzb9Mm/r2qylo75T318whEjn6INZxMAqNH87bSaWDzZuCkk4CFC4HDDuUNMwCduzjn18yZAIN1kTHg3XeBY4/l90+YABhh5qRUkWOdDR2CxP/+GgCwwhiKTxc2Yts25TYAhx/uXJsZPPEEcNFFETqUO7RqRiBe0o4rr8PMmaZ4AICUtz55MjBoEPDhh/z73LnA1q3O+p5+GtjXZxDee3Gn7bph8L/ly+0EkaVSwN69nBC4LDTt5epq4NRTHYXEgmtu5kSoshLYt08qZk52Uae64FVG5Ym6Ovv3Qw8F7rxTW7S8HBg71s5wKyr4AhPo1ZNsbbvwFMczZxiBSxefWniYjQEBAB5+2PUewyA0NAAnpN/F5zvLcT++j2G01H6/rbzVjS1b+LwQ7/jDD4H+/fiY9+nj/Tg6Yrmlln/p0pU/61138/djGxtpgjAGnHbklzhh0HrMnAkkkgwzZgADBzGMGmUWHTQIePBB4OGH+ZxcysdvlXE4vj7/ZtTWevczLNQ5JfddzD8AmDNHInwUnBEIoj12LPDBB5xxX9b1WbzY/xrMng2MS89Bt88/AgAccSS/Z8AA+/zWrbH6euCjD5qRTgMLFgAvvhjp8W3PSWnnc008rlnLoBnchQ3Mncsl0wJCq2YEAJCY8z463fdXEFmL7I037BN23jy+0MUaNQwuIYoy4v/AAYTkpg3Y9oWdESxbxifeiBGcQDCmaA0umDWDMhKTDWvXAm+95bh84ol8IfTsCcyfz9sSfSOwjFTjRmRVyV1AK6mrs7e6GlSz2VHOMLhk9uGHXKN67z3+/ESccQrU1zu1hkDwYASiiw6NTwLBvtJKEoRu3YDBbAPKUY/v40FUYYH2fsMAfvtb/rlXL07svv1tS0Lt0sWSeM88212iVollKsWvV1by/xs3mo9qMD42Xza61qUSy0QCKEkCTLyUDRv4wF92GSZPBsaNSdnG4rzzTC1h1y57vSE0Ahl1dZxupVL8v9t7tQklmglqGMC+vQYo4SQ59fVccheoanwXV9PfQQQ8iu/iF/SXzG+7dznntw4VFcA+o13mu07ws+F//sfZZyRs6yFRmnSUee115hxasUDcYP4WWnvOIVo9I8AJJwCwiCAAbNnK+IQ1R1mYfI4dy38nshMr8T+dtkvcAiNHArNnW98TCWD6dP+uff1kUq0depiLY/ZsvmBkk0syIam8JiurrdUT94oK4MzRm1GSpAyj8pLoAHCu+bOfAQCeespZrq4OOH/2tTgn/RwWLeImIVHnwIFWNb17u5jp/OChOoj34KpiA3jueWar4tl/G6ivB/72N+vaLbfo76+rA1av5p8bGjiBmT+f09klS4Dy3evRnbYDsGtmKrZt4+8uleL/V6zg18V8uv56/j2RACZUGehzSCfnQ4IPxZKPgXXrJIn3b38DGvWMY+Xc7VhLh2S+ExgWLQJ2Pv4y0LWre4cB4NFHLY6lwx/+ALz4IsrLgc6d+aXOnbl2aIPo/6GHWteUd2oYwLfHV2P3a7PQsNP5EoV5SKCdSb8nTQIGVlp1ffklNw05zLcaiG6NG2de8BGicMstjks//gnz1XBtcyrTGG/OjdALi8XV/V4Kpj23AAIzAsZYkjH2MWPsVfP7bMbYEvOvhjH2onmdMcbuZIytZYx9whgblavOyxCTicDQp8JuTxU2vhkz+HeVWGUkT5Ph9+6tb+MQfA4Cw4QJ/qYCABhmLMGCBc7rQSZVMgkcd5z1ncAyjGDKFKcEKmzYL3zQD7VvfIyZM/l3nX3fhjfeAG67DQCXftVyFRXAxSVP4VL2aGbM5DozfQfZbal7dnO/gx9kjYDI0oCkBeSqYoPbkuVn6tmDHALZgw+QdkFWVABDhvDP3bpZ86JvX+CoOf/A2vTB+F/8AQDQocz9EeT2iKz5U2Iy8TSZPoKfADPeszpiGMAOiTDW1QE7GwgEhnlzzXI//znc7D1fH7Ud/bBZ7gnGjwe6sZ3OwuoAXnqpt9r2u98Bzz+PbduAPXv4pT17LEHAQeS++IL/v/hixwSvqwOqPrwD5ahHc8r5Ihnjc6amhr/Pyy7j12fNspuZGvcAhx1mzbEgeP55/l5FVwNrquCWAF8NVx7XDz4AwNtiH3+Mgf3TmDK+FkajJEWcfDL2ml+fN74VTnvOIcJoBNcCWCm+ENEkIhpJRCMBzAfwvPnT6QC+Zv5dBeDvMfXVE8JfkEwQTjzRnKgm5xVqq9BKVQlT/N+4wdQIzpviqHvSJGDBK9wrNHPQdwNp2m/hVO11WeKXOzBpEp+0kybxPr74ovUMMiNYtMgixHPnAscfb/cL9OrabHMsOyR1F33UIMvsJZgjY0D3XkmcegplxkyuU4bNPDBihFbddiAlmzY4gwMC+hkA9O3HbEzfSHNfxc9+br2gn6+9WrvYGANuvJF/rq+3zwt29Q8dZd1QfspITJrEmfekSZyRANyKAwBJc971qXD6c350jfW9ogI4AbNAYJg4Xnl4zTt7/AmlU4xh+nSAJd2X9dY1O/SvX72YSgHJpGP+lJe7+6G2bAF3hCp1VVQAP6f/AwCUlOoHUnZQJ6R1mWBWXR07AaWlnNH6mnpM9O3L+52Q1kNQHD2MhddwAaRMZtchvQsvLDgIjb+9FYA5n997Dx3aW88Utu5cIRAjYIxVAjgDwIOa37oAOAmAcMecA+BRM7ppAYDujLGDYuqvK4SEYhjAU9MZ+vUDzpq0Q1vWTcLsU2G+INlgCS6pzJoF9K7gN7HHHgO6dw/UL5VYAlbAiwohUc+axSewzLwAoIupoo8fby3OsWN5d93sptroIhdG8Cv8JWP2kseHAWjfjmyMU9TpiupqTl39IFH7VIplniGopHT++XYbbcMOwrx5zigRnX9gyxbrOZP7Gz01Dy+w3bsxcybXqGbNsuro24d34t6/m/MmYVUutKq0ZIKTrSzvvePPBRNJe2f79jWfU2OHF8M8c+gP9IEE6uRJp4GSEsf82bYNWDp3N05K/cdxi/CJGKvW2K7LY9q9h90U5mUnNwzASFnjIKxPghEFgej/JZfozb5euOceb7OkW4UlpeZ/08LQKbE3w/gB4JVXrLKedbcggmoEtwP4JQDd7DwXwLtEJPTR/gA2Sr9Xm9dyiqn952DiRC45X4GHcBE9hr/PHxHoXp05QoYIo7NTHH3IoIrtv/ij41qmmrfftjWcSAB9dqwGa9qfKSfspQcfwrCtjpebNctanHPnuoS9SkgkgD7P3gO2vZ4vvlp3D5XW7KVxfskRI/IzuH53g2kaIgDr1lsKgiopCaKhonGvvanu3bh/JJGwry5ZEt+82SImN91kFuhk2e2j2GwZcxcwZOInICRt0U/5WUtKmDPyRjeeCsHfXMt4wIRmWX+1g7fTjvbrHa26SKxkEmAMia21mWerqAD+6/A38R+c5phv4t0lzuca9fLlzrFkZp8Ng2sU/ftzN59uzCdPBpK1Nda9AFLNTrMkAM/5lkgAHTtY3x0MyOXeRJL5Cwfqj+edlwlfEL4ixuw+zFpp/bUaZzFj7EwAW4losUuRCwE8Jd+iKeN4XMbYVYyxRYyxRXUxGMkOT6/AwoWWQ/VwrMEAcJGV1n9pKytPAplTnzTZ561EYN1d5r/tXo+YKbD6gqFDQY89nvnetJ/3afNme/ioTIiffppHpmTsprrZ9eMfw/hwEQ+lHUiZ+tVQ25nXvaqPgoiCnRpbtYI9uzgjSDVzG7CArJUYBnD98Nfw3EE/dtz/wAPMHkpIBmbMyLg9bJAd5++/z4mJcBYDlkYp5oMNSogvkZ0YjR+vCYAS70EzfkJSzWgLTPnRi0KIvpC93jRxjWrnbnNZv/NO5jdZgZV4nicowUVa2mlFIDEG3HQDf1DVTq9qv8OG8Qg4G9E2+76lljB7Nh+z2bMVJm8+u8qwmlNc2taZJYNCGzwhxlp4xZW++tW3dYW0keD55zPErne55TiSHeJyrYXgHwCCaQQTAJzNGFsP4GkAJzHGHgcAxlgvAMcCeE0qXw1ggPS9EkANFBDR/UQ0hojG9HbzzobAbfgpJkywhKSD+luhXs9N+FtmLwBgnwQyp14wX7/4QnFt2cObSAQjomYDggDd+hfK9E381riXOSaNHL0jb5hyw46mjmYorRW+9sIL9jLsL1L0BBEP1ZD6GBiMcSfH8uWexR66nxOVklKgUyfKLHBZ22iY/iYOWvEurqF7HPenSXKsmv1MJLjzV4UIhSwx9mMlhgLgG38EhG/JKzRR7O844QTuDxBYsIB/99Qm/vQn2zgmEh4WRrUiIsfnqdPsc6sb24VpI1ehWw9zEZxySua3HZKV1OGjcsFzL/GXcdHF9sishGkYYGm7WK6bIg0NwKpVUhmJu8umRt0yUTWOlSuAlSv5vgOHWTKgsLJihSZ4QnR8zx574QB1fvN0wsqjzrf3cxW/749Vlg1IMH4AOKivNVCF4B8AAjACIrqeiCqJaDCAaQDeI6KLzZ8vAPAqEcnBdS8D+K4ZPTQOQAMRbUaO0QmNpr2Nv4SNNRYjEJElgpDKk0Dm1FVV+rozkkOQySZ2rQFAMqmNm8aVV/L/Sn2CAE397HeZvokiZR0YKnrbI060kxrgK2/tWqvixx4DAPTo1wHjxwOlSUuzqN3sQeDnzwcGD9ZLqBddBHz8sfWd7H3LRAwNG+ZePwBGnBE0NwODB1kx9/LQ9PjO6ejTXy8CJhgwYbyTSKpjaxj8p+rkQJRhH4ZiNZJJ4IorrTLz5rnvERHViv0dc+c6XElYuFCR8NS+6DQk3ZwS23l1HZDbW2yfW9fQPXhs0RFaZ3HPnlbVYiOgkSZLO9bEtm/czMd88UeKECL6duaZtjZ0W0K6dQOGDrW+123jz/udCwkTJ1rBEYLxGwYXegCLcAoQ+D6C+nqN+VIdH2Vcxc8jR3KNyC14ws0E6Yb584H2sMcWiy0cv15zqe26IAVnfFMKCS8A/wCQ/T6CabCbhQDgdQBfAFgL4AEA12TZRmDIjtD+Ay1GcNBB5m5Yk5CWlADfHLPVlqoBAN59R08UM0RW5KgI0aGmZo83LcccwiJAg7Ah07dS0/E0cKBlGhKagHZSAzz+7vLLrXa++13enY4dMGMGsO4LXk+fPkBf1Y0vL6jm5sxziOuZhfLkkw5KKNvfPZ9XQgnjRKXd0kX4dAXD1Kn6W6dd5NzMAwCXfJfhvXclm6tLLoHJk/mO1L5NGzHWfI0TJgCVkveqqopHpMgb5QT27rV/79jRzjBKSvj9IgFOUAjzjnxPKs1AjXtd7kCGeoweo8wt4VCSqIvKi0491TLpnH++pB2bWqIcDSSY768qn0DFUsnEKRiBbFeD01yzbBl3Ll80YX3m2v4m3pEP5huYPt3ujBXz2pRbHASZge8j8JKi3ZzPYjgHpNdh924uw2QctRLTlR3RBjFfh/aY0ZTRkFzx5z/bNpDK/sZIaVlygFCMgIhmEtGZ0vcTiehNpQwR0Y+I6FAiGkZEi+LqbBhc+UOLcJx3nl39rK4GXlrQB9TUbIscYU5XBoDsQrzalQUYYnMWyBJQpk8kpHeLGO98/OXMbmnHpFbqtCGZRCIh2S4BfOscpSu6/plty/ZVwCIe4rMgtvLmOz989xKrjpFY4mqWYSV6RvDIowwnn2TVcf2vDK15RnYwPs5dMHjvPWtnMcAX5cSJ9o1yAh062onuvn32TYWLF/NhsqU/0O4mskufwlkt70jeuKYRSw7/tut9As88qzCCDtwjSrffnrl0+sRdNm22rL01TxYuYhltUsQ+yNFnF17Mx/zyL28Eu+7nwG9+4/5csLQ5gaOP5tL79A8PzlwrbcfXw/gq4pFx//oz2I28XmGmFbz86AH2gIwjjgSOOEIvRatmX/W3d0w+tg6HYMIE4KijpHqk55HnSf1XzDdly1tvAV062cejcxdNBz/7zPos7R4PlZYlh2j9O4tVmAOcUNRjmesKtfLrXw+WlydoiNdm1QDGWMZU5dVXIfrorEg6dL/0nIzDzDGpBcxZpTrhDAM49Rt8IE480blptdljD5i6kUxNOpdJ5eEi3egkn44d7Bdcd4wm9YxAOEgFVq7UO+BkB6N4/9u2AaulSMfn5vZB6YL3tRtuxfjKydXEfgEAGD6CZXYXO5iZyxzYsgVYtZr/Nm+eZUs/GOtxTMNMe2HNoKrho4IRsFmzMpd+MP9SV4fkmDHWswhfRXnyK6xpdxSvR15Dy5bxTWaAK8XSaXOqANXnIN7n/7xhYOtWgF55he/6MstWVQEJUxzZlLbbf0pL9JEoAPDVV/y/MNvJqKuzr4Nn//KFq9AkzxPGWGa+z5mjbzeZIAwdYh+PI4/UFJQXt8QIIqVlyQHaHiMQL1UiHLvvfQT/0+9RnHaqfTEtmE/2hfv559oqg9rx+vXT9MWDumfmnxBLdaEQsm4vTdj33gOaUwzTH9mnJRLCRKLGW29buwMfLDCjMuYS9u+z38t2SVKY0nZ5uT3ipLMkCZWX80U0g03GGePs+wcE3RhQSU6mq/TdbceokdAzggTj0qXAkUeYu8qVlybvexA/lZcDh0mZEfpgKwZAEWsV2JKrKfOCSAnj9YgaMvY3Y+pUax9BVZXdlh4Iar0dOjiKDOi2SzseAPDcc9KzmMR35extOLjRjGZzm7sujMDBAP/4RzDD7jgQgtHppxEqK4FlyxmIuK/CMITZhJctw37bvV7Wk56P3eHavYoKoI/EtMtLlP1F0g3yPOlVzswQX+3QcrzwApji+9GSCxdGECktSw7Q9hiBgMQIuqQbcI1xlyPdgyBqGeJ29NHaqiKrbJpsizIcyT5Vb5uSD0Y2xQg7/J6Dj8I/DrvV0cdPl/MLqnRbMaQHTh3Gg7h+cPTcjBNRoGS3ZhOeyQjU1NO7d0lOLzPFxIk0Ey/dZ1eN9vw/nqYhlXZKa2rH3Ybrnw/rGcHV19h9BH/8vaGtw7HvATyZ3lqF9ycZySljXOshctqwJ04EPvrI6eS0QewZKWtnI5xNTTw9eiioDlGN1jR6NLmOaYKRI07ekUsIcGpjLgvCoc39+teukTgfLjCQSgG7dvLcSiLtNzcN6TvsmhrpuuvAHv4XADOdhMZvfPZZ0neVpSiRXHIQ47vvAscc43yMDL73PXtghhtURmBCl0o+H2hTjGDLFik8TZFmGOBY4Lt287J+4XSRVbbmZk+NYO0XHm9+8WKeD0aAWRvKAEv6OhRfIL1+o6OPjbud8pNgJGs+4VEOd9yyzzH5Mlku9+4FhK2ZMeDtt1HB6nDe6PV4iF0BwLlDWjyqUNMFutzyv7wakJOGBPSSrdugZwSdOjOwTVYsIRnk73yT1HK1P3fd5RI+Kg2UYQBXjl2KTX1H24oM2fMRRh9jWM5yD40A4LvCRfZUkTYkDOq22h+yepO7CUrN0uqAx4CRqqm6MAKtNqfWa06S444lJJNApy4M+/ZyzXzhh4RxY1JIuHTVde/AX/+a+ei2x8DVf5ZO2zK1ptOWkHXl93m01JIlLu26wS0STPM90Ka1FkCbYgSVlZJQrUgxI0YyvLnDjPE3d1FOGE+BMhlW9CZg+3bf9rU03+MNe777b3zDUY8sqch97nsQc6iVXbrwyS4zP/EIZC7knQ0e1HLdOuCllwAAKcPs6a5dmP7hwbiMHjL7rw+769VTX+82lDs3IAc8MWTAID0jAGDLfPmbG7jJ4Y/Khm4bczAnyfjxVh4ggW7dNWmFFdTVAXuWrMEofGS7/uDHozEk/WlG68k827/+pa1nzhzg8MMtE4HnPJQGTnw85hh7ERF2KWPxYp5BU5YpvCDT+Ex4/X6FsrqkDmduFNxWyCSAZg4hAkOXDin0SO7Enw59ELMXlOKSS1xuBYDt22GsWuMa4umb+gSwM4J77+VhhSaEVgIAS5ayTLiti4sqOFxMQ4WCNsUIbKqj8uZKSwH26af8ixn29vbbPDGY3zthr73KE9b7QCsoeWgEcuZeBzRijUx4JX8gpkwxn0EagEMPMf0AkpQpCLTYR9C9O9wlQelhvtzAB+iiC+0PWLPJuvf88yjjj3Aj7j2ww/FYb7wejBGk4bISlZe3d9WXSKWANZ/Zr9uCAkxCNmMGcN99gZq3obwcKHPJRppIsMwG1Qwvf/llq4A03smkxbBE2hBXSPc1mVG9f01fq7TtvK2hgUvbvlKtWf/FEhEWmnIK0kubMiWcrdQlvv/DBUZGGB+w9zNs6zwIv/jsKgDOAAIb1q5F4oghrrmGdCZARzfkL0r2OnHuBsADAPr0sZ/EFhlBI0HyhMLuXUh0wU6UiOMhvQbenMiJJEMiEUAlf/55nwIcWtXVox8/+S+PysQGAgGPtAMZSUxiBMuX8meUT1Viw7gP5K03zZ2hLu63VAr4bI0kgZq6y9KP7JLgHySpu2ZRDYwU//2r7e4LWd6DBjjNGwKqeefzL13sAgoj+KvxUxydXInDvma/rovmqavT70D2w7ZtwH6X8wkeeJBl7Mnz5vkzORH5w0CBaUW79vyeqfi37XrKcFYg0muPPMYcD3lQ5bEzr3/8kfPnZkhz8YUXsHNH9oxg9ChLIwCARIM+QaQbXP0FTU1O38no0WD3/yPzXfa16c5OEEvvoYd4VQkjhT5nhNhDpAsOYJIgU9QIcotZOMH6oupy8sD/xTzxSMkB4gqPoxFl6FTSfU3RXrhqlyXY56xfyKuIsajb4ly0vXpY11TpnczooPPOcxKxUSMVx67ESBakx+Jc8HwVXolZVXNGn97OhQg4w3oHHhJcN1+WdsbvySZAQQj697fSUGdw8cXQQd77J59joGL0GGbbGOgLMS8ffdS7nERQmYtAUNbRuZxHj2aorgYeecSqJmNW0dRzjHR6SMeO/H9v2A/l/ctvuE09mC6nwHzeN14zUFXlYh4NQCRd/QViE6Rc3Ud2E95XMs/RmLlEqKhNwFrslmotGDL5nwoUhd27kOgL6wCPtBGMADPGIwPigE4lffV19yHevcv1J6QTdo2ALV+O+o1W0L9Wi5GJhblMK3pp7LkSVVN3zDY18c1F8m5JIbXd9n9KKKBCCtqBb0LY8ZU7iUil7L+JPQ2ZOjvxOL2q1Pu2Z7z2v13G0YVo3LDaTtDlw0xWmqdqpNPAylVwQGf5EGfenngiHz4HAzFx2eUsM59WQBNQ7maK27PH2+ISwKk+eLCm2t2E3r2tYZo7jzNAwKSBV1/NVSOz/scfs+51ORgNvzf44e2G3lVgh9iEJmB2JJkgzJkDHFcVTVDa4MZjA4xTz+6Ks9itiuHDw3fMBXfenbDer4d2ny+0KUbQFVY875/+ZP9NO+zmBqvQYXsh4BYKB1iHmmuRdIo85TusMDWbFsOcar/YlJNu0qxWieKo8dElJfyUQx0j6DXLbiK7Xjl3RqRU9nIAqxuE96n7GMwzIc9ir9meUXdeLL8hOCERjy3vRP4/XOco99X7yxzXNtdakUZ1de4Wv48+ZoGOYXD0rUs399QcCCZ9M02nOn/wLu7u8IuMKWV7vUX7zj0X3EmyxtpVF8aU7bK1w46779ZfNwwzJ6Pm/QUgktmY3G0pvjWMQE4mCCimpIhYtSZhaecKIygEntCqGYEqQXWCJcKsX6eYPJZ/qq1Dzj6aE3hFDXnxgQ6ljmvy5hy/o/qOBidmp53ioRFo+rClljB0KI+nd7R/k10M7tdoj5++6y7+/5unu89s1Xz2wnP6stdcTfZnzDJsQ8SpA9z8JarUmW96Pn2v45rIyeS38WfkMc4ILk+YL2Dn3lLPebh4EXkeMQzANdPrFU334ot1JjPvblVicyBrqJGUqcKGphFjXO8JDPPe0nauP3mivDpsTKdLN9J2IrIBA/DSla/YroUOH//USWsOH8JQ8frD/AtjmTkI5D+9BNCKGYFr3ngTD9IVtu+JMSmOQQAAIABJREFURueOEJGR8qqj1F1O8eGss6KpvjrpTpZe2Fopd4miERhgSJoS/ZLFHhqBJkMaA2HRIqBDmdNZ7ICSdE50OeVhMsicAifqdln1nTopTMqNawbUCFIpq7tCK3ELM9RVee63+H+/jT+PPebTpX2Kl/kcnuyJEklPX1U6baWg2O+VyNAFhx3Kx3nCjtczWXYzORRdOuym2M3czLdAex1w5Ie6LYbpM3W23fyAPtwWn3yS+Zgcc4y+TBBIc27vbvtkHYBqdN+x3rrw/PO2rL+BoMkye+NNDOxKkyYpGkG+00sArZgRxCHJn/oNwoABwD1LJ8bTKQ0CxVZrQLrFKaux0q4tArNF2chtjhvr7SPQ4dhjgeb9TtOQsxr7/V278XLi0HYdVMknyVxEIV3+hiDlXCDyMgHAiltfBQD0XTUz0L0AwO7lZyGwgwfzC3JIqFzO73036ZM5XfmDpKcknExaKSjef9+7CRUdO9pNKcIZ+txz/H/DB6usTHwS3B5FbGzcv1//uxfEI44exdON6B65HXkkvPKrf65CFLZt0xSyWu3Qzrk+bFNq9WrX6LowsNWxebMjv1G+zyVotYwgULSPD0Ru+digiThpb3ikE/aALPALGE1SZ6WJ9Mwz3PRx2mn8uyxl/fMBJ6ElIbJrNIKKCp4GYuRw677BB+spwspP7XWLqg7GOm15wBkuquZ/UuvKIKDurGWgAKo/25sxNXV73DT9/JdX/K4LxEE9GsIJIHJYYLOR8BRsRo+ijO8hrEWGKTcJpiB8OQt/rmaS5/jv/9bX16sXv699+3D9ACxZxkgbmDcP3mnaI4Cddqr9gk8GWDUXkrPCmBy7shD35ptg0nzOd3oJoBUzAsZ8NuAEgMgkGRueeMJxib38UqSqdLlNGrbrJ21NDWdoIpmcLP7pooau/Yk7UU0m+O333G1N/vZl+lnauMtez85dvNy1xt9c61cln+5vTteWe+ophfZnqRH0OXOsVdRclKmmHBhm/Saly3OkkcQhaQ33N8FgjV1cRKN+m2lKdAlo6Lxptfb6V/V83FQzXxAkS3hbpUl+trTYE5Ez6EysaooJr9/jYgSasFa5iXyj1TICIPvNem+8Tv7b0XMJjxmgO1e2exdp0kqTs38/A5OS8zDuOGEbsurVqbWfLvc2DQFA4i3rmAmmJg8y0bmz/f5u3c3NQR6qdFA1u2YT2eymRiqgCcltTKXzEslc/Iacg1qGj83Rky784Aee93oxgmH4RPubuE882vHHezehgy7yJZNgzm3M/v1v7eVh9IlrnYFB1DLRMn5RSS7pMlzLR0Wspof40aoZQbbQHnlXIDiMnETKTY09f9gavJ+eYKVr8BExhh3lIQkLMfzmm61rtbXaokMOVxzNplF51GhdaRPq1mIX9O9v1x52NQST3l3Pf5AWfNrUBNrBRUr7xIMgI8hmvmCQ6QuB4X5cFahwe02kjWc7jOGyy6zv4hULpnzCCS6dcsFR4Gmqowhi4phjMgzQvPluLpPYYOhInG3gfZ63BTSCQkDgV8kYSzLGPmaMvWp+Z4yxPzDG1jDGVjLG/ku6fidjbC1j7BPG2CjvmvOHin0bgHucB6IXAphuN89552U+ytKYoH0ZaVuTOkDGb27g1776ShPzH0JPZS52+3YlHgvnlVfcf5MwbZq9K66aRFCNABYBTLIgO6HckU2QgvzeZIZSkiD0gn9iQwChbQlkEJYusdrNaFokbP0RbRMRCKTYHlOaJMxOj8+crpkrbKt30Qj+8AeuWgXZxxC3j6AAEYanXwtgpfT9ewAGABhKREcAECe9ng7ga+bfVQD+nn03cwP2nzeBH/84b+0HTLypxY9/ZN28r1l4/5w+At0kvmgan5Tfu5Twki74JSihUerORBd5LZyAC0LtQpdOWZqGYIUbs9V623dQZBOkIOzyALBwriUOu/meM8iCGO3fD6QlBpTRtETCNRvHDbFBL4JpSNQ+f66Z7yrHBnI5Y28Gu3dzU+Hs2b7pYwgxaQRtwTTEGKsEcAaAB6XLVwO4mYhv0yMikcbvHACPmmcXLwDQnTGmHpFeGMizl+aOO/zLuCFj5wfwzrv8OTIL00cjEGmo04Yj+WK4Sa+UzaRdWL/e/Z6IO2fiCOGLa+PgdL1/OxDKe1nP8UA/K/1Cj+4xEBsXqOlWMtNj7FjlQjgkNJsO/SDuKL/2Iv7BLY9FTNDucj/7bNCTT7reI9/y9/sYjLVfZN+RNmIauh3ALwHIq/hQAFMZY4sYY28wxr5mXu8P2M77qzav2cAYu8q8d1FdvnZT5JkRrMtifs1KW3sfBD3OHFzjwwhEnD8DOQhsqKWtEHVx/q6Tu0iIqiK7SVSqodrjnYqNVNliwIDo98rj/Z1TJVOQHwMOY9dWkEhYqcfjhFvyOy8IHwE++ID/z+m2ftgOc5LhZtYE7AdVrf8SSBwbIvOoG1q7RsAYOxPAViJS0++1B7CPiMYAeADAQ+IWTTWOt0FE9xPRGCIa01urv/kj623Zec4Rno4retEkfr3LgzmLH/0XJ8ZDDydHKgmXACE9lBdw+NAAjDXqS/vMJbQyjE8jJr4f15p2PTVLB6LI0nOHDvzsjWAdCYEIjKDks5X+hWJEFNLSpbP1edDgmCZNG9AIJgA4mzG2HtwPcBJj7HFwSd/cm4gXAIhUfdXgvgOBSgA1sfRWgl+KiSDwPb4vx4ir/W+cwv8LaZP8TENXXgkAKC0hTJtq/z3UfFXq/t3vcsgIXDQJVfMnD+Yel/CZ1d6TLOzNdOn3+P+Q84YB6LUhWLRWISRAixNRTIqGdNDGNdfERCPynUzIB76MgIiuJ6JKIhoMYBqA94joYgAvAjjJLHYCABHv+DKA75rRQ+MANBDRZrXebBFHign24x/F05mIiJh9woH2pVLuINg3o+kcer2aeUL6Vas0qaRLo/sIAgmWQXcIq91woVD//Ke90f0e5z9kuxNdYONG/zKucKO0PhSYACx+h5uSZsyIQK2/9z2Puq0xu0h/HIPLjW2Ma5hIbrNMm3Fpkbt3FfZYZWMb+TOA8xhjywD8CcCV5vXXAXwBYC24yeiarHrogjhSTOQb8glfWeG11wBYjjFZeHazkQLAEUMJZWX237sjxElRUaQcqXM0ZAiM7j20xZ5+Olj1XyrJQ73Ooch2J7rA1KlZ3ByREXy2hrCjgT9b3OZmOc3Dlx8FDGFtLXA5aCgwYuIEt/21lWsEMohoJhGdaX7eQURnENEwIqoioqXmdSKiHxHRoeZvi3LR8ThSTOQb3brFa5o691ucmIjjDwHgJz92JzC//73T4cfC2IZcjiH0QuNua0Fs2MDw1Q79PZs2KRkZXQhle0WD8XL7xOUSyol/04cRNDbycyIA55kO2aKdlEJkbnpc8Btbg0bwxhtZ3b5rdzxr1C3LLv8tliayQqveWVzg50H7I+YZsPBDXl/nLtbkVU7pczafTR9Ukf3yy31veewR6549e5mrDfc6utWZkVGXsrip5VfRrw/LIn404nh37kQYO5Y/v/x+40DkWP5CoGA5xk03xVOP7nwPgeJ5BEXEis6d+GSTw9/EIeE67GzIciGrhCBIyJF0OhRLMNtJaCqCRNUMGmi/7nlEaUyE68bGX0a/2S0M1Kdvhx5qjceOhujNFxEOcUX29evn/n6L5xFkiXxz0awR8z4GEV3YJWXZ+Z/805eu5bt1pXg1ggAokc4fSBvuGoEWmvG67Hv2PshmMRXLl8XDCPwyF3sNqetuXJ/3wPgpLgCAHt1CPodat2r+K2oErkjGRCFra9zHqngeQZbINxctNHTq6JxsiVtvcS3PQI6j+kIhAiH4zlSLinbs6B3ep/IZXcnE9Kdt3zt0dCdqI0fEIzn4ndXrlZTuOxdaT2EbviD7CEyCPWZ0yHFXCf2774a737VLbZ8RxGUa8nq/M99uzvfe1tbNCPLNRbNGzAupcY9mz4APod8X4ZSpbFDW3urPwYewjDlLB3mfCBmkl1xr7FtUvIbUywwVBn5rdq7HyaeLFlkdbIx2ZhGa9menEajnD0Tdz6I5kbHNoUvnuNaoez1sX8SJECNaNSPINxfNGjEzgmPHOutr2udhxyBCWfuWNQ299YbkI4D3Xgo5Okc96leASktt32X/iIpuaBnjetBhees/0pcAGoEg2HPmZDdvNmxU9l5EPCUsnWr7GkFcazSOXFm5RKtmBK0eMTOCZ/7trK9d0tugHSVfjABFYATb65TjNj0ot7xPpKxML7caJfY8xl4Lrg4xqZAbNnj+7DWkJx9pne2wrd667pfJk2DF+4fVbNSar77ap0BAlHqlG28j2LWzBRhBAUi0RUaQT8TMCHSTzSu5VrZ9iJKGuLJncDVY3ifCAG2aiUT7Use1fMMrBcU/VkzKfJbf1003eo/lunXWsY5lcFGPXLB/n73uIcYK2/dX34hGBrzMem0FN/8unnqKGkER7og77ElH1L2yfWoOrw+DKGmIJx4jaQA+bdv2ibiUZR062L7rHOYtjer1wbb+ykd6dl8537Ps3kbKaARjjgxnU1an2e34aaj73ZCNNtlaoE1jHQFe+wgKAUVGkE/EvZB0Ceb80j5nwYx8tQ3dPVIipFRzDM+vHDITV/6mbNCnMpiWMm2a9fw/w988y3bsCLRrzz+XpsNpBMlEYROhQkZc86l//6JpqAg3xMwIdKaaVSs8iHW27UdgBCR5fT/7zLv9LVvkGwP2tRVJqR3Lgvd18CCydgDvDacR+CYSLABCVKj4aTzKE6ZeUNjzssgI8omYidb2emd9jbtyZxqKEkcuawF+dtPKytDVtypGEKavNjNMyBPf/cj8KadEZAStfkenP169zeUcjLDwGqsCYMRFRpBP1Nb6lwmBXj01UUMJb0ZgZGEDbdgR/t6SECdl2bJstkGNIHRfBcEISYD9WunaLVw3BGIynxc0vk/3x1LPs88W9mAVGUE+ceutsVanjxpyZwTpNPDqy1lEDaUi+AgkInbYod5tRzoApq0yArlsSEbA9nvvGoyadE4+96IIb3ilmChqBEXECw1h6dzRnRHU1ACpLDYFRYojl/pY4uPErK7W3xe0/oJHCIKeSksnz8VtkomYxjeundoHAvodVNjzssgI2hI0RFDNzimj30FkC2EMi1yHavbpI30JSuBbkd3aaAieo+HztYQ5c01G0JqYXREAgHPPbSMaAWMsyRj7mDH2qvn9YcbYOsbYEvNvpHmdMcbuZIytZYx9whgblavOF2GHLmqIrVrlWn7XLoBlEd+8e2cEohsi9XJbjxpKvPpKqPL123OjEUQdso4dWs9Y5xv7Ggt7rMJoBNcCWKlc+wURjTT/lpjXTgfwNfPvKgB/z76bRQSBLmrIC3feQTiHXorcXiTTQAhGYIsaaoOMICx69uSMIEpqDy/s8zjn2QtR9pEcqCjr4F8mnwjECBhjlQDOAPBggOLnAHjUPLJyAYDujLGDsuijO9rwoo+CXr3Cle+8xuP4sgCItG1eJh4+7y/S2bxtdE4ceghh0vH8c1apwzVoX5Z/00Rbx7497u9MzQabDwTVCG4H8EvAIQL+wTT/3MYYM/c9oj+AjVKZavNa/AhyItYBhLCEeUqH17NqL5JpIIRGYIsaOsA1gpKEtaGMUbyMYP/+4sE0uUYHj82DW7e2YEdc4MsIGGNnAthKRIuVn64HMBTAWAA9AfxK3KKpxjEKjLGrGGOLGGOL6qKeMFNWFu2+toqQC9PLkRwEWZsGfPprS/JZJDoZxG2SmT0n2n0HwsE0ccFLSLv4Epb3GIcgGsEEAGczxtYDeBrASYyxx4los2n+2Q/gXwCONctXAxgg3V8JwH56CAAiup+IxhDRmN69e0frfceO0e5rqwi5MNPpLFXSKIRAzg0UQ9K5AwbSCWVxU42tdRGDBw/0dxIGHu9s/vz8n7boOwOI6HoiqiSiwQCmAXiPiC4Wdn/G9dVvAVhu3vIygO+a0UPjADQQ0ebcdL8IG0IuTL9cP3G3Fxa2E+iKRCdnjCCqHNZa3kkdyvPdBc+xGlfF8n7aYpS9mwJPMMZ6g5uClgD4oXn9dQDfBLAWQCOAy7LqYRGBYaSMUGFgWedIz7FpyBZe3UqITq5ARNi/n6EMiJ0RnPINAI9H6lSs/cgVoh7FGSs83tk77+R/K0EoRkBEMwHMND+f5FKGAPwo247lCzRsGGbXHIbj61/Id1dC44rLCf8KUT5rRpAlIUinCD7nwEtNFcRyzhs21xDmrGP4NhA7AX7rLYbTotzYShhBr3IGbMtzJx56yPUnVgC504s7ixWkmgn12/Pdi2hYtjScpNi5fXN2DWZJCJI1Gz1/l4WoWbOyaqrVY9++3NHdLRGjVlrLwTTJpD+hpbPOboGeFC6KjEBBSQnQs3vrmOAqRg4Pxwj671+XXYM5JgSyAy3sZrm2hrIy5Mx+cGDrWhxz5+W7B/lFkREoWPcFtdrtCff/o20RS9mBVq5JsX0g4aC+hHPOcSfYNGxY5LpHYol/odaMAAx0ex6tAIXAiIuMQEFjI+Cfwb0w0dayQcrrd9Kk1vlO4gKD97YZFjGDKACMxNLI97YVdO+ZP1J48sn5z5VYZAQKOhR4ThAv6JLOtWbQVzsyn1uLPTpnIPKWHPMddlLICDA2x45tgX64YO48Vvj7CA40HHII0KtH6yQ6p57SxjSCnj2sLwc4IyAA777rUaDICNwRYGza5zFJwfjxyPs+giIjUJBOARMn5JfopPv2i3Rfo0diq1aPA5wRGCnC1m0eBO0AHx8vUABGkE82+t4Mlnc+XmQEClatBubPy++i2lwbbVb4nfjVqnGAE7pEgjJpqLXINyUpYOTb7OKHQnh1RUagwfY8Rw2F2x9sIe489QWFA5wRMADHn1AAFKMVYn/E8xYOJBQZgQY9e1AgdTJXiMoI2lrUkA0HOCMAETp0KhK0KGjfzr9MXmdXAagERUagYOgQoGqclfs9H+jXv2gacqDICDzt2PkUXAodvfv4j82c2S3QkQJGkREoKCkxQxXzuLBK20Vr+5npbVgjKMJzTq5eU2QErgiwlvOaVqYAmHiREShoTnHhM58SVtTNQT0CpsZY0/mYSPXnFQe6RuCDPbvz3YPChWH4r+VePVugIwWMIiNQsHo18M7bhOZUHrl01F2iAZ3FX/tatOrziiIj8JQcO3VuwX60MiQCpLidOCn3/ShkFBmBBpXp9WiHLDNzZoOIjOCr+mCMIP+KaAQc4IzA71jIIUNb5VttEQTRCA700SsyAgUEhiOwKr+diGiWuuTiYMSyORWp+ryCjAObEdRvI89osgOdkHlhg3e28yJQZASFiYiMIOg+guXLIlWfVyxceGAzgqYm4LXXPbKPtmBfWhsKIbtnoSMwI2CMJRljHzPGXlWu38UY2y19b88Ym84YW8sY+4AxNji+7uYeQ4fmuweIbBoqTQRjBK2RaOxqaI29jg/tSgnbPE7ZSuXTp1VEVigEq2cYinMtgJXyBcbYGADdlXJXAPiKiA4DcBuAW7LqYQujNJtTnGNC1Iilh/5ZADMqR+jate0+WxD06gVcRu7HHZaUtmBnWhkGDipsJnniia0kDTVjrBLAGQAelK4lAdwK4JdK8XMAPGJ+fhbAySyfu7NaIVLpaMP111uDzaYjhtqJ6t8H/jFSey2JXTsPbEbgl4a7RRfYBx+0ZGvZo8DJz7x5+c+HFFQjuB2c4MuU5scAXiaizUrZ/gA2AgARpQA0AOilVsgYu4oxtogxtqgu36MgoRDITUm7aKah1auC9V494OQHP4jUXIuCFcSbySO2bPH+PQfEbh6q9D+MGBF7W7nE+vX57oE3WkUaasbYmQC2EtFi6Vo/ABcAuEt3i+aaYxUT0f1ENIaIxvTu3TtEl3OLdV8EK2fkUAbTKlArVzqvKThiSNvdWXzAM4I8oLDl6OAodGfx9On5V1qCiJ4TAJzNGFsP4GkAJwH4FMBhANaa1zsyxtaa5asBDAAAxlgJgG4A8rmBOxT4UZX+2IocsnCNs9gg/5ny02uDMYK1n9m/72ks7IVSRAAEoSR//nO4Kl2Yb6ETVhWF3t8+ffLdgwCMgIiuJ6JKIhoMYBqA94ioBxH1JaLB5vVG0zkMAC8DuNT8fL5ZvtWIcx07AnTxJb7lcjq5NIt6+1f+7d1xe7BhVg+w6dShZV7PLJwQ+d5uXVrNFMo/XnpJf71bt1DVdOmiv/71r4fsT55xyCH57oE3CoE65mIfwT8B9DI1hJ8B+J8ctJEzHHwIgMpK33I5telpGEGvcn9G8NnqYBpBaSJt+74noBaULbIxp40cWQCrpZAhz5meLolz9u8PVeWRR+rHfN68UNXkHSUlha0R+Ll/WgKhGAERzSSiMzXXO0uf9xHRBUR0GBEdS0QBre6Fg8ef8J84yVxuxdOYhljCv09P0oWBqmeGnRF07hSsW/lE1MPrqVMreDgJp+Ct3FUekhG4zbjRYwqbsKoINHPyKJbn2z8AFHcWO5BKARurA7yZXL49Xd0xttelzJ5jIgiTiQdZtBNxoe7dVwCrLAS2JqOdVx1Eiw3LCNzwzDOxVNNi2LCxsOdAq/ARHGjYuCHYmkrnMkBHQ/SDOIuDov9Baf9CAKhDh9jaBIDxE6M/Q1NTNEbQnG5dU/zIoyKO0QMPWJ/dmOa554ar06WevgfllrDWv/1RrPU17vXvbz4dykWNoABxSONynHue/5up3ZLDt6cxDdVvj689lg7GCGZ1OoN/aGiIpd32ZdGn2+KIuYYSyQJYZSHw6acRbyyVthanXLIKDh4csXI7ck24ep4c73kZHToGyD760ouxttna0KoZQa62ZefdZp5j0xAURrDL5VCTunqzza5dHb81Dz06dLPZHSIejRF07tK6GMHIYyL2V54fLpJ8aKnXTbPIMSeIu/pBg+KtT2APOuam4jygVTOCXG1IfvSx/BKPJo05Y1yV1KcLgzmFXaEwgj/9SV+s3LEf3ETnzih94hGXH90x6/3Qt2QQ9Y2wkujJo+jMsyLfGwZf4ODM50fCD6sDRlpPwE89LeQoqlvQA+AP+H+h78k11Kdeg3hOZkojwIk3rQStmhGUl+em3nw7l+YvcL6WlEy7x4zJrgGFEbhpVjbmI4EYi9VnEQTDh0WM6siCEey44PuR7w2DDu2tZ2MlEYmLJEa7WfLmLwj3zqiHSxiqh8i+P5G9Xyl2TV8xtc4a/L1Yqi0yggKBV1rebDCo0t+Gnkvnki7ePinburPVndPpQBlOXzETjqsLs7ERqK8P32w2aSKWL2t5RvDnW1qG2fU9CFYoTtRjSqX32c0lU6sbY3fDm/P4jrIX8K3A9/zyl9mPWa5Tj11+RTz1dOtZZAQFgVxt6rpkmv8xlX2kthdjVKzt65jMgg9iZATvvw+6487M17J2esKRIM4Q1YWZSrNIIafdu2pEvdKg+ZMjMoJk9MW6chV/xlSOJT8GAH37AgC2bY+2JGVm/Yuf60Xqt94O98621vPnDjPdOnbOnhFUVAD4VnDm4wvFAx8kiigIElG1twJEq2YEufJZsZQ/IyhpZzXernP72NpOsRItIyjvbV2zndo4cWL4Ro46CqgckPn6mxv1xdqhCQBfmPTBh5nryWSwnc4qdu3SXFy6NNC9kbWJLDSCww/n/5/s94vIdQQCUcbUNm58tCVZt816HytWuDQTUovtWc4J3WmnBa8njrxVuY5K8g0GCRpdFVV7K0C0nSeJE83+jECWwI4env3M/aTrRHyGw7CBBmgXmhw+evc91mfqpp4L5IJ27TIfDQP49Q3+fa7oxjcgMWZfnJ06s0iLtbSnJnlNwMUUmRFkoRH85S/8/0UXRa4iMHY08AHVBQoEgZxVokOZfqxWrApXNzO3z7dvZ79+4onu97SGjdx+2uz+g4cEqyiLuVVoKDICHQIwgk01DHXt+C7QOASYr3YmMoeT64is7Bhft84q0NSEjFnBE1IoYF0dsGKl9erdpLjjRuzT3s/cOumDieOc8e1GIpjEnvj/7V15mBXFtf+de2cYVmcYlmF3QEFAQEQwBJWAIgQVUGPy8BlF0IBR4y7RuMTlRaOJMT4XlKhRo4lGkxifTx8uaJaHG0YEfYgiCIJs4i77vef9UV23q7urernL3DtQv++bb/p2V1Wfru3UOXXqnDIwAvmJ27aZ03x1/hV5l6+ifb14WSpP3yXvvue2x/Zt+rpK6hriow2i7vyS3IKXzOXc/Rvjo2aDF1+Il85uFjcTPNklz12hGIwAcCZhoCiybE98iHYQI+7gg4PP1RVxb9faEC0M+v0wdO4M9B/g0mwSlcngkoCBvL6ZNAedNn8ejxEMztNqaCfyVw1deJH4xtYh3lnbtjU+ig/m3Or7tdfzG5Lt27vXAwfq0+xMGPmuYxcx0c2f770/apQ5zwerm8G5jYi+G9c54qq1lhFUJvbZx/NzxYY8R+m11wJ/+1toEga52pYiMII+WIluWIdWNaxqcXLI2YafdhrOPsd9X9zVuTqVbdwIXHe9UoYhe/aMM3PXavjML78ivwVqPGgycTp6omYiVKfzYwRvL82/iy9dFqNdi+WszGmETg350dvY26X1xhv0NKUTnrLexXKi85b3QsiKuWcM9yyVjrjSp5UIKhUdO4KVJVq3rnkO0m7dgCFDQpP06O6qa3bsKt4qqEsXRosazR7BJmdTYsYMpAp0EtejB3DpT6LL2DTxFABiT2HmTPf+rgxh2ql50KCRCA4cEc0IiPI3PL0QN+WZ00VosCINI2CTG+gwSG6c5wZkFoS3sL94v8ER1pq1ydpsnaMaSsFb3tix5jyzftj8JYIxId+noliMoNyB64HdjREwg5TTNKUMb5hWfJy/nPCgThgI+j2Hjh3M35L0K3ftAt7+P+ctdXXA5MnadNI8d9OmoCXKkreKwwi2Z2IMplQKu3bkN1r+lj4ir3yA62oIZy3DAAAgAElEQVQ8TDWkYwTaUKMhyGTYNRDIkxEQRFAlwHygLKmXy85dBC0d6rx1HxaPoMkc2ZYQ/s1xE+SeHt9wY0Hvq4SQ7bsXIwA8A2ndutK9huFy8qbwZE7svMxvwoN4Kwo1R1UVMGCgc2fqVONms3xN587AAUO8Xzl0aByqfdA5Q4ujGmrVClWp8I9kgwQ3YkRIpppws9/fPSgqgAjGVSRnNRKBqcC+etcGH61lzJxVGCP4cA25e0fMGHOowfFcAvzbiYKWUaO8XxS2R6A1EU6IkocGSMKou3Y1F+NwPbrg/ILIKXfgeiABIyCiNBG9QURPOr/vIaI3iWgxET1GRG2d+zVE9AgRLSeiV4iosTSkRyNv1RAQ2Rsz6RZInXcuAGA7JffJEvpeXUd16Pnkk+DEn3TuWLMG+MUv3Yknyl0EETBnjvu7rg647/48ln5Kne7qOwAA8H/LHIngO98xZltQ/S2sWhG+KUFnnKG9v3BhCDkRodlyG7AhfUGnNqI8jl2/ubgwRqDy8umnMrbtDJe0Mp2ixQPp7sIfFOjFF815rjP4rUqCMWMqI3wjgFAxKpMNHwN8eTyLsubmhvpcAEuV3+cz8wHMPATAagBnO/dPA/CpE8P4ZgA3FIXSPHDcsSVUDbVrDfrxbADA6IlFNp7WxSNwNosnTSZcrBzjZ05uvtrQ4K5mGIRJk6NLUN05p1LuyeIvkWBDXuFg/7n8KABAxwZnwnrsMWO2jz9JY9uWcInAJBWpq9dMg3d1N+bwBN3fMEGHqo0SYMgBhTECEOU29LNZDmWAALBxU3Sbf73daRvfrBw2cUVNjnj44cj3LlgAbJ5+EdbVNEamLQnU7w352NbSvbUhDY3LXy3Z1IjV64ioB4CjAdwt7zHzF84zAtAKrkQ8BcD9zvVjAI6gpErTCsaOYd8AAJBycqZlXXEDuOjw8UYx02WywBYn6tZcmoUdOxKoptRdPqdJtm4jr/uKOFCaM5G/f2W23ptXAgA2bIzOP6DNavTDu6Fp1q/X31dXr/4YEpGxd0kZ6KbBnuDz2bDM7daV8Zu7C2QEcA9RV6UYhxwSQUuM5UObdnpGEIZQ8o87DjjggMgyRo0Cdow4BA9vTxhIp1jI2YUj9BBJ7z4R5TSjaS9ur/s1gNmA13yAiH4LYD2A/gBudW53B/AhADDzLgCfAwg4NCaimUS0kIgWbirWbomvw27dmkcZs2eHPm5RI3cQFV/kreP5JX+/zeDcNZ96qriYNcubyDDo5Ma3OoAfOuxOtKhmYxySWQe6biEYAGpr3YfOiG3VJoWDv5Gsw6rnCFq3yY8RDMYSpyyR3/QNANDv6zciTfquv07z/KuvvG76fZNfTlowHQaQmcMmwgSTpMnkNp1SDBsKYATy6+69V6++UaWmbIyhn/OEqmaMCN/HYWrGunin4F94QVRDwbLWL3+pvx/VZuo5ohCTMaJwiWC3YgREdAyAjcz8uv8ZM08H0A1CZfRvMoummEDNM/NcZh7OzMM7deqUjGo/Jk7U3jYdtQ/F0U5UrqjOop7gidh0lOgz2J1w6Le/FRe6cJCaDiR9DaVTwD77iOv584GXXzFbHcxbbN7oku+gFOG/n9J32NxmOHt93H/+uRs60yjsHX988J7ndLK4TlWJLnjYYWZS4yBO6NDFGILV1Cv3OzdZxjGnKcKgVi3Ncpg4UdQLF8AITj/dk6+ulrXkqv0kjkSQTSWXCDR758rDbKx6HDsW6NQJ6NGtQFZgojvqe1SGdeWVwJNP6tNFfcvuxAgAHAJgMhF9AOBhAIcT0YPyITNnADwCQO72rQHQEwCIqApALYBPikhzEHGCDMdFlEsC2biD3dV93MH7ts4ZmL+zmCSCfsLi5L+epNyJ16VLgU8/Nb9v2HCFLmYvncpqxqTekZqkMWPEJrXEzl3k/jZ1do2zN1ZWltI2vaGLyP/aa8bPiAWtZwYfbTtRjWcxPvj4XzFi5JraOOYkycOHg3R9yy91xOlLfoc+Bx0UiybVTYnurIofX291aFElgojJLdSPT0xGsGCBcDH/3ROSM4Itp54ZnSjKzO7XvwZ++ENxPWOGuzhMCn87FLraKSEiex0zX8rMPZi5EcBUAPMBnExE+wK5PYJJAN5xsjwBYJpzfQKA+WxSjhYD11/vmbzVNv7r43m8Nu6K7LLL3OuY/my++EIzCOK+zxlAHeo517+GDg1/9R0P1WLrCSeL7IBXhaUeYDIMTqlDX7AAHgPx6mrF+2iCVc+unRqbe2cGj9JpR+FnP9Pc9NFGZFj8a0JxemCy5JLP/NBIuJTNguN4Qo3TH1Q92r33AsccE50H3vgdnRui263tXsklgisuB/j9FfqHuglY8acifXeNGiVMKvM5B9SqWqkbXZuNGBFPIujZMzyNWr6pb/hd1VSwt9J8KSMA9xPREgBLAHQFcI3z7B4AHYhoOYALAFxSMJVhuOQSt2GZPeLvhvV5MAIZni+qs6iNGpMRtNPNN0nFR2Z89bXIk8kAmV3aeQeAWG232re7+x7TitRAg9ShjxoFdFAOy9bWKfEIEtCvngXIqe2c/GFuC+Igai4HgPHjEy7u5LdNmGBOo+snunuZjOKyQUkq0yeRCFQfUNOnuxLxn/5kfj+8/SSO/UZujyCmFQ0AtGsHUJ/ewIYNwYfZbPD7Xnkl5zyrw+pFAITKjgiJGFCOPMWFvPZMw/Dh8cqN0w5Rdeh/z+7CCJj5RWY+hpmzzHwIMw9m5kHMfJK0ImLmbcz8XWbel5kPZmbD8qCIUFYa6uGMOE45PZgwIfqkVAGB5QeNiGFdFLb6dJ6320s8r6oC2tcDVdUhFi1+1cN4RzXiWEN8vYWM+mI5OecGZq5c94fHQdf//q+ZbohVsUTXLl5GUJIx4qvHljV5qm3HjdNm5Pp6r/9nCd2ucCaDqpogI3jpZRLWROytj7wgAygYVB8e1xCffRZdXiqBauib3/Q+15yS4ky4aihFHPqKWFCkpWuuNaSJYAQb1nOsPZRceg3P075H7eTSWKRCULksKgmUjqp2osmTEq4ounbNFZDI/0dcn/o66yJd3ghGIB+vWQOM/OOFoJtv9qY58EC3HH9Z8+YBALI7xWR1x50pjJ/gS3PaaR7SdOTIzWI1TkIOU6boaVfbqRgTn4rRowF/PRRQ9rqaRmTbKPETNGXRqlXAxZqgNToTqEwGpFENffqpUy1qfaxZkyfV4fCYy2r8ULzS3if5pIMSgXFEXRF9eGr71og9Av/EmY9GWVHHaMcwc+TgHjKYMeeu6DEtw7326Gn4Jv97VG+SFbaRvHswggiTy3zgj4ecDQsAY2AEp6V+m/zFUZ1fkRgaGgA64nDge99LVgaALz4Rk1WGKehfXm6UheCTT0Uez8pJdu7HHxf/2/kC0agDo9jbRg0NwHnnFa24XpmV+HSHuymrjfHctq0+Appuoslmtaq59u2d7qPWR/fuRrqeo3G4DWe5dOmq0VC3Ya4hAGDEm/d4bzj0qlt869dTqKlv2ARX0yJiddW+PXD22e7vfPqIUvctUgZCI8plACtXRU/U8gCfsT7UftDQ4G1/ywhKgLx8Iivo1y8wSDv19tmWE4H79w82YCZj3CNYO/I74GeedW/E7dhRq6YocUVdXZJmogZQ2y7r3KLEQc0BoEPgZAjM3/fcc8Hn6vW7hsNiRx2VmC4PwupRruQ//FD7eNQor9aHQfgDnagv6z/+w/t7yRJ39Td6tPhv6Ccjv0nIZljrs0iHlXuPwXnp23K/x4zRdAdDO2hdQ1x5Ze4yYD22v/BmunO7+4Jt24F33kFeoDCroVGjRJ3deqt7Lx9GcJtbN5ddtAM87kjPY2YAd90VyMbKYo4ANDZGjwmpkjXaAPj7u85qr0KwezACORLC/OOGILfaUxqHWtYg+0DOShaff8ZYvYqDMkaI1c19f2oHOnKc8qJgxw5EB7v66uAhMxVbtgD3329+7n8PyZW7OGCX4xFZwTzP/hHhuecTdkpyN4s7dArpQrJepOc3/4zVy7HpNzhjQ2NjOB1Tp4Y/D4OMQ2kwPX7xRbiO/iDMIjt3NExMqgUZIDY/Jae86CLxP5Pxnlh18Mw8Yd9/1pmasjVxH0+bwVi0yP29YIHmHIlJQtY1s2JxtGmzry3HjgX23x/VabceWtaYA99EIowRtNT468qHESg74m1b7MAOn+HO1q2s90apMOklS4AfnpWKJEF+iVGTp/b3TMYygpKDWXQkObil6VfMjmT0j+JrrK1bhQ19AAbVUMBUUaFH9pHbb/elOf10o1toHH440KED2Bn5xs/TPMhkgD/+UVlBOlJUm3apgO13ZLUp9eIJdmLQ8eb82vhXSKtWmd8xaFC05BMlCfoHW3V1eHp/VmVDlSCqPzb8dbFrF/DVV4FkOx21wltLfOnHjxfWDoce6rmdAsuFOgDX1DL03WFQmM3QAzV9++KLQT/6Ue5nl66G7h5nYmtqx/vbtweCPLUy+YdU6qxjB8Ztd4iP1EpcEoqKVgvPUe6sZQSlBmeyyKbSbluedVZoehWrWu0nFgOaweM3P2vVUj+X5E5g+hBo6+9+N7fykas4v0bAQ0aLFsC0ae7N559H9sCDsH61WFkaO6lOImDxrtwKUk6img45a6ZBhaP7OFXd4SNG5uy7n7O6SrJHcPfd0WmyWWHz/cADQH19oC4CXlWTRlZXT4ynUuF7ToMGhZeVyYg9DJ+X1aoqAoExeJCv7HnzxKlzvy16NutpMr9FV2IodbIjo5kOpk0D/v3fcz8jzU7DnuvMR8PyqIPNv2kXB9u3B2x/tm4D+JxzgyQofW3zx4wVTlxwrcSVy+SWzusN5rK5BD7VkGmxVyY0e0aQzQLzn8vi6y3kToyzZwNvvRVrZdRrWEfRuc84Q5gJKlBt09NpoFcvvVHZFkPw9wBOPRW4/HIA7irOfxDTM7mnUoHJddMm4J87xCEcYyfVcIfZg/8HN6V/7K4gVUbg010vW6yPVeyBeiBNwlffsrbkBJPdlXU3tuOsWnVp1B1PObGcfDKQTgfqIlA3SRnByJHe/RZZr8uWuRviEkuWhEso2Szwgx8ENvYnTK1Dh771uO1WzbdWVwcZgVonp5yin0PjSgS33+5RyaTU49lHHqnJgPy4ztVXi/9+1ZBsDxO9KiNWXbrEhSbm9oO/Ay56QXOYRJUIOrqhPz0SV8huOzVoggqYVEM//7n58E+Z0OwZwaZNwOaPs8gi5U6MRGKjS9fBfvpTz0+SVji33+5Z+QDe4/Lt2sEYH7hNu+TVKIvxCy+eyV3DCDp3Bh4d8QsAvk66caObSCMR3LToCDy/tr+7gpSTlmaPY/jAcD/9IHI7tcpE/O6KpT8hZ4JJIQs88ogIAxql1mlsFNYz/pW2ynh8ljidOwMbatwToYHTsyNGiBVuQB8XA7KOFiwQxgU6E9kwM2KDeWXqzjmoemWBfn6NwQi0iMMI/vpX4MwzPW3viTr39NPRZQDAVVd5f/s/pEMHYN99xbV/geIPe+dHlA+vN98MZ+66GNnMWPS2RqxX/WARcM75oi09Epdfz5TkQNmcOYBUsbVpY1VDxUbnzkDnDlkwSK8v9cOv0As7wKVuHgNCtD/9dO+kC+UEZhzMmuUx6Pb3Y883aBgBEfDwo+J92k46apSWEaRSjrmpTB+iGvrl1V9Hf4cU27/80i3DT6vzf8UHopvlxO++fcPdjR55pCD28suDfoDUybamxmOiSgR02rLa/a2KW488Ik7hHnqomAB1iDI/ZXYPToWl0f3WvXPoUNEB2rfXm57oGEEcPXscRiBVE0r7e8aO6bS8TD9ypPjvW1h5sHSpUOnIQ4z+sRblckP26X/+U89khwwJD0GXyQT6d4qAAYOV915xhZBYfPtXcvGSy961a/CEapRHAbWtTjpJ9L3Nm4X2wTKC4oII+NZoxl51qaC+VG3co48G/vIX7yrh2Wfji9EPPijs608+OSjWRTWq6myqY0fvZOLL6/kGVR2hQHsCU3bKdDreN8nBqdqsv/46MH48aN99wvM2NLiM4LPPXJHZP7nLzTTHsRz6OA7cBw1yD73p8Mwz4n8q5dUT1/iOBs+dC7z8siercVEe59Cfo7Yz5k+yCRsn7RtvuNff+AawwncIv7o6WKcmE9yod59zTjQ9LVvGt8QySSNqf+3fX/zv2FFIeP6JOWoiHTpU+CIKc0Qlj78//3zwWSYTqIuTvg/c+mx/19fINdcIE1rnoGUORx8N3Hmn+/ujj4LnO3T033GHe61j2vX1ggFaRlB8UDaDVFU6WLdqJ7jxRuDYY72MYNy42BJBqJOaqEnm7383P/OrU1RSNBIBAMGIzvfFSZU0jBvnuuXWnSyW6NFDmDM6p4gBiM3JefO8nlXVdwLAt74lvkdO0IsXu9Zaat3W17vSl6RNDtarrhJM2A9paunHiY79/pYt3o2b2tpwXavhDEVeaGzML7hsNus1jdQewICgLxd02EFVVbhqyARdmltuEf9nzBCLGl1aIuAPfwgvW2ckoOJrgzR54YVCItNJBKa2mTRJ+CKKA51Jl0Y11Lolgzp1DEZKkwsjQNRJz57hZtyAqAO/2atqWyvH7gcfBPNaRlACxHRvCyC4Eo3y7QNEr6biOJ2LGsA6nXM6rWcELVsCv/qV956cbK+8UrhaWLkyuIL2o7rafb5tGzBggDmttOlv1UqoY+Qg7tJFiOjXX+8deDff7AYMlu/w61j9MO0b/Pzn4n8qJSYxKTGYcN113vfKvFEIq6t//EO4J44L+S07d3ojJB1+eHDlb0LUHoGuTw0f7voc0uGee4SaQleG/P6VK835ZZpp04D33gveNzGCs8/2vhdwx80JJxhjigSgOQyWg39zOEyNposDEgV//0ing9GvVBrk+/feO7qsMmP3YAR+06wwjB7tHShxGIFcTZkwaVKwY82YEU2L1A8DelfCBtWQFv7vlxN33A4XM7hODlIiSKeFq4VLLvGqMVq2dFfvcWmordVbh6jfttde0RYkl14avBcn+IyETm3VqlU0I1Mhzwz4J3Ki+HU9dmxwgozqD6+9JtRMhUD2nTDU1LibwD/4gbupb2IEErItFy50I+bdcINZGvTjsMPMXt787RNmkJBOG9yTJoCuX6uhLQ84QGghdNAdoCsjYjhIbwYw2SfH1aHGUQ2FoW9f4Nxz3ZUrIFZeUVi7VjCDl14S8Vz9k5VJNaRD1OZesSEZgbrhFzbwjosRf/YnP9Fv2PrbNuk3xZUYZZqbbkpWvg5yQtCcJo4N6QZD7Utx9ghUtG8fHr1IRZzydPU4d674X1WlPTTngZys/cF04oIovopOLkz23luoMGtrvd9oClEady/IPzZHjPCu/vffX+xL6qCGja0A7B4SQU2NvlGPPdZsISIReoY8wYRz3nnhqhUdamvF4Hn8caE7njTJ+zwJI2gqX+d+r6EqAwpjBH/+c3TZ1dX6AeL/tt69hWoiLpIyjkJ9VwHuvkYhjECHpG4Xjj02XIKS5fXqFTuuhhFt20ZLBPX1wBdfFPYeAPj9791rU52oYydOwAoJ0z5OWPkA8OqrQgoAot3Z53MuooTYPRjBPfcIEzM/pkwJ2jkD3okhTDVUVxefczc0FC6S+5GEEZi+Yd99XRE+CV4PhKjWI4oRRA2IOPCXW18P3Hdf4eX60bq10OHvE2E1FQdyoiomI7jlFnE6XSIOUxgxwhtn1IRVq+KpvsKYahxGAAS90iaBfP+JBgeAgKiXzp3dfiPrqU+faGni8svNapu6Ou+CM2xs+j0C+9G6dVBtWEbsHqqhuhAX0RKmDhzGCI48Mr5YrSLEjXAiJGEEJkydmp9ztmHD9Pe7dvX+VhmB7myAaiKZL4q9qtZh7FghWerMEAuBbj8gX3Wd32gh6b6ODsV0B/7CC6XXfcetO2looaZXvcLmg9mzxaZ3XZ0op9CxGSd0aRMhNiVElAawEMBaZj6GiB4CMBzATgCvApjFzDudGMa3ADgKwBYApzJzjOjgZURY58pn0D71VP60qCgGIyg2VGulAQO8aptiqFR0aGz0WqiUAvPnF7/MzZv1KonaWk+s3rywbl2yDfCmQD6SZ6mQTgf7oy4wlIqDDgL228/8XFVd9utXeWOzACRRDZ0LYKny+yEA/QEMBtAKwOnO/YkA+jp/MwHMKZzMAiAHonR5DHjt5IsdICWdFuaUheLeeyuTEagHvPwuAkybb4WCqLImmbiQh4f8aN06vn28CV26FMcQoL4+eCZFh5kzxf9ymj0ecUR85pdOCwl16FD3FHQUFi4Evv/9eGkrcWwWgFgSARH1AHA0gJ9BBKQHMz+lPH8VgHTsPgXAAyzCGr1MRHVE1JWZNU7AmwA1NcHJ/tFH3ZVsEtPTOCjWQJk+Hbj22mSdbfXq6DSFIuz7jj9eGwLRogj46KPSlFtTEzyTosNddwFvvy2knHJBBjiKgxNPFIcNL7igNLRcemnhm+sVhLiqoV8DmA0gsMtDRNUAToaQGACgOwA17NMa5946X76ZEBIDeqmr9aaAOpnNmVNxhztySKWSqVtkHIZygSiZdYZFfFRCH41z5qZScP31pSs7SoswdWp8w5EYYWGbApGMgIiOAbCRmV8nojGaJHcA+Dsz/0Nm0aQJ1BwzzwUwFwCGDx9eZP1MAsQVG+Ng4MBAIJGC0K1bfFO2pkJzmQheeqncFBQP116bfz8odns1l/YvJ6LcdKhQfROVEXEkgkMATCaiowC0BLAXET3IzN8nop8C6ARAdcqxBoC6NO0BoERybYXh4ovdQ0DFwNNPN935gLioNHpMKCaDLzfCnOGFYdky795YoSj2fppFxSByVDPzpczcg5kbAUwFMN9hAqcDmADgRGZWFdlPADiFBEYC+Lxs+wPNHW3a5OcTpVT47LOKOxpvEYJ+/YrfXlYi2C1RiCHrnQBWAXjJCV/3Z2a+BsBTEKajyyHMR6cXSqRFhaDCjsVbNDGsRLDbIhEjYOYXAbzoXGvzOtZC8YMGlwu2U1tYJEOrVqU7K2JRVlTO0TYLC4vKxmOP7Va28xYuLCOwsLCIh/r6clNgUSI0ExMQCwsLC4tSwTICCwsLiz0clhFYWFhY7OGwjMDCwsJiD4dlBBYWFhZ7OCwjsLCwsNjDYRmBhYWFxR4OywgsLCws9nAQV4CrBSLaBOG3KB90BPBxEckpNix9haGS6atk2gBLX6GoZPokbXszc6dCC6sIRlAIiGghMw8vNx0mWPoKQyXTV8m0AZa+QlHJ9BWbNqsasrCwsNjDYRmBhYWFxR6O3YERzC03ARGw9BWGSqavkmkDLH2FopLpKyptzX6PwMLCwsKiMOwOEoGFhYWFRQGwjMDCwsJiD0ezZgRE9G0iWkZEy4nokjK8vycRvUBES4nobSI617l/FRGtJaJFzt9RSp5LHXqXEdGEJqDxAyJa4tCx0LlXT0TPEtF7zv/2zn0iov906FtMRMNKTNt+Sh0tIqIviOi8ctYfEd1LRBuJ6C3lXuL6IqJpTvr3iGhaien7BRG949DwFyKqc+43EtFWpR7vVPIc5PSL5c43FByV3kBb4rYs1bg20PeIQtsHRLTIud+kdeeUa5pPSt//mLlZ/gFIA3gfQB8ALQC8CWBgE9PQFcAw57odgHcBDARwFYCLNOkHOnTWAOjt0J8uMY0fAOjou3cjgEuc60sA3OBcHwXgaQAEYCSAV5q4PdcD2Luc9QdgNIBhAN7Kt74A1ANY4fxv71y3LyF94wFUOdc3KPQ1qul85bwK4JsO7U8DmFgi2hK1ZSnHtY4+3/ObAFxZjrpzyjXNJyXvf81ZIjgYwHJmXsHMOwA8DGBKUxLAzOuY+V/O9ZcAlgLoHpJlCoCHmXk7M68EsBziO5oaUwDc71zfD+BY5f4DLPAygDoi6tpENB0B4H1mDjthXvL6Y+a/A/hE894k9TUBwLPM/AkzfwrgWQDfLhV9zPwMM+9yfr4MoEdYGQ6NezHzSyxmjgeUbyoqbSEwtWXJxnUYfc6q/nsA/hBWRqnqzqHPNJ+UvP81Z0bQHcCHyu81CJ+ESwoiagRwIIBXnFtnO+LavVKUQ3loZgDPENHrRDTTudfAzOsA0fkAdC4jfRJT4R2ElVJ/QPL6Kmc9zoBYJUr0JqI3iOhvRHSYc6+7Q1NT0ZekLctVd4cB2MDM7yn3ylZ3vvmk5P2vOTMCnV6uLLawRNQWwJ8AnMfMXwCYA2AfAEMBrIMQOYHy0HwIMw8DMBHAWUQ0OiRtWeqUiFoAmAzgUedWJdVfGEz0lKseLwOwC8BDzq11AHox84EALgDweyLaq4npS9qW5WrjE+FdiJSt7jTziTGpgZbENDZnRrAGQE/ldw8AHzU1EURUDdFoDzHznwGAmTcwc4aZswB+A1d90eQ0M/NHzv+NAP7i0LJBqnyc/xvLRZ+DiQD+xcwbHForpv4cJK2vJqfT2RA8BsBJjsoCjtpls3P9OoTuvZ9Dn6o+Khl9ebRlOequCsDxAB5R6C5L3enmEzRB/2vOjOA1AH2JqLezopwK4ImmJMDRK94DYCkz/0q5r+rVjwMgrRSeADCViGqIqDeAvhAbT6Wirw0RtZPXEJuKbzl0SEuCaQD+qtB3imONMBLA51IkLTE8q7FKqT8FSetrHoDxRNTeUYWMd+6VBET0bQA/BjCZmbco9zsRUdq57gNRXyscGr8kopFOHz5F+aZi05a0LcsxrscBeIeZcyqfctSdaT5BU/S/Yux2l+sPYtf8XQhufVkZ3n8ohMi1GMAi5+8oAL8DsMS5/wSArkqeyxx6l6FI1gYh9PWBsLp4E8Dbso4AdADwPID3nP/1zn0CcLtD3xIAw5ugDlsD2AygVrlXtvqDYEjrAOyEWFmdlk99Qejqlzt/00tM33IInbDsg3c6ab/jtPubAP4FYJJSznCISfl9ALfB8TJQAtoSt2WpxrWOPuf+fS5DFOUAAABaSURBVADO8KVt0rpzyjXNJyXvf9bFhIWFhcUejuasGrKwsLCwKAIsI7CwsLDYw2EZgYWFhcUeDssILCwsLPZwWEZgYWFhsYfDMgILCwuLPRyWEVhYWFjs4fh/AwZNJasZvJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.datatechnotes.com/2019/12/how-to-fit-regression-data-with-cnn.html\n",
    "x_ax = range(len(ypred))\n",
    "plt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training loss','Validation loss'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Novel Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# from the first Fully-Connected layer \n",
    "layer_name = 'dense_1'\n",
    "intermediate_layer_model = Model(inputs=clf_cnn.input,\n",
    "                                 outputs=clf_cnn.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features of the train dataset to use it in future.\n",
    "out_cnn_train = intermediate_layer_model.predict(x_train)\n",
    "# Save the features of the test dataset to use it in future.\n",
    "out_cnn_test = intermediate_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (from CNN) Shape: (7654, 1)\n",
      "Training Labels (from CNN) Shape: (7654,) \n",
      "\n",
      "Test Features (from CNN) Shape: (1914, 1)\n",
      "Test Labels (from CNN) Shape: (1914,) \n",
      "\n",
      "Test Features original Shape: (7654, 4, 1)\n",
      "Test Features original Shape: (1914, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features (from CNN) Shape:', out_cnn_train.shape)\n",
    "print('Training Labels (from CNN) Shape:', y_train.shape,'\\n')\n",
    "\n",
    "print('Test Features (from CNN) Shape:', out_cnn_test.shape)\n",
    "print('Test Labels (from CNN) Shape:', y_test.shape,'\\n')\n",
    "\n",
    "print('Test Features original Shape:', x_train_.shape)\n",
    "print('Test Features original Shape:', x_test_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + Random Forest + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "djinn example\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:263: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:266: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:302: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:286: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:328: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:333: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:334: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:335: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch: 0001 cost= 0.397026605\n",
      "Epoch: 0002 cost= 0.068964306\n",
      "Epoch: 0003 cost= 0.040548795\n",
      "Epoch: 0004 cost= 0.032680609\n",
      "Epoch: 0005 cost= 0.023453800\n",
      "Epoch: 0006 cost= 0.014350142\n",
      "Epoch: 0007 cost= 0.007974462\n",
      "Epoch: 0008 cost= 0.005441121\n",
      "Epoch: 0009 cost= 0.005325003\n",
      "Epoch: 0010 cost= 0.005386843\n",
      "Epoch: 0011 cost= 0.005369321\n",
      "Epoch: 0012 cost= 0.005291299\n",
      "Epoch: 0013 cost= 0.005098262\n",
      "Epoch: 0014 cost= 0.005246503\n",
      "Epoch: 0015 cost= 0.005210182\n",
      "Epoch: 0016 cost= 0.005095919\n",
      "Epoch: 0017 cost= 0.005161770\n",
      "Epoch: 0018 cost= 0.005079293\n",
      "Epoch: 0019 cost= 0.005623035\n",
      "Epoch: 0020 cost= 0.005421253\n",
      "Epoch: 0021 cost= 0.005145343\n",
      "Epoch: 0022 cost= 0.005265036\n",
      "Epoch: 0023 cost= 0.005455244\n",
      "Epoch: 0024 cost= 0.005382966\n",
      "Epoch: 0025 cost= 0.005376242\n",
      "Epoch: 0026 cost= 0.005275695\n",
      "Epoch: 0027 cost= 0.005326775\n",
      "Epoch: 0028 cost= 0.005283016\n",
      "Epoch: 0029 cost= 0.005236659\n",
      "Epoch: 0030 cost= 0.005348047\n",
      "Epoch: 0031 cost= 0.005279565\n",
      "Epoch: 0032 cost= 0.005364367\n",
      "Epoch: 0033 cost= 0.005374223\n",
      "Epoch: 0034 cost= 0.005458954\n",
      "Epoch: 0035 cost= 0.005386603\n",
      "Epoch: 0036 cost= 0.005244384\n",
      "Epoch: 0037 cost= 0.005365672\n",
      "Epoch: 0038 cost= 0.005499906\n",
      "Epoch: 0039 cost= 0.005555415\n",
      "Epoch: 0040 cost= 0.005359365\n",
      "Epoch: 0041 cost= 0.005311882\n",
      "Epoch: 0042 cost= 0.005124856\n",
      "Epoch: 0043 cost= 0.005469853\n",
      "Epoch: 0044 cost= 0.005292382\n",
      "Epoch: 0045 cost= 0.005240780\n",
      "Epoch: 0046 cost= 0.005251760\n",
      "Epoch: 0047 cost= 0.005378743\n",
      "Epoch: 0048 cost= 0.005303109\n",
      "Epoch: 0049 cost= 0.005218561\n",
      "Epoch: 0050 cost= 0.005223930\n",
      "Epoch: 0051 cost= 0.005288543\n",
      "Epoch: 0052 cost= 0.005238438\n",
      "Epoch: 0053 cost= 0.005446422\n",
      "Epoch: 0054 cost= 0.005494825\n",
      "Epoch: 0055 cost= 0.005510128\n",
      "Epoch: 0056 cost= 0.005331006\n",
      "Epoch: 0057 cost= 0.005032993\n",
      "Epoch: 0058 cost= 0.005526431\n",
      "Epoch: 0059 cost= 0.005415532\n",
      "Epoch: 0060 cost= 0.005145262\n",
      "Epoch: 0061 cost= 0.005099183\n",
      "Epoch: 0062 cost= 0.005453058\n",
      "Epoch: 0063 cost= 0.005319496\n",
      "Epoch: 0064 cost= 0.005163223\n",
      "Epoch: 0065 cost= 0.005105533\n",
      "Epoch: 0066 cost= 0.005190025\n",
      "Epoch: 0067 cost= 0.005268997\n",
      "Epoch: 0068 cost= 0.005319866\n",
      "Epoch: 0069 cost= 0.005411067\n",
      "Epoch: 0070 cost= 0.005507754\n",
      "Epoch: 0071 cost= 0.005559743\n",
      "Epoch: 0072 cost= 0.005377450\n",
      "Epoch: 0073 cost= 0.005394583\n",
      "Epoch: 0074 cost= 0.005501980\n",
      "Epoch: 0075 cost= 0.005470423\n",
      "Epoch: 0076 cost= 0.005354483\n",
      "Epoch: 0077 cost= 0.005360701\n",
      "Epoch: 0078 cost= 0.005314980\n",
      "Epoch: 0079 cost= 0.005151432\n",
      "Epoch: 0080 cost= 0.005456092\n",
      "Epoch: 0081 cost= 0.005223834\n",
      "Epoch: 0082 cost= 0.005596256\n",
      "Epoch: 0083 cost= 0.005248539\n",
      "Epoch: 0084 cost= 0.005386599\n",
      "Epoch: 0085 cost= 0.005654549\n",
      "Epoch: 0086 cost= 0.005524466\n",
      "Epoch: 0087 cost= 0.005289742\n",
      "Epoch: 0088 cost= 0.005279721\n",
      "Epoch: 0089 cost= 0.005169427\n",
      "Epoch: 0090 cost= 0.005054911\n",
      "Epoch: 0091 cost= 0.005488786\n",
      "Epoch: 0092 cost= 0.005457475\n",
      "Epoch: 0093 cost= 0.005085309\n",
      "Epoch: 0094 cost= 0.005361041\n",
      "Epoch: 0095 cost= 0.005435504\n",
      "Epoch: 0096 cost= 0.005540047\n",
      "Epoch: 0097 cost= 0.005319872\n",
      "Epoch: 0098 cost= 0.005235434\n",
      "Epoch: 0099 cost= 0.005194475\n",
      "Epoch: 0100 cost= 0.005299108\n",
      "Epoch: 0101 cost= 0.005227783\n",
      "Epoch: 0102 cost= 0.005258145\n",
      "Epoch: 0103 cost= 0.005408798\n",
      "Epoch: 0104 cost= 0.005209111\n",
      "Epoch: 0105 cost= 0.005442307\n",
      "Epoch: 0106 cost= 0.005477681\n",
      "Epoch: 0107 cost= 0.005150795\n",
      "Epoch: 0108 cost= 0.005106708\n",
      "Epoch: 0109 cost= 0.005152713\n",
      "Epoch: 0110 cost= 0.005410355\n",
      "Epoch: 0111 cost= 0.005457591\n",
      "Epoch: 0112 cost= 0.005313238\n",
      "Epoch: 0113 cost= 0.005380669\n",
      "Epoch: 0114 cost= 0.005345464\n",
      "Epoch: 0115 cost= 0.005407477\n",
      "Epoch: 0116 cost= 0.005495190\n",
      "Epoch: 0117 cost= 0.005452192\n",
      "Epoch: 0118 cost= 0.005476033\n",
      "Epoch: 0119 cost= 0.005402871\n",
      "Epoch: 0120 cost= 0.005235794\n",
      "Epoch: 0121 cost= 0.005361823\n",
      "Epoch: 0122 cost= 0.005397627\n",
      "Epoch: 0123 cost= 0.005312416\n",
      "Epoch: 0124 cost= 0.005209005\n",
      "Epoch: 0125 cost= 0.005028640\n",
      "Epoch: 0126 cost= 0.005153079\n",
      "Epoch: 0127 cost= 0.005306738\n",
      "Epoch: 0128 cost= 0.005224865\n",
      "Epoch: 0129 cost= 0.005251054\n",
      "Epoch: 0130 cost= 0.005335116\n",
      "Epoch: 0131 cost= 0.005168625\n",
      "Epoch: 0132 cost= 0.005259469\n",
      "Epoch: 0133 cost= 0.005219785\n",
      "Epoch: 0134 cost= 0.005428911\n",
      "Epoch: 0135 cost= 0.005295118\n",
      "Epoch: 0136 cost= 0.005540802\n",
      "Epoch: 0137 cost= 0.005476904\n",
      "Epoch: 0138 cost= 0.005538681\n",
      "Epoch: 0139 cost= 0.005445266\n",
      "Epoch: 0140 cost= 0.005377725\n",
      "Epoch: 0141 cost= 0.005293822\n",
      "Epoch: 0142 cost= 0.005291875\n",
      "Epoch: 0143 cost= 0.005529591\n",
      "Epoch: 0144 cost= 0.005258002\n",
      "Epoch: 0145 cost= 0.005183207\n",
      "Epoch: 0146 cost= 0.005404891\n",
      "Epoch: 0147 cost= 0.005245997\n",
      "Epoch: 0148 cost= 0.005108007\n",
      "Epoch: 0149 cost= 0.005270956\n",
      "Epoch: 0150 cost= 0.005159523\n",
      "Epoch: 0151 cost= 0.005054907\n",
      "Epoch: 0152 cost= 0.005509085\n",
      "Epoch: 0153 cost= 0.005117555\n",
      "Epoch: 0154 cost= 0.005244509\n",
      "Epoch: 0155 cost= 0.005207388\n",
      "Epoch: 0156 cost= 0.005297019\n",
      "Epoch: 0157 cost= 0.005558264\n",
      "Epoch: 0158 cost= 0.005455187\n",
      "Epoch: 0159 cost= 0.005176717\n",
      "Epoch: 0160 cost= 0.005415343\n",
      "Epoch: 0161 cost= 0.005297592\n",
      "Epoch: 0162 cost= 0.005400204\n",
      "Epoch: 0163 cost= 0.005398931\n",
      "Epoch: 0164 cost= 0.005411385\n",
      "Epoch: 0165 cost= 0.005314507\n",
      "Epoch: 0166 cost= 0.005364598\n",
      "Epoch: 0167 cost= 0.005180478\n",
      "Epoch: 0168 cost= 0.005207200\n",
      "Epoch: 0169 cost= 0.005340013\n",
      "Epoch: 0170 cost= 0.005325239\n",
      "Epoch: 0171 cost= 0.005032576\n",
      "Epoch: 0172 cost= 0.005407912\n",
      "Epoch: 0173 cost= 0.005396442\n",
      "Epoch: 0174 cost= 0.005335682\n",
      "Epoch: 0175 cost= 0.005340591\n",
      "Epoch: 0176 cost= 0.005102432\n",
      "Epoch: 0177 cost= 0.005084175\n",
      "Epoch: 0178 cost= 0.005114808\n",
      "Epoch: 0179 cost= 0.005234431\n",
      "Epoch: 0180 cost= 0.005299553\n",
      "Epoch: 0181 cost= 0.005360865\n",
      "Epoch: 0182 cost= 0.005547187\n",
      "Epoch: 0183 cost= 0.005335616\n",
      "Epoch: 0184 cost= 0.005374821\n",
      "Epoch: 0185 cost= 0.005341809\n",
      "Epoch: 0186 cost= 0.005332135\n",
      "Epoch: 0187 cost= 0.005473316\n",
      "Epoch: 0188 cost= 0.005409888\n",
      "Epoch: 0189 cost= 0.005231275\n",
      "Epoch: 0190 cost= 0.005285801\n",
      "Epoch: 0191 cost= 0.005048214\n",
      "Epoch: 0192 cost= 0.005458119\n",
      "Epoch: 0193 cost= 0.005306318\n",
      "Epoch: 0194 cost= 0.005320388\n",
      "Epoch: 0195 cost= 0.005461762\n",
      "Epoch: 0196 cost= 0.005526314\n",
      "Epoch: 0197 cost= 0.005147669\n",
      "Epoch: 0198 cost= 0.005278917\n",
      "Epoch: 0199 cost= 0.005258299\n",
      "Epoch: 0200 cost= 0.005258352\n",
      "Epoch: 0201 cost= 0.005338857\n",
      "Epoch: 0202 cost= 0.005129755\n",
      "Epoch: 0203 cost= 0.005159888\n",
      "Epoch: 0204 cost= 0.005350788\n",
      "Epoch: 0205 cost= 0.005402826\n",
      "Epoch: 0206 cost= 0.005141051\n",
      "Epoch: 0207 cost= 0.005363248\n",
      "Epoch: 0208 cost= 0.005350288\n",
      "Epoch: 0209 cost= 0.005255286\n",
      "Epoch: 0210 cost= 0.005146574\n",
      "Optimization Finished!\n",
      "Model saved in: ./reg_djinn_test_tree0.ckpt\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn.py:276: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./reg_djinn_test_tree0.ckpt\n",
      "Model 0 restored\n",
      "Mean Squa Error : 30.270413599117287\n",
      "Mean Abso Error : 4.384470304770156\n",
      "Expl. Variance  : 0.8992686547699327 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from djinn import djinn\n",
    "print(\"djinn example\")    \n",
    "modelname=\"reg_djinn_test\"   # name the model\n",
    "ntrees=1                 # number of trees = number of neural nets in ensemble\n",
    "maxdepth=5               # max depth of tree -- optimize this for each data set\n",
    "dropout_keep=1.0         # dropout typically set to 1 for non-Bayesian models\n",
    "\n",
    "#initialize the model\n",
    "model=djinn.DJINN_Regressor(ntrees,maxdepth,dropout_keep)\n",
    "x_train, y_train, x_test, y_test = out_cnn_train, y_train, out_cnn_test, y_test\n",
    "\n",
    "# find optimal settings: this function returns dict with hyper-parameters\n",
    "# each djinn function accepts random seeds for reproducible behavior\n",
    "# optimal=model.get_hyperparameters(x_train, y_train, random_state=42)\n",
    "# batchsize=optimal['batch_size']\n",
    "# learnrate=optimal['learn_rate']\n",
    "# epochs=optimal['epochs']\n",
    "\n",
    "batchsize=304\n",
    "learnrate=0.002474296684203603\n",
    "epochs=210\n",
    " \n",
    "# train the model with hyperparameters determined above\n",
    "model.train(x_train,y_train,epochs=epochs,learn_rate=learnrate, batch_size=batchsize, \n",
    "              display_step=1, save_files=True, file_name=modelname, \n",
    "              save_model=True,model_name=modelname, random_state=1)\n",
    "\n",
    "# *note there is a function model.fit(x_train,y_train, ... ) that wraps \n",
    "# get_hyperparameters() and train(), so that you do not have to manually\n",
    "# pass hyperparameters to train(). However, get_hyperparameters() can\n",
    "# be expensive, so I recommend running it once per dataset and using those\n",
    "# hyperparameter values in train() to save computational time\n",
    "\n",
    "# make predictions\n",
    "m=model.predict(x_test) #returns the median prediction if more than one tree\n",
    "\n",
    "#evaluate results\n",
    "evaluate(y_test,m)\n",
    "\n",
    "#close model \n",
    "model.close_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + ( SVM, XGB, DTree, ExtraTrees, RandomFores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 30.275702180095543\n",
      "Mean Abso Error : 4.3457315649952255\n",
      "Expl. Variance  : 0.8991320953958977 \n",
      "\n",
      "================================================================================\n",
      "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False) \n",
      "\n",
      "Mean Squa Error : 6.856744280844701e+26\n",
      "Mean Abso Error : 26168103288539.19\n",
      "Expl. Variance  : -3.0181021315611964e+21 \n",
      "\n",
      "================================================================================\n",
      "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 31.694207377744995\n",
      "Mean Abso Error : 4.489749129071673\n",
      "Expl. Variance  : 0.8942845213754823 \n",
      "\n",
      "================================================================================\n",
      "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
      "          fit_path=True, max_iter=500, normalize=True, positive=False,\n",
      "          precompute='auto', verbose=False) \n",
      "\n",
      "Mean Squa Error : 299.79091049982316\n",
      "Mean Abso Error : 15.038168662139988\n",
      "Expl. Variance  : 0.0 \n",
      "\n",
      "================================================================================\n",
      "ARDRegression(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, threshold_lambda=10000.0, tol=0.001,\n",
      "              verbose=False) \n",
      "\n",
      "Mean Squa Error : 31.694207425939414\n",
      "Mean Abso Error : 4.489749136755418\n",
      "Expl. Variance  : 0.8942845212146168 \n",
      "\n",
      "================================================================================\n",
      "PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=1000,\n",
      "                           n_iter_no_change=5, random_state=None, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "Mean Squa Error : 45.04039453033918\n",
      "Mean Abso Error : 5.452522119949576\n",
      "Expl. Variance  : 0.8944782171233048 \n",
      "\n",
      "================================================================================\n",
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "                  max_subpopulation=10000, n_jobs=None, n_subsamples=None,\n",
      "                  random_state=None, tol=0.001, verbose=False) \n",
      "\n",
      "Mean Squa Error : 33.489195168908644\n",
      "Mean Abso Error : 4.558381355493691\n",
      "Expl. Variance  : 0.894465164352948 \n",
      "\n",
      "================================================================================\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) \n",
      "\n",
      "Mean Squa Error : 31.69408985799226\n",
      "Mean Abso Error : 4.489729301109833\n",
      "Expl. Variance  : 0.8942849207232743 \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/41925157/logisticregression-unknown-label-type-continuous-using-sklearn-in-python\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVR(gamma='scale'),\n",
    "    linear_model.SGDRegressor(),\n",
    "    linear_model.BayesianRidge(),\n",
    "    linear_model.LassoLars(),\n",
    "    linear_model.ARDRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.TheilSenRegressor(),\n",
    "    linear_model.LinearRegression()\n",
    "              ]\n",
    "\n",
    "for item in classifiers:\n",
    "    print(item,'\\n')\n",
    "    clf = item\n",
    "    clf.fit(out_cnn_train, y_train)\n",
    "    #print(clf.predict(predictionData),'\\n')\n",
    "    #Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "    m = clf.predict(out_cnn_test)\n",
    "    #evaluate results\n",
    "    mse=sklearn.metrics.mean_squared_error(y_test,m)\n",
    "    mabs=sklearn.metrics.mean_absolute_error(y_test,m)\n",
    "    exvar=sklearn.metrics.explained_variance_score(y_test,m)   \n",
    "    print('Mean Squa Error :',mse)\n",
    "    print('Mean Abso Error :',mabs)\n",
    "    print('Expl. Variance  :',exvar,'\\n')\n",
    "    print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN XGBRegressor      \n",
      "Mean Squa Error : 32.2544146089795\n",
      "Mean Abso Error : 4.462893221385801\n",
      "Expl. Variance  : 0.8924105921727137 \n",
      "\n",
      "CNN ExtraTreesRegressor      \n",
      "Mean Squa Error : 48.017189945271696\n",
      "Mean Abso Error : 5.345745820271684\n",
      "Expl. Variance  : 0.8398399504220132 \n",
      "\n",
      "CNN DecisionTreeRegressor      \n",
      "Mean Squa Error : 57.54746899164054\n",
      "Mean Abso Error : 5.8583699059561125\n",
      "Expl. Variance  : 0.8080818247488795 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "from xgboost import XGBRegressor\n",
    "XGBModel = XGBRegressor()\n",
    "XGBModel.fit(out_cnn_train, y_train , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(out_cnn_test)\n",
    "print('CNN XGBRegressor      ')\n",
    "evaluate(y_test,XGBpredictions)\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "Ext = ExtraTreesRegressor(n_estimators=10)\n",
    "Ext.fit(out_cnn_train, y_train)\n",
    "#Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "predictionsCNN_Ext = Ext.predict(out_cnn_test)\n",
    "print('CNN ExtraTreesRegressor      ')\n",
    "evaluate(y_test,predictionsCNN_Ext)\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "clf_dt = tree.DecisionTreeRegressor()\n",
    "clf_dt.fit(out_cnn_train, y_train)\n",
    "# Get the mean absolute error on the validation data :\n",
    "clf_dtpredictions = clf_dt.predict(out_cnn_test)\n",
    "print('CNN DecisionTreeRegressor      ')\n",
    "evaluate(y_test,clf_dtpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7654, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cnn_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "7654/7654 [==============================] - 2s 289us/step - loss: 1471112.0939\n",
      "Epoch 2/50\n",
      "7654/7654 [==============================] - 2s 241us/step - loss: 1295852.6810\n",
      "Epoch 3/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1301732.1349\n",
      "Epoch 4/50\n",
      "7654/7654 [==============================] - 2s 243us/step - loss: 1302407.9748\n",
      "Epoch 5/50\n",
      "7654/7654 [==============================] - 2s 233us/step - loss: 1294576.7993\n",
      "Epoch 6/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1298579.8777\n",
      "Epoch 7/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1303236.6790\n",
      "Epoch 8/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1297037.0035\n",
      "Epoch 9/50\n",
      "7654/7654 [==============================] - 2s 255us/step - loss: 1297140.5023\n",
      "Epoch 10/50\n",
      "7654/7654 [==============================] - 2s 246us/step - loss: 1296538.5429\n",
      "Epoch 11/50\n",
      "7654/7654 [==============================] - 2s 235us/step - loss: 1297086.4914\n",
      "Epoch 12/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1292484.3521\n",
      "Epoch 13/50\n",
      "7654/7654 [==============================] - 2s 237us/step - loss: 1295299.0330\n",
      "Epoch 14/50\n",
      "7654/7654 [==============================] - 2s 236us/step - loss: 1294566.4951\n",
      "Epoch 15/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1292527.4410\n",
      "Epoch 16/50\n",
      "7654/7654 [==============================] - 2s 238us/step - loss: 1294693.4597\n",
      "Epoch 17/50\n",
      "7654/7654 [==============================] - 2s 234us/step - loss: 1293505.2593\n",
      "Epoch 18/50\n",
      "7654/7654 [==============================] - 2s 267us/step - loss: 1292493.5955\n",
      "Epoch 19/50\n",
      "7654/7654 [==============================] - 2s 253us/step - loss: 1291473.5410\n",
      "Epoch 20/50\n",
      "7654/7654 [==============================] - 2s 248us/step - loss: 1293456.4878\n",
      "Epoch 21/50\n",
      "7654/7654 [==============================] - 2s 252us/step - loss: 1290357.8051\n",
      "Epoch 22/50\n",
      "7654/7654 [==============================] - 2s 263us/step - loss: 1288451.0200\n",
      "Epoch 23/50\n",
      "7654/7654 [==============================] - 2s 248us/step - loss: 1292790.7949\n",
      "Epoch 24/50\n",
      "7654/7654 [==============================] - 2s 245us/step - loss: 1289624.4777\n",
      "Epoch 25/50\n",
      "7654/7654 [==============================] - 2s 230us/step - loss: 1288597.0313\n",
      "Epoch 26/50\n",
      "7654/7654 [==============================] - 2s 251us/step - loss: 1288499.7692\n",
      "Epoch 27/50\n",
      "7654/7654 [==============================] - 2s 244us/step - loss: 1289134.2662\n",
      "Epoch 28/50\n",
      "7654/7654 [==============================] - 2s 226us/step - loss: 1288468.9345\n",
      "Epoch 29/50\n",
      "7654/7654 [==============================] - 2s 229us/step - loss: 1287181.9289\n",
      "Epoch 30/50\n",
      "7654/7654 [==============================] - 2s 229us/step - loss: 1287766.3877\n",
      "Epoch 31/50\n",
      "7654/7654 [==============================] - 2s 229us/step - loss: 1283933.7236 0s - loss: 1\n",
      "Epoch 32/50\n",
      "7654/7654 [==============================] - 2s 227us/step - loss: 1280668.6220\n",
      "Epoch 33/50\n",
      "7654/7654 [==============================] - 2s 226us/step - loss: 1284733.5498\n",
      "Epoch 34/50\n",
      "7654/7654 [==============================] - 2s 226us/step - loss: 1282179.2044\n",
      "Epoch 35/50\n",
      "7654/7654 [==============================] - 2s 248us/step - loss: 1280272.1636\n",
      "Epoch 36/50\n",
      "7654/7654 [==============================] - 2s 244us/step - loss: 1279479.8413\n",
      "Epoch 37/50\n",
      "7654/7654 [==============================] - 2s 228us/step - loss: 1277915.7929\n",
      "Epoch 38/50\n",
      "7654/7654 [==============================] - 2s 228us/step - loss: 1279298.7932\n",
      "Epoch 39/50\n",
      "7654/7654 [==============================] - 2s 227us/step - loss: 1276853.6241\n",
      "Epoch 40/50\n",
      "7654/7654 [==============================] - 2s 227us/step - loss: 1277696.6539\n",
      "Epoch 41/50\n",
      "7654/7654 [==============================] - 2s 236us/step - loss: 1270880.4194\n",
      "Epoch 42/50\n",
      "7654/7654 [==============================] - 2s 227us/step - loss: 1265895.4647\n",
      "Epoch 43/50\n",
      "7654/7654 [==============================] - 2s 228us/step - loss: 1270197.0039\n",
      "Epoch 44/50\n",
      "7654/7654 [==============================] - 2s 258us/step - loss: 1265260.6140\n",
      "Epoch 45/50\n",
      "7654/7654 [==============================] - 2s 244us/step - loss: 1264081.9596\n",
      "Epoch 46/50\n",
      "7654/7654 [==============================] - 2s 229us/step - loss: 1258701.0882\n",
      "Epoch 47/50\n",
      "7654/7654 [==============================] - 2s 227us/step - loss: 1255418.4403\n",
      "Epoch 48/50\n",
      "7654/7654 [==============================] - 2s 228us/step - loss: 1252226.5278\n",
      "Epoch 49/50\n",
      "7654/7654 [==============================] - 2s 230us/step - loss: 1248779.1006\n",
      "Epoch 50/50\n",
      "7654/7654 [==============================] - 2s 226us/step - loss: 1234550.8173\n",
      "1914/1914 [==============================] - 0s 105us/step\n",
      "CNN MLP Mean Squa Error : 1376.359289655173\n",
      "CNN MLP Mean Abso Error : 32.81110762800418\n",
      "CNN MLP Expl. Variance  : 0.0\n"
     ]
    }
   ],
   "source": [
    "# Regression Example With Boston Dataset: Baseline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(128, input_dim=out_cnn_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(64, activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "clf_MLP = KerasClassifier(build_fn = baseline_model, epochs = 50, batch_size=5, verbose=1)\n",
    "clf_MLP.fit(out_cnn_train, y_train)\n",
    "y_predmlp = clf_MLP.predict(out_cnn_test)\n",
    "\n",
    "#print(\"CNN MLP Model.evaluate : \",clf_MLP.evaluate(out_cnn_test, y_train),'\\n')\n",
    "#evaluate results\n",
    "mse=sklearn.metrics.mean_squared_error(y_test,y_predmlp)\n",
    "mabs=sklearn.metrics.mean_absolute_error(y_test,y_predmlp)\n",
    "exvar=sklearn.metrics.explained_variance_score(y_test,y_predmlp)   \n",
    "print('CNN MLP Mean Squa Error :',mse)\n",
    "print('CNN MLP Mean Abso Error :',mabs)\n",
    "print('CNN MLP Expl. Variance  :',exvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by RandomForest, ExtraTrees, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = x_train_.reshape(x_train_.shape[0], x_train_.shape[1])\n",
    "x_test_  = x_test_.reshape(x_test_.shape[0], x_test_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN RandomForestRegressor      \n",
      "Mean Squa Error : 9.741312037706342\n",
      "Mean Abso Error : 2.2888140543364597\n",
      "Expl. Variance  : 0.967506932557853 \n",
      "\n",
      "CNN XGBRegressor      \n",
      "Mean Squa Error : 9.160980036551427\n",
      "Mean Abso Error : 2.2364909957519012\n",
      "Expl. Variance  : 0.9694422805677624 \n",
      "\n",
      "CNN ExtraTreesRegressor      \n",
      "Mean Squa Error : 11.593332050679194\n",
      "Mean Abso Error : 2.4890391849529783\n",
      "Expl. Variance  : 0.9613560113816303 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier : from dataset originl\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(x_train_, y_train_)\n",
    "predictions = rf.predict(x_test_)\n",
    "print('CNN RandomForestRegressor      ')\n",
    "evaluate(y_test_,predictions)\n",
    "\n",
    "\n",
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "from xgboost import XGBRegressor\n",
    "XGBModel = XGBRegressor()\n",
    "XGBModel.fit(x_train_, y_train_ , verbose=False)\n",
    "# Get the mean absolute error on the validation data :\n",
    "XGBpredictions = XGBModel.predict(x_test_)\n",
    "print('CNN XGBRegressor      ')\n",
    "evaluate(y_test_,XGBpredictions)\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "Ext = ExtraTreesRegressor(n_estimators=10)\n",
    "Ext.fit(x_train_, y_train_)\n",
    "#Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "predictionsCNN_Ext = Ext.predict(x_test_)\n",
    "print('CNN ExtraTreesRegressor      ')\n",
    "evaluate(y_test_,predictionsCNN_Ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
