{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "try: from sklearn.model_selection import train_test_split\n",
    "except: from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the train & test and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data, split into training/testing groups\n",
    "d=datasets.load_breast_cancer()\n",
    "X=d.data\n",
    "Y=d.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(X), np.asarray(Y), test_size=0.3, shuffle= True)\n",
    "x_train_, x_test_, y_train_, y_test_ = x_train, x_test, y_train, y_test\n",
    "# The known number of output classes.\n",
    "num_classes = len(np.unique(y_train))\n",
    "# Input image dimensions\n",
    "input_shape = (X.shape[1],)\n",
    "\n",
    "# Convert class vectors to binary class matrices. This uses 1 hot encoding.\n",
    "y_train_binary = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_binary = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], X.shape[1],1)\n",
    "x_test = x_test.reshape(x_test.shape[0], X.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]*x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation structure of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CNN\n",
    "def CNN_net():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=100, kernel_size=10, activation='relu', input_shape=(X.shape[1],1)))\n",
    "    #model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "#     model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(X.shape[1]))\n",
    "#     model.add(Activation('relu'))\n",
    "    \n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 712us/step - loss: 29.6360 - accuracy: 0.4698 - val_loss: 4.9546 - val_accuracy: 0.4094\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 170us/step - loss: 18.9073 - accuracy: 0.5377 - val_loss: 1.6452 - val_accuracy: 0.8187\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 205us/step - loss: 13.2262 - accuracy: 0.6256 - val_loss: 1.4317 - val_accuracy: 0.7485\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 10.4074 - accuracy: 0.6683 - val_loss: 1.8590 - val_accuracy: 0.7427\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 243us/step - loss: 9.8191 - accuracy: 0.6457 - val_loss: 0.5756 - val_accuracy: 0.9240\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 185us/step - loss: 9.4210 - accuracy: 0.6533 - val_loss: 1.3359 - val_accuracy: 0.9006\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 175us/step - loss: 7.8791 - accuracy: 0.7136 - val_loss: 0.7103 - val_accuracy: 0.9123\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 208us/step - loss: 6.0433 - accuracy: 0.7513 - val_loss: 0.7421 - val_accuracy: 0.9181\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 193us/step - loss: 6.2395 - accuracy: 0.7236 - val_loss: 0.8586 - val_accuracy: 0.9064\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 223us/step - loss: 6.0514 - accuracy: 0.7714 - val_loss: 0.9138 - val_accuracy: 0.8947\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 226us/step - loss: 4.0511 - accuracy: 0.7814 - val_loss: 0.8198 - val_accuracy: 0.9298\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 4.4150 - accuracy: 0.7688 - val_loss: 1.3862 - val_accuracy: 0.9298\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 158us/step - loss: 4.8805 - accuracy: 0.7789 - val_loss: 0.9601 - val_accuracy: 0.9240\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 351us/step - loss: 3.3347 - accuracy: 0.8141 - val_loss: 1.0441 - val_accuracy: 0.8830\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 183us/step - loss: 4.3900 - accuracy: 0.7965 - val_loss: 0.8163 - val_accuracy: 0.9240\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 293us/step - loss: 3.8761 - accuracy: 0.7864 - val_loss: 0.8464 - val_accuracy: 0.9298\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 188us/step - loss: 3.2744 - accuracy: 0.7965 - val_loss: 0.8243 - val_accuracy: 0.9298\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 251us/step - loss: 2.4899 - accuracy: 0.8065 - val_loss: 0.9510 - val_accuracy: 0.9240\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 331us/step - loss: 2.6712 - accuracy: 0.8166 - val_loss: 1.2785 - val_accuracy: 0.8655\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 241us/step - loss: 2.1343 - accuracy: 0.8543 - val_loss: 0.7959 - val_accuracy: 0.9240\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 266us/step - loss: 2.2680 - accuracy: 0.8417 - val_loss: 0.8147 - val_accuracy: 0.9298\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 233us/step - loss: 2.1907 - accuracy: 0.8342 - val_loss: 0.9239 - val_accuracy: 0.8947\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 238us/step - loss: 2.0205 - accuracy: 0.8467 - val_loss: 0.8392 - val_accuracy: 0.9006\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 2.3412 - accuracy: 0.8141 - val_loss: 0.9139 - val_accuracy: 0.9181\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 241us/step - loss: 2.2888 - accuracy: 0.8191 - val_loss: 0.8385 - val_accuracy: 0.9181\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 261us/step - loss: 2.1704 - accuracy: 0.8367 - val_loss: 0.7078 - val_accuracy: 0.9298\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 331us/step - loss: 1.9335 - accuracy: 0.8392 - val_loss: 0.6326 - val_accuracy: 0.9240\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 208us/step - loss: 1.5614 - accuracy: 0.8618 - val_loss: 0.7736 - val_accuracy: 0.9181\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 291us/step - loss: 1.6595 - accuracy: 0.8367 - val_loss: 0.9952 - val_accuracy: 0.8655\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 209us/step - loss: 1.5821 - accuracy: 0.8568 - val_loss: 0.8054 - val_accuracy: 0.8830\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 221us/step - loss: 1.2777 - accuracy: 0.8392 - val_loss: 0.5050 - val_accuracy: 0.9298\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 277us/step - loss: 1.2945 - accuracy: 0.8492 - val_loss: 0.5338 - val_accuracy: 0.9357\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 220us/step - loss: 1.0015 - accuracy: 0.8668 - val_loss: 0.5233 - val_accuracy: 0.9357\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 224us/step - loss: 1.4413 - accuracy: 0.8342 - val_loss: 0.4728 - val_accuracy: 0.9298\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 189us/step - loss: 1.1357 - accuracy: 0.8693 - val_loss: 0.5735 - val_accuracy: 0.9006\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 194us/step - loss: 1.3639 - accuracy: 0.8492 - val_loss: 0.6782 - val_accuracy: 0.8830\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 181us/step - loss: 1.0805 - accuracy: 0.8342 - val_loss: 0.3906 - val_accuracy: 0.9357\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 201us/step - loss: 1.0574 - accuracy: 0.8492 - val_loss: 0.3879 - val_accuracy: 0.9298\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 209us/step - loss: 1.2278 - accuracy: 0.8492 - val_loss: 0.5442 - val_accuracy: 0.9298\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 181us/step - loss: 0.9829 - accuracy: 0.8392 - val_loss: 0.3504 - val_accuracy: 0.9357\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 206us/step - loss: 0.8250 - accuracy: 0.8819 - val_loss: 0.4640 - val_accuracy: 0.9123\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 199us/step - loss: 0.9902 - accuracy: 0.8643 - val_loss: 0.3893 - val_accuracy: 0.9298\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 176us/step - loss: 0.8148 - accuracy: 0.8568 - val_loss: 0.3636 - val_accuracy: 0.9240\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 292us/step - loss: 0.9156 - accuracy: 0.8568 - val_loss: 0.2827 - val_accuracy: 0.9357\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 206us/step - loss: 0.7240 - accuracy: 0.8744 - val_loss: 0.2781 - val_accuracy: 0.9415\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 171us/step - loss: 0.6320 - accuracy: 0.8492 - val_loss: 0.3506 - val_accuracy: 0.9240\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.5862 - accuracy: 0.8618 - val_loss: 0.2579 - val_accuracy: 0.9357\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 224us/step - loss: 0.6482 - accuracy: 0.8844 - val_loss: 0.2393 - val_accuracy: 0.9298\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.5717 - accuracy: 0.8719 - val_loss: 0.2302 - val_accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 189us/step - loss: 0.5284 - accuracy: 0.8719 - val_loss: 0.3175 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.7479 - accuracy: 0.8417 - val_loss: 0.5253 - val_accuracy: 0.8538\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 193us/step - loss: 0.8993 - accuracy: 0.8342 - val_loss: 0.3191 - val_accuracy: 0.9123\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 176us/step - loss: 0.4735 - accuracy: 0.8719 - val_loss: 0.3424 - val_accuracy: 0.9123\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 163us/step - loss: 0.5465 - accuracy: 0.8467 - val_loss: 0.2170 - val_accuracy: 0.9298\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 166us/step - loss: 0.3698 - accuracy: 0.8920 - val_loss: 0.4899 - val_accuracy: 0.8421\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.4287 - accuracy: 0.8719 - val_loss: 0.2080 - val_accuracy: 0.9298\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 242us/step - loss: 0.4710 - accuracy: 0.8593 - val_loss: 0.1884 - val_accuracy: 0.9474\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 198us/step - loss: 0.4754 - accuracy: 0.8593 - val_loss: 0.2471 - val_accuracy: 0.9240\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 171us/step - loss: 0.4318 - accuracy: 0.8744 - val_loss: 0.2346 - val_accuracy: 0.9240\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 163us/step - loss: 0.4365 - accuracy: 0.8693 - val_loss: 0.2418 - val_accuracy: 0.9240\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 369us/step - loss: 0.5097 - accuracy: 0.8693 - val_loss: 0.2005 - val_accuracy: 0.9357\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 266us/step - loss: 0.3688 - accuracy: 0.8844 - val_loss: 0.2782 - val_accuracy: 0.9240\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 204us/step - loss: 0.4240 - accuracy: 0.8844 - val_loss: 0.1786 - val_accuracy: 0.9474\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 206us/step - loss: 0.5235 - accuracy: 0.8518 - val_loss: 0.2250 - val_accuracy: 0.9240\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 181us/step - loss: 0.3618 - accuracy: 0.8869 - val_loss: 0.2088 - val_accuracy: 0.9240\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 244us/step - loss: 0.3558 - accuracy: 0.8668 - val_loss: 0.1748 - val_accuracy: 0.9415\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.3161 - accuracy: 0.8769 - val_loss: 0.1790 - val_accuracy: 0.9474\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 236us/step - loss: 0.3576 - accuracy: 0.8844 - val_loss: 0.1830 - val_accuracy: 0.9298\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 166us/step - loss: 0.3922 - accuracy: 0.8794 - val_loss: 0.1873 - val_accuracy: 0.9298\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 186us/step - loss: 0.3771 - accuracy: 0.8794 - val_loss: 0.1796 - val_accuracy: 0.9357\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 203us/step - loss: 0.3893 - accuracy: 0.8593 - val_loss: 0.2276 - val_accuracy: 0.9181\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.4043 - accuracy: 0.8643 - val_loss: 0.1813 - val_accuracy: 0.9240\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 171us/step - loss: 0.3343 - accuracy: 0.8894 - val_loss: 0.1868 - val_accuracy: 0.9298\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 156us/step - loss: 0.3385 - accuracy: 0.8719 - val_loss: 0.2644 - val_accuracy: 0.9240\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.5064 - accuracy: 0.8342 - val_loss: 0.3426 - val_accuracy: 0.8772\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 188us/step - loss: 0.3633 - accuracy: 0.8844 - val_loss: 0.2647 - val_accuracy: 0.9240\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 175us/step - loss: 0.3487 - accuracy: 0.8844 - val_loss: 0.1838 - val_accuracy: 0.9298\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 145us/step - loss: 0.2886 - accuracy: 0.8970 - val_loss: 0.1872 - val_accuracy: 0.9298\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 145us/step - loss: 0.4099 - accuracy: 0.8568 - val_loss: 0.2134 - val_accuracy: 0.9181\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 138us/step - loss: 0.3421 - accuracy: 0.8819 - val_loss: 0.1758 - val_accuracy: 0.9415\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 153us/step - loss: 0.3314 - accuracy: 0.8894 - val_loss: 0.2749 - val_accuracy: 0.9240\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 160us/step - loss: 0.3779 - accuracy: 0.8668 - val_loss: 0.2101 - val_accuracy: 0.9123\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 162us/step - loss: 0.2926 - accuracy: 0.8894 - val_loss: 0.1799 - val_accuracy: 0.9357\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 165us/step - loss: 0.3082 - accuracy: 0.8894 - val_loss: 0.1855 - val_accuracy: 0.9298\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 159us/step - loss: 0.3232 - accuracy: 0.8794 - val_loss: 0.1934 - val_accuracy: 0.9240\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 155us/step - loss: 0.3443 - accuracy: 0.8668 - val_loss: 0.2331 - val_accuracy: 0.9181\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 150us/step - loss: 0.3441 - accuracy: 0.8945 - val_loss: 0.2503 - val_accuracy: 0.9240\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 172us/step - loss: 0.3291 - accuracy: 0.8769 - val_loss: 0.1786 - val_accuracy: 0.9415\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 198us/step - loss: 0.3251 - accuracy: 0.8769 - val_loss: 0.1761 - val_accuracy: 0.9415\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 253us/step - loss: 0.3000 - accuracy: 0.8869 - val_loss: 0.1850 - val_accuracy: 0.9298\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 201us/step - loss: 0.2996 - accuracy: 0.8844 - val_loss: 0.1748 - val_accuracy: 0.9415\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 189us/step - loss: 0.2891 - accuracy: 0.8819 - val_loss: 0.2037 - val_accuracy: 0.9181\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 165us/step - loss: 0.3496 - accuracy: 0.8719 - val_loss: 0.1748 - val_accuracy: 0.9415\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 158us/step - loss: 0.3221 - accuracy: 0.8794 - val_loss: 0.1780 - val_accuracy: 0.9474\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 298us/step - loss: 0.2778 - accuracy: 0.8894 - val_loss: 0.2095 - val_accuracy: 0.9181\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 263us/step - loss: 0.3058 - accuracy: 0.8844 - val_loss: 0.1876 - val_accuracy: 0.9298\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 213us/step - loss: 0.2878 - accuracy: 0.8970 - val_loss: 0.2334 - val_accuracy: 0.9240\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 241us/step - loss: 0.2530 - accuracy: 0.8945 - val_loss: 0.1727 - val_accuracy: 0.9415\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 0.2687 - accuracy: 0.8995 - val_loss: 0.1796 - val_accuracy: 0.9298\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 236us/step - loss: 0.2716 - accuracy: 0.8920 - val_loss: 0.1754 - val_accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "# Parametres\n",
    "verbose, epochs, batch_size = 1, 100, 32\n",
    "# initialize the model object\n",
    "clf_cnn = CNN_net()\n",
    "# fit network\n",
    "history = clf_cnn.fit(x_train, y_train_binary, batch_size=batch_size,\n",
    "          epochs=epochs, verbose=verbose, validation_data=(x_test, y_test_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 105us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17538799999053017, 0.9356725215911865]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call predict to get predictions Report the accuracy\n",
    "clf_cnn.evaluate(x_test, y_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN : Accuracy: 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "# call predict to get predictions\n",
    "y_pred = clf_cnn.predict(x_test)\n",
    "y_pred = np.round(y_pred)\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Report the accuracy\n",
    "accuracy_CNN = accuracy_score(y_test_binary, y_pred)\n",
    "print(\"CNN : Accuracy: \" + str(accuracy_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 21, 100)           1100      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 100)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1402      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training loss','Validation loss'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model train vs validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training acc','Validation acc'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Novel Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "# from the first Fully-Connected layer \n",
    "layer_name = 'dense_1'\n",
    "intermediate_layer_model = Model(inputs=clf_cnn.input,\n",
    "                                 outputs=clf_cnn.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features of the train dataset to use it in future.\n",
    "out_cnn_train = intermediate_layer_model.predict(x_train)\n",
    "# Save the features of the test dataset to use it in future.\n",
    "out_cnn_test = intermediate_layer_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features (from CNN) Shape: (398, 2)\n",
      "Training Labels (from CNN) Shape: (398,)\n",
      "Test Features (from CNN) Shape: (171, 2)\n",
      "Test Labels (from CNN) Shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features (from CNN) Shape:', out_cnn_train.shape)\n",
    "print('Training Labels (from CNN) Shape:', y_train.shape)\n",
    "\n",
    "print('Test Features (from CNN) Shape:', out_cnn_test.shape)\n",
    "print('Test Labels (from CNN) Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + Random Forest + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "djinn breast_cancer\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:263: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:266: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:302: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:286: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:320: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:328: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:333: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:334: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn_fns.py:335: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch: 0001 cost= 0.802740065 accuracy= 0.603\n",
      "Epoch: 0002 cost= 0.690113501 accuracy= 0.587\n",
      "Epoch: 0003 cost= 0.651179157 accuracy= 0.598\n",
      "Epoch: 0004 cost= 0.657153471 accuracy= 0.617\n",
      "Epoch: 0005 cost= 0.682126766 accuracy= 0.615\n",
      "Epoch: 0006 cost= 0.663567456 accuracy= 0.617\n",
      "Epoch: 0007 cost= 0.671139788 accuracy= 0.617\n",
      "Epoch: 0008 cost= 0.663252890 accuracy= 0.620\n",
      "Epoch: 0009 cost= 0.667267144 accuracy= 0.617\n",
      "Epoch: 0010 cost= 0.650251221 accuracy= 0.617\n",
      "Epoch: 0011 cost= 0.640479456 accuracy= 0.617\n",
      "Epoch: 0012 cost= 0.625448211 accuracy= 0.617\n",
      "Epoch: 0013 cost= 0.654020001 accuracy= 0.617\n",
      "Epoch: 0014 cost= 0.636919623 accuracy= 0.617\n",
      "Epoch: 0015 cost= 0.637768881 accuracy= 0.620\n",
      "Epoch: 0016 cost= 0.659485914 accuracy= 0.615\n",
      "Epoch: 0017 cost= 0.659823629 accuracy= 0.606\n",
      "Epoch: 0018 cost= 0.661041926 accuracy= 0.620\n",
      "Epoch: 0019 cost= 0.670914915 accuracy= 0.606\n",
      "Epoch: 0020 cost= 0.652819270 accuracy= 0.623\n",
      "Epoch: 0021 cost= 0.649914942 accuracy= 0.615\n",
      "Epoch: 0022 cost= 0.646778118 accuracy= 0.612\n",
      "Epoch: 0023 cost= 0.652509668 accuracy= 0.617\n",
      "Epoch: 0024 cost= 0.645652148 accuracy= 0.626\n",
      "Epoch: 0025 cost= 0.641113346 accuracy= 0.617\n",
      "Epoch: 0026 cost= 0.605716944 accuracy= 0.615\n",
      "Epoch: 0027 cost= 0.613113956 accuracy= 0.609\n",
      "Epoch: 0028 cost= 0.611760660 accuracy= 0.615\n",
      "Epoch: 0029 cost= 0.638391988 accuracy= 0.615\n",
      "Epoch: 0030 cost= 0.629955129 accuracy= 0.606\n",
      "Epoch: 0031 cost= 0.601504250 accuracy= 0.642\n",
      "Epoch: 0032 cost= 0.621925554 accuracy= 0.609\n",
      "Epoch: 0033 cost= 0.609399649 accuracy= 0.690\n",
      "Epoch: 0034 cost= 0.618167834 accuracy= 0.651\n",
      "Epoch: 0035 cost= 0.629339364 accuracy= 0.601\n",
      "Epoch: 0036 cost= 0.609765153 accuracy= 0.673\n",
      "Epoch: 0037 cost= 0.589340909 accuracy= 0.673\n",
      "Epoch: 0038 cost= 0.578379235 accuracy= 0.665\n",
      "Epoch: 0039 cost= 0.578042003 accuracy= 0.693\n",
      "Epoch: 0040 cost= 0.559748387 accuracy= 0.693\n",
      "Epoch: 0041 cost= 0.598330999 accuracy= 0.690\n",
      "Epoch: 0042 cost= 0.539268082 accuracy= 0.696\n",
      "Epoch: 0043 cost= 0.582389558 accuracy= 0.729\n",
      "Epoch: 0044 cost= 0.573313025 accuracy= 0.715\n",
      "Epoch: 0045 cost= 0.532014554 accuracy= 0.704\n",
      "Epoch: 0046 cost= 0.484878716 accuracy= 0.751\n",
      "Epoch: 0047 cost= 0.531107152 accuracy= 0.749\n",
      "Epoch: 0048 cost= 0.528203059 accuracy= 0.721\n",
      "Epoch: 0049 cost= 0.542698768 accuracy= 0.735\n",
      "Epoch: 0050 cost= 0.532025232 accuracy= 0.788\n",
      "Epoch: 0051 cost= 0.533984387 accuracy= 0.760\n",
      "Epoch: 0052 cost= 0.521413445 accuracy= 0.749\n",
      "Epoch: 0053 cost= 0.497718481 accuracy= 0.796\n",
      "Epoch: 0054 cost= 0.519884353 accuracy= 0.765\n",
      "Epoch: 0055 cost= 0.468003566 accuracy= 0.760\n",
      "Epoch: 0056 cost= 0.461090399 accuracy= 0.768\n",
      "Epoch: 0057 cost= 0.493087026 accuracy= 0.774\n",
      "Epoch: 0058 cost= 0.499394438 accuracy= 0.788\n",
      "Epoch: 0059 cost= 0.527531079 accuracy= 0.765\n",
      "Epoch: 0060 cost= 0.489506619 accuracy= 0.760\n",
      "Epoch: 0061 cost= 0.486293961 accuracy= 0.723\n",
      "Epoch: 0062 cost= 0.433390994 accuracy= 0.799\n",
      "Epoch: 0063 cost= 0.443890355 accuracy= 0.782\n",
      "Epoch: 0064 cost= 0.498278648 accuracy= 0.754\n",
      "Epoch: 0065 cost= 0.495842088 accuracy= 0.777\n",
      "Epoch: 0066 cost= 0.393839191 accuracy= 0.751\n",
      "Epoch: 0067 cost= 0.484559419 accuracy= 0.793\n",
      "Epoch: 0068 cost= 0.455078978 accuracy= 0.802\n",
      "Epoch: 0069 cost= 0.487541345 accuracy= 0.802\n",
      "Epoch: 0070 cost= 0.477997178 accuracy= 0.777\n",
      "Epoch: 0071 cost= 0.468457707 accuracy= 0.796\n",
      "Epoch: 0072 cost= 0.500064538 accuracy= 0.740\n",
      "Epoch: 0073 cost= 0.439311713 accuracy= 0.771\n",
      "Epoch: 0074 cost= 0.441529978 accuracy= 0.788\n",
      "Epoch: 0075 cost= 0.449404936 accuracy= 0.793\n",
      "Epoch: 0076 cost= 0.442107241 accuracy= 0.804\n",
      "Epoch: 0077 cost= 0.432488582 accuracy= 0.802\n",
      "Epoch: 0078 cost= 0.416404792 accuracy= 0.782\n",
      "Epoch: 0079 cost= 0.421795596 accuracy= 0.816\n",
      "Epoch: 0080 cost= 0.399332130 accuracy= 0.804\n",
      "Epoch: 0081 cost= 0.448865078 accuracy= 0.763\n",
      "Epoch: 0082 cost= 0.492838407 accuracy= 0.774\n",
      "Epoch: 0083 cost= 0.417588789 accuracy= 0.782\n",
      "Epoch: 0084 cost= 0.450406774 accuracy= 0.791\n",
      "Epoch: 0085 cost= 0.466555617 accuracy= 0.782\n",
      "Epoch: 0086 cost= 0.424161280 accuracy= 0.816\n",
      "Epoch: 0087 cost= 0.418615878 accuracy= 0.791\n",
      "Epoch: 0088 cost= 0.400876676 accuracy= 0.799\n",
      "Epoch: 0089 cost= 0.463056442 accuracy= 0.821\n",
      "Epoch: 0090 cost= 0.442873857 accuracy= 0.813\n",
      "Epoch: 0091 cost= 0.516868711 accuracy= 0.779\n",
      "Epoch: 0092 cost= 0.463009187 accuracy= 0.785\n",
      "Epoch: 0093 cost= 0.457052513 accuracy= 0.788\n",
      "Epoch: 0094 cost= 0.422951804 accuracy= 0.807\n",
      "Epoch: 0095 cost= 0.444371535 accuracy= 0.852\n",
      "Epoch: 0096 cost= 0.419059805 accuracy= 0.777\n",
      "Epoch: 0097 cost= 0.453091695 accuracy= 0.777\n",
      "Epoch: 0098 cost= 0.414771107 accuracy= 0.771\n",
      "Epoch: 0099 cost= 0.447963311 accuracy= 0.782\n",
      "Epoch: 0100 cost= 0.389829944 accuracy= 0.793\n",
      "Optimization Finished!\n",
      "Model saved in: ./class_djinn_breast_cancer_tree0.ckpt\n",
      "Epoch: 0001 cost= 0.842898553 accuracy= 0.609\n",
      "Epoch: 0002 cost= 0.684660072 accuracy= 0.542\n",
      "Epoch: 0003 cost= 0.693265931 accuracy= 0.601\n",
      "Epoch: 0004 cost= 0.696031988 accuracy= 0.617\n",
      "Epoch: 0005 cost= 0.672200718 accuracy= 0.617\n",
      "Epoch: 0006 cost= 0.666366588 accuracy= 0.617\n",
      "Epoch: 0007 cost= 0.686687399 accuracy= 0.617\n",
      "Epoch: 0008 cost= 0.662072572 accuracy= 0.617\n",
      "Epoch: 0009 cost= 0.651172475 accuracy= 0.617\n",
      "Epoch: 0010 cost= 0.674884915 accuracy= 0.617\n",
      "Epoch: 0011 cost= 0.679968964 accuracy= 0.617\n",
      "Epoch: 0012 cost= 0.668703767 accuracy= 0.617\n",
      "Epoch: 0013 cost= 0.665535715 accuracy= 0.617\n",
      "Epoch: 0014 cost= 0.652930070 accuracy= 0.617\n",
      "Epoch: 0015 cost= 0.666678347 accuracy= 0.617\n",
      "Epoch: 0016 cost= 0.640709124 accuracy= 0.617\n",
      "Epoch: 0017 cost= 0.672644388 accuracy= 0.617\n",
      "Epoch: 0018 cost= 0.637616250 accuracy= 0.617\n",
      "Epoch: 0019 cost= 0.639275881 accuracy= 0.617\n",
      "Epoch: 0020 cost= 0.663486616 accuracy= 0.623\n",
      "Epoch: 0021 cost= 0.627011678 accuracy= 0.617\n",
      "Epoch: 0022 cost= 0.659513403 accuracy= 0.637\n",
      "Epoch: 0023 cost= 0.649890298 accuracy= 0.623\n",
      "Epoch: 0024 cost= 0.641941845 accuracy= 0.651\n",
      "Epoch: 0025 cost= 0.609538273 accuracy= 0.642\n",
      "Epoch: 0026 cost= 0.607316713 accuracy= 0.676\n",
      "Epoch: 0027 cost= 0.633512248 accuracy= 0.673\n",
      "Epoch: 0028 cost= 0.587871048 accuracy= 0.701\n",
      "Epoch: 0029 cost= 0.563046705 accuracy= 0.665\n",
      "Epoch: 0030 cost= 0.558537632 accuracy= 0.690\n",
      "Epoch: 0031 cost= 0.576943766 accuracy= 0.737\n",
      "Epoch: 0032 cost= 0.548871569 accuracy= 0.721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0033 cost= 0.566542856 accuracy= 0.757\n",
      "Epoch: 0034 cost= 0.597130206 accuracy= 0.718\n",
      "Epoch: 0035 cost= 0.561724289 accuracy= 0.709\n",
      "Epoch: 0036 cost= 0.526510472 accuracy= 0.796\n",
      "Epoch: 0037 cost= 0.495335075 accuracy= 0.777\n",
      "Epoch: 0038 cost= 0.517269972 accuracy= 0.751\n",
      "Epoch: 0039 cost= 0.475738504 accuracy= 0.779\n",
      "Epoch: 0040 cost= 0.462019465 accuracy= 0.788\n",
      "Epoch: 0041 cost= 0.457312457 accuracy= 0.771\n",
      "Epoch: 0042 cost= 0.421165103 accuracy= 0.804\n",
      "Epoch: 0043 cost= 0.437322668 accuracy= 0.804\n",
      "Epoch: 0044 cost= 0.434084854 accuracy= 0.791\n",
      "Epoch: 0045 cost= 0.498595701 accuracy= 0.804\n",
      "Epoch: 0046 cost= 0.442084039 accuracy= 0.830\n",
      "Epoch: 0047 cost= 0.451409096 accuracy= 0.821\n",
      "Epoch: 0048 cost= 0.423311775 accuracy= 0.804\n",
      "Epoch: 0049 cost= 0.419836779 accuracy= 0.818\n",
      "Epoch: 0050 cost= 0.425808996 accuracy= 0.838\n",
      "Epoch: 0051 cost= 0.451239759 accuracy= 0.810\n",
      "Epoch: 0052 cost= 0.428449978 accuracy= 0.838\n",
      "Epoch: 0053 cost= 0.394114692 accuracy= 0.830\n",
      "Epoch: 0054 cost= 0.383621064 accuracy= 0.830\n",
      "Epoch: 0055 cost= 0.439012636 accuracy= 0.793\n",
      "Epoch: 0056 cost= 0.400807643 accuracy= 0.838\n",
      "Epoch: 0057 cost= 0.446336982 accuracy= 0.849\n",
      "Epoch: 0058 cost= 0.407642362 accuracy= 0.832\n",
      "Epoch: 0059 cost= 0.388514687 accuracy= 0.838\n",
      "Epoch: 0060 cost= 0.407594012 accuracy= 0.813\n",
      "Epoch: 0061 cost= 0.410821048 accuracy= 0.832\n",
      "Epoch: 0062 cost= 0.401491580 accuracy= 0.844\n",
      "Epoch: 0063 cost= 0.414675328 accuracy= 0.860\n",
      "Epoch: 0064 cost= 0.391641552 accuracy= 0.835\n",
      "Epoch: 0065 cost= 0.383052533 accuracy= 0.802\n",
      "Epoch: 0066 cost= 0.397242035 accuracy= 0.838\n",
      "Epoch: 0067 cost= 0.383056153 accuracy= 0.846\n",
      "Epoch: 0068 cost= 0.322279528 accuracy= 0.835\n",
      "Epoch: 0069 cost= 0.389935903 accuracy= 0.860\n",
      "Epoch: 0070 cost= 0.379623963 accuracy= 0.827\n",
      "Epoch: 0071 cost= 0.392200730 accuracy= 0.863\n",
      "Epoch: 0072 cost= 0.391057502 accuracy= 0.816\n",
      "Epoch: 0073 cost= 0.373088384 accuracy= 0.835\n",
      "Epoch: 0074 cost= 0.418133226 accuracy= 0.860\n",
      "Epoch: 0075 cost= 0.389728844 accuracy= 0.860\n",
      "Epoch: 0076 cost= 0.410876555 accuracy= 0.838\n",
      "Epoch: 0077 cost= 0.390504311 accuracy= 0.804\n",
      "Epoch: 0078 cost= 0.392215824 accuracy= 0.824\n",
      "Epoch: 0079 cost= 0.379247161 accuracy= 0.846\n",
      "Epoch: 0080 cost= 0.357907880 accuracy= 0.846\n",
      "Epoch: 0081 cost= 0.334584063 accuracy= 0.827\n",
      "Epoch: 0082 cost= 0.406994597 accuracy= 0.832\n",
      "Epoch: 0083 cost= 0.415462559 accuracy= 0.813\n",
      "Epoch: 0084 cost= 0.371879009 accuracy= 0.830\n",
      "Epoch: 0085 cost= 0.381220009 accuracy= 0.796\n",
      "Epoch: 0086 cost= 0.412809025 accuracy= 0.841\n",
      "Epoch: 0087 cost= 0.384061139 accuracy= 0.835\n",
      "Epoch: 0088 cost= 0.377272328 accuracy= 0.849\n",
      "Epoch: 0089 cost= 0.368169438 accuracy= 0.855\n",
      "Epoch: 0090 cost= 0.323361800 accuracy= 0.860\n",
      "Epoch: 0091 cost= 0.344153010 accuracy= 0.849\n",
      "Epoch: 0092 cost= 0.380461448 accuracy= 0.810\n",
      "Epoch: 0093 cost= 0.461407176 accuracy= 0.813\n",
      "Epoch: 0094 cost= 0.405061508 accuracy= 0.813\n",
      "Epoch: 0095 cost= 0.459531510 accuracy= 0.830\n",
      "Epoch: 0096 cost= 0.396764097 accuracy= 0.830\n",
      "Epoch: 0097 cost= 0.385502552 accuracy= 0.894\n",
      "Epoch: 0098 cost= 0.452871648 accuracy= 0.824\n",
      "Epoch: 0099 cost= 0.360764322 accuracy= 0.824\n",
      "Epoch: 0100 cost= 0.362764169 accuracy= 0.872\n",
      "Optimization Finished!\n",
      "Model saved in: ./class_djinn_breast_cancer_tree1.ckpt\n",
      "Epoch: 0001 cost= 0.690989847 accuracy= 0.620\n",
      "Epoch: 0002 cost= 0.659631312 accuracy= 0.617\n",
      "Epoch: 0003 cost= 0.667277488 accuracy= 0.617\n",
      "Epoch: 0004 cost= 0.682253068 accuracy= 0.617\n",
      "Epoch: 0005 cost= 0.655318732 accuracy= 0.617\n",
      "Epoch: 0006 cost= 0.663988038 accuracy= 0.617\n",
      "Epoch: 0007 cost= 0.654575445 accuracy= 0.617\n",
      "Epoch: 0008 cost= 0.663735699 accuracy= 0.617\n",
      "Epoch: 0009 cost= 0.649128128 accuracy= 0.617\n",
      "Epoch: 0010 cost= 0.642008565 accuracy= 0.617\n",
      "Epoch: 0011 cost= 0.672687243 accuracy= 0.623\n",
      "Epoch: 0012 cost= 0.635922004 accuracy= 0.631\n",
      "Epoch: 0013 cost= 0.668704759 accuracy= 0.631\n",
      "Epoch: 0014 cost= 0.668707333 accuracy= 0.637\n",
      "Epoch: 0015 cost= 0.648860650 accuracy= 0.626\n",
      "Epoch: 0016 cost= 0.651486326 accuracy= 0.645\n",
      "Epoch: 0017 cost= 0.652489407 accuracy= 0.665\n",
      "Epoch: 0018 cost= 0.655466893 accuracy= 0.648\n",
      "Epoch: 0019 cost= 0.634438818 accuracy= 0.665\n",
      "Epoch: 0020 cost= 0.625570888 accuracy= 0.640\n",
      "Epoch: 0021 cost= 0.640434254 accuracy= 0.659\n",
      "Epoch: 0022 cost= 0.604980550 accuracy= 0.679\n",
      "Epoch: 0023 cost= 0.618848817 accuracy= 0.679\n",
      "Epoch: 0024 cost= 0.590868273 accuracy= 0.696\n",
      "Epoch: 0025 cost= 0.577086199 accuracy= 0.698\n",
      "Epoch: 0026 cost= 0.583232541 accuracy= 0.715\n",
      "Epoch: 0027 cost= 0.558752949 accuracy= 0.721\n",
      "Epoch: 0028 cost= 0.531349927 accuracy= 0.743\n",
      "Epoch: 0029 cost= 0.544588189 accuracy= 0.749\n",
      "Epoch: 0030 cost= 0.508932287 accuracy= 0.749\n",
      "Epoch: 0031 cost= 0.530192605 accuracy= 0.740\n",
      "Epoch: 0032 cost= 0.491479819 accuracy= 0.774\n",
      "Epoch: 0033 cost= 0.507689343 accuracy= 0.746\n",
      "Epoch: 0034 cost= 0.537836920 accuracy= 0.771\n",
      "Epoch: 0035 cost= 0.486558134 accuracy= 0.791\n",
      "Epoch: 0036 cost= 0.465095588 accuracy= 0.779\n",
      "Epoch: 0037 cost= 0.458370805 accuracy= 0.777\n",
      "Epoch: 0038 cost= 0.451855803 accuracy= 0.810\n",
      "Epoch: 0039 cost= 0.470897265 accuracy= 0.765\n",
      "Epoch: 0040 cost= 0.484692034 accuracy= 0.807\n",
      "Epoch: 0041 cost= 0.449792388 accuracy= 0.799\n",
      "Epoch: 0042 cost= 0.455473442 accuracy= 0.804\n",
      "Epoch: 0043 cost= 0.463118309 accuracy= 0.774\n",
      "Epoch: 0044 cost= 0.441353210 accuracy= 0.732\n",
      "Epoch: 0045 cost= 0.450318252 accuracy= 0.793\n",
      "Epoch: 0046 cost= 0.467739184 accuracy= 0.796\n",
      "Epoch: 0047 cost= 0.406669162 accuracy= 0.749\n",
      "Epoch: 0048 cost= 0.476914081 accuracy= 0.796\n",
      "Epoch: 0049 cost= 0.426630172 accuracy= 0.802\n",
      "Epoch: 0050 cost= 0.425153426 accuracy= 0.796\n",
      "Epoch: 0051 cost= 0.404183667 accuracy= 0.785\n",
      "Epoch: 0052 cost= 0.379065081 accuracy= 0.807\n",
      "Epoch: 0053 cost= 0.455603824 accuracy= 0.782\n",
      "Epoch: 0054 cost= 0.424138194 accuracy= 0.774\n",
      "Epoch: 0055 cost= 0.432200185 accuracy= 0.791\n",
      "Epoch: 0056 cost= 0.452518615 accuracy= 0.768\n",
      "Epoch: 0057 cost= 0.447657959 accuracy= 0.791\n",
      "Epoch: 0058 cost= 0.466746425 accuracy= 0.782\n",
      "Epoch: 0059 cost= 0.445673300 accuracy= 0.768\n",
      "Epoch: 0060 cost= 0.407525737 accuracy= 0.802\n",
      "Epoch: 0061 cost= 0.434019663 accuracy= 0.771\n",
      "Epoch: 0062 cost= 0.392329614 accuracy= 0.796\n",
      "Epoch: 0063 cost= 0.397619911 accuracy= 0.802\n",
      "Epoch: 0064 cost= 0.441562105 accuracy= 0.799\n",
      "Epoch: 0065 cost= 0.425775016 accuracy= 0.804\n",
      "Epoch: 0066 cost= 0.430704854 accuracy= 0.793\n",
      "Epoch: 0067 cost= 0.408475120 accuracy= 0.788\n",
      "Epoch: 0068 cost= 0.440365426 accuracy= 0.763\n",
      "Epoch: 0069 cost= 0.447243818 accuracy= 0.830\n",
      "Epoch: 0070 cost= 0.412017996 accuracy= 0.802\n",
      "Epoch: 0071 cost= 0.508179613 accuracy= 0.796\n",
      "Epoch: 0072 cost= 0.421688876 accuracy= 0.771\n",
      "Epoch: 0073 cost= 0.409577882 accuracy= 0.793\n",
      "Epoch: 0074 cost= 0.423570609 accuracy= 0.813\n",
      "Epoch: 0075 cost= 0.502883686 accuracy= 0.816\n",
      "Epoch: 0076 cost= 0.435147131 accuracy= 0.774\n",
      "Epoch: 0077 cost= 0.424129410 accuracy= 0.824\n",
      "Epoch: 0078 cost= 0.432921568 accuracy= 0.816\n",
      "Epoch: 0079 cost= 0.455006423 accuracy= 0.802\n",
      "Epoch: 0080 cost= 0.396867701 accuracy= 0.788\n",
      "Epoch: 0081 cost= 0.499946405 accuracy= 0.791\n",
      "Epoch: 0082 cost= 0.395187205 accuracy= 0.779\n",
      "Epoch: 0083 cost= 0.484604342 accuracy= 0.810\n",
      "Epoch: 0084 cost= 0.493904807 accuracy= 0.749\n",
      "Epoch: 0085 cost= 0.462364541 accuracy= 0.771\n",
      "Epoch: 0086 cost= 0.432687992 accuracy= 0.818\n",
      "Epoch: 0087 cost= 0.403947272 accuracy= 0.816\n",
      "Epoch: 0088 cost= 0.421557055 accuracy= 0.813\n",
      "Epoch: 0089 cost= 0.430032703 accuracy= 0.796\n",
      "Epoch: 0090 cost= 0.440968969 accuracy= 0.813\n",
      "Epoch: 0091 cost= 0.388192282 accuracy= 0.799\n",
      "Epoch: 0092 cost= 0.405445066 accuracy= 0.824\n",
      "Epoch: 0093 cost= 0.429174369 accuracy= 0.807\n",
      "Epoch: 0094 cost= 0.419885476 accuracy= 0.785\n",
      "Epoch: 0095 cost= 0.442885225 accuracy= 0.824\n",
      "Epoch: 0096 cost= 0.430656256 accuracy= 0.779\n",
      "Epoch: 0097 cost= 0.419934457 accuracy= 0.816\n",
      "Epoch: 0098 cost= 0.374115609 accuracy= 0.802\n",
      "Epoch: 0099 cost= 0.354268678 accuracy= 0.810\n",
      "Epoch: 0100 cost= 0.386921197 accuracy= 0.827\n",
      "Optimization Finished!\n",
      "Model saved in: ./class_djinn_breast_cancer_tree2.ckpt\n",
      "Epoch: 0001 cost= 0.701924140 accuracy= 0.606\n",
      "Epoch: 0002 cost= 0.675180923 accuracy= 0.612\n",
      "Epoch: 0003 cost= 0.678530715 accuracy= 0.620\n",
      "Epoch: 0004 cost= 0.650020876 accuracy= 0.617\n",
      "Epoch: 0005 cost= 0.671568394 accuracy= 0.617\n",
      "Epoch: 0006 cost= 0.670797110 accuracy= 0.617\n",
      "Epoch: 0007 cost= 0.660235307 accuracy= 0.617\n",
      "Epoch: 0008 cost= 0.668837255 accuracy= 0.620\n",
      "Epoch: 0009 cost= 0.615906244 accuracy= 0.617\n",
      "Epoch: 0010 cost= 0.639991327 accuracy= 0.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0011 cost= 0.644957374 accuracy= 0.656\n",
      "Epoch: 0012 cost= 0.599535693 accuracy= 0.704\n",
      "Epoch: 0013 cost= 0.604265435 accuracy= 0.676\n",
      "Epoch: 0014 cost= 0.568349998 accuracy= 0.682\n",
      "Epoch: 0015 cost= 0.596152663 accuracy= 0.682\n",
      "Epoch: 0016 cost= 0.587212424 accuracy= 0.668\n",
      "Epoch: 0017 cost= 0.590281286 accuracy= 0.684\n",
      "Epoch: 0018 cost= 0.579374541 accuracy= 0.709\n",
      "Epoch: 0019 cost= 0.555140306 accuracy= 0.721\n",
      "Epoch: 0020 cost= 0.523206835 accuracy= 0.791\n",
      "Epoch: 0021 cost= 0.501230413 accuracy= 0.765\n",
      "Epoch: 0022 cost= 0.532568571 accuracy= 0.729\n",
      "Epoch: 0023 cost= 0.496224902 accuracy= 0.777\n",
      "Epoch: 0024 cost= 0.510049216 accuracy= 0.765\n",
      "Epoch: 0025 cost= 0.486653258 accuracy= 0.771\n",
      "Epoch: 0026 cost= 0.437643463 accuracy= 0.821\n",
      "Epoch: 0027 cost= 0.464851163 accuracy= 0.785\n",
      "Epoch: 0028 cost= 0.464931036 accuracy= 0.810\n",
      "Epoch: 0029 cost= 0.443139063 accuracy= 0.830\n",
      "Epoch: 0030 cost= 0.430549188 accuracy= 0.821\n",
      "Epoch: 0031 cost= 0.378192241 accuracy= 0.824\n",
      "Epoch: 0032 cost= 0.394849444 accuracy= 0.824\n",
      "Epoch: 0033 cost= 0.421721350 accuracy= 0.824\n",
      "Epoch: 0034 cost= 0.460458661 accuracy= 0.810\n",
      "Epoch: 0035 cost= 0.389465489 accuracy= 0.804\n",
      "Epoch: 0036 cost= 0.413289525 accuracy= 0.818\n",
      "Epoch: 0037 cost= 0.404287367 accuracy= 0.844\n",
      "Epoch: 0038 cost= 0.391283818 accuracy= 0.835\n",
      "Epoch: 0039 cost= 0.398899750 accuracy= 0.835\n",
      "Epoch: 0040 cost= 0.385515097 accuracy= 0.858\n",
      "Epoch: 0041 cost= 0.439196833 accuracy= 0.810\n",
      "Epoch: 0042 cost= 0.458882515 accuracy= 0.757\n",
      "Epoch: 0043 cost= 0.480829713 accuracy= 0.802\n",
      "Epoch: 0044 cost= 0.389466977 accuracy= 0.821\n",
      "Epoch: 0045 cost= 0.392339254 accuracy= 0.827\n",
      "Epoch: 0046 cost= 0.404757874 accuracy= 0.844\n",
      "Epoch: 0047 cost= 0.403079185 accuracy= 0.821\n",
      "Epoch: 0048 cost= 0.408781141 accuracy= 0.835\n",
      "Epoch: 0049 cost= 0.424563362 accuracy= 0.849\n",
      "Epoch: 0050 cost= 0.400396602 accuracy= 0.849\n",
      "Epoch: 0051 cost= 0.354062298 accuracy= 0.835\n",
      "Epoch: 0052 cost= 0.377382585 accuracy= 0.838\n",
      "Epoch: 0053 cost= 0.374768040 accuracy= 0.846\n",
      "Epoch: 0054 cost= 0.380002699 accuracy= 0.849\n",
      "Epoch: 0055 cost= 0.381621854 accuracy= 0.844\n",
      "Epoch: 0056 cost= 0.385654439 accuracy= 0.869\n",
      "Epoch: 0057 cost= 0.330047518 accuracy= 0.844\n",
      "Epoch: 0058 cost= 0.384391340 accuracy= 0.860\n",
      "Epoch: 0059 cost= 0.374569140 accuracy= 0.835\n",
      "Epoch: 0060 cost= 0.349500219 accuracy= 0.835\n",
      "Epoch: 0061 cost= 0.359630621 accuracy= 0.821\n",
      "Epoch: 0062 cost= 0.444387726 accuracy= 0.855\n",
      "Epoch: 0063 cost= 0.397757487 accuracy= 0.849\n",
      "Epoch: 0064 cost= 0.381410623 accuracy= 0.849\n",
      "Epoch: 0065 cost= 0.377398527 accuracy= 0.849\n",
      "Epoch: 0066 cost= 0.391036325 accuracy= 0.846\n",
      "Epoch: 0067 cost= 0.370001293 accuracy= 0.877\n",
      "Epoch: 0068 cost= 0.390531430 accuracy= 0.849\n",
      "Epoch: 0069 cost= 0.305303544 accuracy= 0.863\n",
      "Epoch: 0070 cost= 0.423778840 accuracy= 0.844\n",
      "Epoch: 0071 cost= 0.388717185 accuracy= 0.849\n",
      "Epoch: 0072 cost= 0.395102444 accuracy= 0.852\n",
      "Epoch: 0073 cost= 0.345589597 accuracy= 0.835\n",
      "Epoch: 0074 cost= 0.320918559 accuracy= 0.866\n",
      "Epoch: 0075 cost= 0.377905339 accuracy= 0.844\n",
      "Epoch: 0076 cost= 0.430026146 accuracy= 0.841\n",
      "Epoch: 0077 cost= 0.343153393 accuracy= 0.866\n",
      "Epoch: 0078 cost= 0.384373999 accuracy= 0.832\n",
      "Epoch: 0079 cost= 0.393309425 accuracy= 0.852\n",
      "Epoch: 0080 cost= 0.311026676 accuracy= 0.849\n",
      "Epoch: 0081 cost= 0.388138610 accuracy= 0.830\n",
      "Epoch: 0082 cost= 0.353359130 accuracy= 0.852\n",
      "Epoch: 0083 cost= 0.328076140 accuracy= 0.830\n",
      "Epoch: 0084 cost= 0.362080945 accuracy= 0.832\n",
      "Epoch: 0085 cost= 0.380414880 accuracy= 0.818\n",
      "Epoch: 0086 cost= 0.395573136 accuracy= 0.866\n",
      "Epoch: 0087 cost= 0.346386857 accuracy= 0.852\n",
      "Epoch: 0088 cost= 0.377967328 accuracy= 0.855\n",
      "Epoch: 0089 cost= 0.382751132 accuracy= 0.852\n",
      "Epoch: 0090 cost= 0.387630818 accuracy= 0.860\n",
      "Epoch: 0091 cost= 0.389886436 accuracy= 0.827\n",
      "Epoch: 0092 cost= 0.363555339 accuracy= 0.852\n",
      "Epoch: 0093 cost= 0.339389099 accuracy= 0.855\n",
      "Epoch: 0094 cost= 0.302259402 accuracy= 0.869\n",
      "Epoch: 0095 cost= 0.379920649 accuracy= 0.849\n",
      "Epoch: 0096 cost= 0.364017916 accuracy= 0.852\n",
      "Epoch: 0097 cost= 0.337726785 accuracy= 0.888\n",
      "Epoch: 0098 cost= 0.339865500 accuracy= 0.818\n",
      "Epoch: 0099 cost= 0.384973453 accuracy= 0.838\n",
      "Epoch: 0100 cost= 0.349914478 accuracy= 0.874\n",
      "Optimization Finished!\n",
      "Model saved in: ./class_djinn_breast_cancer_tree3.ckpt\n",
      "WARNING:tensorflow:From ..\\djinn\\djinn.py:276: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./class_djinn_breast_cancer_tree0.ckpt\n",
      "Model 0 restored\n",
      "INFO:tensorflow:Restoring parameters from ./class_djinn_breast_cancer_tree1.ckpt\n",
      "Model 1 restored\n",
      "INFO:tensorflow:Restoring parameters from ./class_djinn_breast_cancer_tree2.ckpt\n",
      "Model 2 restored\n",
      "INFO:tensorflow:Restoring parameters from ./class_djinn_breast_cancer_tree3.ckpt\n",
      "Model 3 restored\n",
      "(4, 171, 2)\n"
     ]
    }
   ],
   "source": [
    "from djinn import djinn\n",
    "\n",
    "print(\"djinn breast_cancer\")    \n",
    "modelname=\"class_djinn_breast_cancer\"   # name the model\n",
    "ntrees=4               # number of trees = number of neural nets in ensemble\n",
    "maxdepth=4            # max depth of tree -- optimize this for each data set\n",
    "dropout_keep=0.5 \n",
    "\n",
    "#initialize the model\n",
    "model=djinn.DJINN_Classifier(ntrees,maxdepth,dropout_keep)\n",
    "\n",
    "x_train, y_train, x_test, y_test = out_cnn_train, y_train, out_cnn_test, y_test \n",
    "\n",
    "# find optimal settings: this function returns dict with hyper-parameters\n",
    "# each djinn function accepts random seeds for reproducible behavior\n",
    "# optimal=model.get_hyperparameters(x_train, y_train, random_state=1)\n",
    "# batchsize=optimal['batch_size']\n",
    "# learnrate=optimal['learn_rate']\n",
    "# epochs=optimal['epochs']\n",
    "batchsize=32\n",
    "learnrate=0.006\n",
    "epochs=100\n",
    "    \n",
    "# train the model with hyperparameters determined above\n",
    "model.train(x_train,y_train,epochs=epochs,learn_rate=learnrate, batch_size=batchsize, \n",
    "              display_step=1, save_files=True, file_name=modelname, \n",
    "              save_model=True,model_name=modelname, random_state=1)\n",
    "\n",
    "# *note there is a function model.fit(x_train,y_train, ... ) that wraps \n",
    "# get_hyperparameters() and train(), so that you do not have to manually\n",
    "# pass hyperparameters to train(). However, get_hyperparameters() can\n",
    "# be expensive, so I recommend running it once per dataset and using those\n",
    "# hyperparameter values in train() to save computational time\n",
    "# make predictions\n",
    "m=model.predict(x_test) #returns the median prediction if more than one tree\n",
    "\n",
    "import sklearn\n",
    "#evaluate results\n",
    "acc=sklearn.metrics.accuracy_score(y_test,m.flatten())  \n",
    "#close model \n",
    "model.close_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by CNN + ( SVM, XGB, DTree, ExtraTrees, RandomFores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8769\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 639us/step - loss: 0.2411 - accuracy: 0.9020\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 602us/step - loss: 0.2311 - accuracy: 0.9045\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 526us/step - loss: 0.2243 - accuracy: 0.9045\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 511us/step - loss: 0.2235 - accuracy: 0.9045\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 566us/step - loss: 0.2171 - accuracy: 0.9045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 727us/step - loss: 0.2208 - accuracy: 0.9045\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 599us/step - loss: 0.2251 - accuracy: 0.9095\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 645us/step - loss: 0.2292 - accuracy: 0.8995\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 749us/step - loss: 0.2266 - accuracy: 0.9070\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 704us/step - loss: 0.2204 - accuracy: 0.9171\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 712us/step - loss: 0.2182 - accuracy: 0.9121\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 566us/step - loss: 0.2246 - accuracy: 0.9070\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 759us/step - loss: 0.2134 - accuracy: 0.9070\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 747us/step - loss: 0.2375 - accuracy: 0.9045\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 641us/step - loss: 0.2262 - accuracy: 0.9070\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 669us/step - loss: 0.2126 - accuracy: 0.9070\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 631us/step - loss: 0.2179 - accuracy: 0.9045\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 844us/step - loss: 0.2168 - accuracy: 0.9070\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 674us/step - loss: 0.2154 - accuracy: 0.9171\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 730us/step - loss: 0.2146 - accuracy: 0.8995\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 796us/step - loss: 0.2212 - accuracy: 0.9070\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 679us/step - loss: 0.2140 - accuracy: 0.9146\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 741us/step - loss: 0.2223 - accuracy: 0.9146\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 702us/step - loss: 0.2130 - accuracy: 0.9121\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 796us/step - loss: 0.2135 - accuracy: 0.9146\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 722us/step - loss: 0.2162 - accuracy: 0.9146\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 960us/step - loss: 0.2084 - accuracy: 0.9246\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 596us/step - loss: 0.2193 - accuracy: 0.9146\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 636us/step - loss: 0.2108 - accuracy: 0.9095\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 564us/step - loss: 0.2130 - accuracy: 0.9171\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 534us/step - loss: 0.2135 - accuracy: 0.9121\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 536us/step - loss: 0.2135 - accuracy: 0.9146\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 586us/step - loss: 0.2079 - accuracy: 0.9121\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 576us/step - loss: 0.2134 - accuracy: 0.9045\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 609us/step - loss: 0.2148 - accuracy: 0.8995\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 566us/step - loss: 0.2081 - accuracy: 0.9070\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 544us/step - loss: 0.2077 - accuracy: 0.9146\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 520us/step - loss: 0.2067 - accuracy: 0.9171\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 843us/step - loss: 0.2131 - accuracy: 0.9095\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 546us/step - loss: 0.2166 - accuracy: 0.9121\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 694us/step - loss: 0.2168 - accuracy: 0.9171\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 713us/step - loss: 0.2139 - accuracy: 0.9121\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 724us/step - loss: 0.2075 - accuracy: 0.9146\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 728us/step - loss: 0.2134 - accuracy: 0.9095\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 583us/step - loss: 0.2027 - accuracy: 0.9171\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 570us/step - loss: 0.2075 - accuracy: 0.9146\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 704us/step - loss: 0.2130 - accuracy: 0.8945\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 671us/step - loss: 0.2066 - accuracy: 0.91460s - loss: 0.1687 - accuracy\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 639us/step - loss: 0.2071 - accuracy: 0.9070\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 595us/step - loss: 0.2035 - accuracy: 0.9070\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 639us/step - loss: 0.2100 - accuracy: 0.9196\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 611us/step - loss: 0.2079 - accuracy: 0.9045\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 607us/step - loss: 0.2059 - accuracy: 0.9045\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 580us/step - loss: 0.2101 - accuracy: 0.9020\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 623us/step - loss: 0.2071 - accuracy: 0.9146\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 542us/step - loss: 0.2015 - accuracy: 0.9121\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 507us/step - loss: 0.2132 - accuracy: 0.9070\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 537us/step - loss: 0.2063 - accuracy: 0.9196\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 942us/step - loss: 0.2123 - accuracy: 0.9070\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 599us/step - loss: 0.2036 - accuracy: 0.9095\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 679us/step - loss: 0.2074 - accuracy: 0.9196\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 687us/step - loss: 0.2043 - accuracy: 0.9070\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 536us/step - loss: 0.2058 - accuracy: 0.9146\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 720us/step - loss: 0.2042 - accuracy: 0.9146\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.89 - 0s 739us/step - loss: 0.2057 - accuracy: 0.9020\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 779us/step - loss: 0.2050 - accuracy: 0.9121\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 568us/step - loss: 0.2138 - accuracy: 0.9095\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 504us/step - loss: 0.2052 - accuracy: 0.9095\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 560us/step - loss: 0.2088 - accuracy: 0.9146\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 613us/step - loss: 0.2071 - accuracy: 0.9095\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 594us/step - loss: 0.2067 - accuracy: 0.9121\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 516us/step - loss: 0.2022 - accuracy: 0.9146\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 541us/step - loss: 0.2071 - accuracy: 0.9095\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 854us/step - loss: 0.2081 - accuracy: 0.9121\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 669us/step - loss: 0.2045 - accuracy: 0.9171\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 634us/step - loss: 0.2021 - accuracy: 0.9146\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 599us/step - loss: 0.2063 - accuracy: 0.9196\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 624us/step - loss: 0.2033 - accuracy: 0.9171\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 823us/step - loss: 0.2019 - accuracy: 0.9121\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 721us/step - loss: 0.2072 - accuracy: 0.9146\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 953us/step - loss: 0.2062 - accuracy: 0.9146\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 845us/step - loss: 0.2102 - accuracy: 0.9146\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 844us/step - loss: 0.2050 - accuracy: 0.9095\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 678us/step - loss: 0.2073 - accuracy: 0.9070\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 654us/step - loss: 0.2108 - accuracy: 0.9045\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 739us/step - loss: 0.2068 - accuracy: 0.9146\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 660us/step - loss: 0.2075 - accuracy: 0.9095\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 584us/step - loss: 0.2095 - accuracy: 0.9095\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 500us/step - loss: 0.2046 - accuracy: 0.9070\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 514us/step - loss: 0.2084 - accuracy: 0.9070\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 506us/step - loss: 0.2076 - accuracy: 0.9146\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 529us/step - loss: 0.2060 - accuracy: 0.9070\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 564us/step - loss: 0.2082 - accuracy: 0.9146\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 483us/step - loss: 0.2061 - accuracy: 0.9146\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 516us/step - loss: 0.2066 - accuracy: 0.9070\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 514us/step - loss: 0.2056 - accuracy: 0.9146\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 532us/step - loss: 0.2053 - accuracy: 0.9121\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 567us/step - loss: 0.2140 - accuracy: 0.9095\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 494us/step - loss: 0.2022 - accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(out_cnn_train, y_train)\n",
    "#Feed the features of the test to Random Forest Classifier to predict its class\n",
    "predictions = rf.predict(out_cnn_test)\n",
    "accuracy_CNN_RF=accuracy_score(predictions , y_test)\n",
    "#print('CNN+RF : Accuracy:', accuracy_CNN_RF, '%.')\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Ext = ExtraTreesClassifier(n_estimators=10)\n",
    "Ext.fit(out_cnn_train, y_train)\n",
    "#Feed the features of the test to ExtraTreesClassifier Classifier to predict its class\n",
    "predictions = Ext.predict(out_cnn_test)\n",
    "accuracy_CNN_Ext=accuracy_score(predictions , y_test)\n",
    "#print('CNN+Extrat : Accuracy:', accuracy_CNN_Ext, '%.')\n",
    "\n",
    "\n",
    "#Applying SVC (Support Vector Classification)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=.10, C=1.0)\n",
    "svm.fit(out_cnn_train, y_train)\n",
    "#print('The accuracy of the SVM classifier on training data is {:.4f}'.format(svm.score(x_train, y_train)))\n",
    "\n",
    "\n",
    "#Applying XGBoost\n",
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf = xgb_clf.fit(out_cnn_train, y_train)\n",
    "#print('The accuracy of the XGBoost classifier on training data is {:.4f}'.format(xgb_clf.score(x_train, y_train)))\n",
    "\n",
    "\n",
    "#Applying Decision Tree\n",
    "from sklearn import tree\n",
    "#Create tree object\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "#Train DT based on scaled training set\n",
    "decision_tree.fit(out_cnn_train, y_train)\n",
    "#Print performance\n",
    "#print('The accuracy of the Decision Tree classifier on training data is {:.4f}'.format(decision_tree.score(x_train, y_train)))\n",
    "\n",
    "\n",
    "# define the keras model\n",
    "MLP = Sequential()\n",
    "MLP.add(Dense(32, input_dim=out_cnn_train.shape[1], activation='relu'))\n",
    "MLP.add(Dense(64, activation='relu'))\n",
    "MLP.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "MLP.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "MLP.fit(out_cnn_train, y_train, epochs=100, batch_size=3)\n",
    "# make class predictions with the model\n",
    "predictions = MLP.predict_classes(x_test)\n",
    "#accuracy_MLP\n",
    "accuracy_MLP=accuracy_score(predictions , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# 10-fold cross-validation with the best KNN model\n",
    "# This will allow us to get a better results\n",
    "cx_train = np.concatenate((x_train, x_test), 0)\n",
    "cy_train = np.concatenate((y_train, y_test), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification by RandomForest, ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier : from dataset originl\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(x_train_, y_train_)\n",
    "predictions = rf.predict(x_test_)\n",
    "accuracy_RF=accuracy_score(predictions , y_test_)\n",
    "#print('RF : Accuracy:', accuracy_RF, '%.')\n",
    "\n",
    "# ExtraTreesClassifier : from dataset originl\n",
    "Extra = ExtraTreesClassifier(n_estimators=10)\n",
    "Extra.fit(x_train_, y_train_)\n",
    "predictions = Extra.predict(x_test_)\n",
    "accuracy_Extra=accuracy_score(predictions , y_test_)\n",
    "#print('Extra : Accuracy:', accuracy_Extra, '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Accuracy RF          :: 0.9825 %.\n",
      "Accuracy Extrat      :: 0.9591 %.\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Accuracy CNN         :: 0.9357 %.\n",
      "Accuracy CNN+RF      :: 0.9415 %.\n",
      "Accuracy CNN+Extrat  :: 0.9123 %.\n",
      "Accuracy CNN+SVM     :: 0.9415 %.\n",
      "Accuracy CNN+XGBoost :: 0.9298 %.\n",
      "Accuracy CNN+DTree   :: 0.9123 %.\n",
      "Accuracy CNN+MLP     :: 0.9240 %.\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Accuracy CNN+RF+MLP  :: 0.8480 %.\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Accuracy CNN+SVM using cv=10     :: 0.9210 %.\n",
      "Accuracy CNN+rf  using cv=10     :: 0.9123 %.\n",
      "Accuracy CNN+XGBoost using cv=10 :: 0.9210 %.\n"
     ]
    }
   ],
   "source": [
    "print('::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::')\n",
    "print('Accuracy RF          ::',  \"{:.4f}\".format(accuracy_RF),'%.')\n",
    "print('Accuracy Extrat      ::',  \"{:.4f}\".format(accuracy_Extra),'%.')\n",
    "print('::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::')\n",
    "print('Accuracy CNN         ::',  \"{:.4f}\".format(accuracy_CNN), '%.')\n",
    "print('Accuracy CNN+RF      ::',  \"{:.4f}\".format(accuracy_CNN_RF), '%.')\n",
    "print('Accuracy CNN+Extrat  ::',  \"{:.4f}\".format(accuracy_CNN_Ext), '%.')\n",
    "print('Accuracy CNN+SVM     :: {:.4f}'.format(svm.score(x_test, y_test)),'%.')\n",
    "print('Accuracy CNN+XGBoost :: {:.4f}'.format(xgb_clf.score(x_test, y_test)),'%.')\n",
    "print('Accuracy CNN+DTree   :: {:.4f}'.format(decision_tree.score(x_test, y_test)),'%.')\n",
    "print('Accuracy CNN+MLP     :: {:.4f}'.format(accuracy_MLP),'%.')\n",
    "print('::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::')\n",
    "print('Accuracy CNN+RF+MLP  ::',  \"{:.4f}\".format(acc),'%.')\n",
    "print('::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::')\n",
    "print('Accuracy CNN+SVM using cv=10     :: {:.4f}' .format(cross_val_score(svm, cx_train, cy_train, cv=10, scoring='accuracy').mean()),'%.')\n",
    "print('Accuracy CNN+rf  using cv=10     :: {:.4f}' .format(cross_val_score(rf, cx_train, cy_train, cv=10, scoring='accuracy').mean() ),'%.')\n",
    "print('Accuracy CNN+XGBoost using cv=10 :: {:.4f}'.format(cross_val_score(xgb_clf, cx_train, cy_train, cv=10, scoring='accuracy').mean() ),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/38957/keras-conv1d-for-simple-data-target-prediction\n",
    "#https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
